-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/row/row0sel.cc
Function: row_search_mvcc
dberr_t row_search_mvcc(byte *buf, page_cur_mode_t mode,
                        row_prebuilt_t *prebuilt, ulint match_mode,
                        const ulint direction) {
  DBUG_TRACE;

  dict_index_t *index = prebuilt->index;
  bool comp = dict_table_is_comp(index->table);
  const dtuple_t *search_tuple = prebuilt->search_tuple;
  btr_pcur_t *pcur = prebuilt->pcur;
  trx_t *trx = prebuilt->trx;
  dict_index_t *clust_index;
  /* True if we are scanning a secondary index, but the template is based
  on the primary index. */
  bool clust_templ_for_sec;
  que_thr_t *thr;
  const rec_t *prev_rec = nullptr;
#ifdef UNIV_DEBUG
  const rec_t *prev_rec_debug = nullptr;
  ulint prev_rec_debug_n_fields = 0;
  byte *prev_rec_debug_buf = nullptr;
  size_t prev_rec_debug_buf_size = 0;
#endif /* UNIV_DEBUG */
  const rec_t *rec = nullptr;
  byte *end_range_cache = nullptr;
  const dtuple_t *prev_vrow = nullptr;
  const dtuple_t *vrow = nullptr;
  const rec_t *result_rec = nullptr;
  const rec_t *clust_rec;
  Row_sel_get_clust_rec_for_mysql row_sel_get_clust_rec_for_mysql;
  dberr_t err = DB_SUCCESS;
  bool unique_search = false;
  bool mtr_has_extra_clust_latch = false;
  bool moves_up = false;
  bool set_also_gap_locks = true;
  /* if the query is a plain locking SELECT, and the isolation level
  is <= TRX_ISO_READ_COMMITTED, then this is set to false */
  bool did_semi_consistent_read = false;
  /* if the returned record was locked and we did a semi-consistent
  read (fetch the newest committed version), then this is set to
  true */
  ulint next_offs;
  bool same_user_rec = false;
  mtr_t mtr;
  mem_heap_t *heap = nullptr;
  ulint offsets_[REC_OFFS_NORMAL_SIZE];
  ulint *offsets = offsets_;
  ulint sec_offsets_[REC_OFFS_NORMAL_SIZE];
  ulint *sec_offsets = nullptr;
  bool table_lock_waited = false;
  byte *next_buf = nullptr;
  bool spatial_search = false;
  ulint end_loop = 0;

  rec_offs_init(offsets_);

  ut_ad(index && pcur && search_tuple);
  ut_a(prebuilt->magic_n == ROW_PREBUILT_ALLOCATED);
  ut_a(prebuilt->magic_n2 == ROW_PREBUILT_ALLOCATED);
  ut_a(!trx->has_search_latch);

  /* We don't support FTS queries from the HANDLER interfaces, because
  we implemented FTS as reversed inverted index with auxiliary tables.
  So anything related to traditional index query would not apply to
  it. */
  if (prebuilt->index->type & DICT_FTS) {
    return DB_END_OF_INDEX;
  }

#ifdef UNIV_DEBUG
  {
    btrsea_sync_check check(trx->has_search_latch);
    ut_ad(!sync_check_iterate(check));
  }
#endif /* UNIV_DEBUG */

  if (dict_table_is_discarded(prebuilt->table)) {
    return DB_TABLESPACE_DELETED;

  } else if (prebuilt->table->ibd_file_missing) {
    return DB_TABLESPACE_NOT_FOUND;

  } else if (!prebuilt->index_usable) {
    return DB_MISSING_HISTORY;

  } else if (prebuilt->index->is_corrupted()) {
    return DB_CORRUPTION;
  }

  /* We need to get the virtual column values stored in secondary
  index key, if this is covered index scan or virtual key read is
  requested. */
  bool need_vrow = dict_index_has_virtual(prebuilt->index) &&
                   (prebuilt->read_just_key || prebuilt->m_read_virtual_key);

  /* Reset the new record lock info.
  Then we are able to remove the record locks set here on an
  individual row. */
  prebuilt->new_rec_lock.reset();
  /*-------------------------------------------------------------*/
  /* PHASE 1: Try to pop the row from the record buffer or from
  the prefetch cache */

  const auto record_buffer = row_sel_get_record_buffer(prebuilt);

  if (UNIV_UNLIKELY(direction == 0)) {
    trx->op_info = "starting index read";

    prebuilt->n_rows_fetched = 0;
    prebuilt->n_fetch_cached = 0;
    prebuilt->fetch_cache_first = 0;
    prebuilt->m_end_range = false;
    if (record_buffer != nullptr) {
      record_buffer->reset();
    }

    if (prebuilt->sel_graph == nullptr) {
      /* Build a dummy select query graph */
      row_prebuild_sel_graph(prebuilt);
    }
  } else {
    trx->op_info = "fetching rows";

    if (prebuilt->n_rows_fetched == 0) {
      prebuilt->fetch_direction = direction;
    }

    if (UNIV_UNLIKELY(direction != prebuilt->fetch_direction)) {
      if (UNIV_UNLIKELY(prebuilt->n_fetch_cached > 0)) {
        ut_error;
        /* TODO: scrollable cursor: restore cursor to
        the place of the latest returned row,
        or better: prevent caching for a scroll
        cursor! */
      }

      prebuilt->n_rows_fetched = 0;
      prebuilt->n_fetch_cached = 0;
      prebuilt->fetch_cache_first = 0;
      prebuilt->m_end_range = false;

      /* A record buffer is not used for scroll cursors.
      Otherwise, it would have to be reset here too. */
      ut_ad(record_buffer == nullptr);

    } else if (UNIV_LIKELY(prebuilt->n_fetch_cached > 0)) {
      row_sel_dequeue_cached_row_for_mysql(buf, prebuilt);

      prebuilt->n_rows_fetched++;

      err = DB_SUCCESS;
      goto func_exit;
    } else if (prebuilt->m_end_range) {
      err = DB_RECORD_NOT_FOUND;
      goto func_exit;
    }

    /* The prefetch cache is exhausted, so fetch_cache_first
    should point to the beginning of the cache. */
    ut_ad(prebuilt->fetch_cache_first == 0);

    if (record_buffer != nullptr && record_buffer->is_out_of_range()) {
      /* The previous returned row was popped from
      the fetch cache, but the end of the range was
      reached while filling the cache, so there are
      no more rows to put into the cache. */

      err = DB_RECORD_NOT_FOUND;
      goto func_exit;
    }

    prebuilt->n_rows_fetched++;

    if (prebuilt->n_rows_fetched > 1000000000) {
      /* Prevent wrap-over */
      prebuilt->n_rows_fetched = 500000000;
    }

    mode = pcur->m_search_mode;
  }

  /* In a search where at most one record in the index may match, we
  can use a LOCK_REC_NOT_GAP type record lock when locking a
  non-delete-marked matching record.

  Note that in a unique secondary index there may be different
  delete-marked versions of a record where only the primary key
  values differ: thus in a secondary index we must use next-key
  locks when locking delete-marked records. */

  if (match_mode == ROW_SEL_EXACT && dict_index_is_unique(index) &&
      dtuple_get_n_fields(search_tuple) == dict_index_get_n_unique(index) &&
      (index->is_clustered() || !dtuple_contains_null(search_tuple))) {
    /* Note above that a UNIQUE secondary index can contain many
    rows with the same key value if one of the columns is the SQL
    null. A clustered index under MySQL can never contain null
    columns because we demand that all the columns in primary key
    are non-null. */

    unique_search = true;

    /* Even if the condition is unique, MySQL seems to try to
    retrieve also a second row if a primary key contains more than
    1 column. Return immediately if this is not a HANDLER
    command. */

    if (UNIV_UNLIKELY(direction != 0 && !prebuilt->used_in_HANDLER)) {
      err = DB_RECORD_NOT_FOUND;
      goto func_exit;
    }
  }

  /* We don't support sequential scan for Rtree index, because it
  is no meaning to do so. */
  if (dict_index_is_spatial(index) && !RTREE_SEARCH_MODE(mode)) {
    err = DB_END_OF_INDEX;
    goto func_exit;
  }

  mtr_start(&mtr);

  /*-------------------------------------------------------------*/
  /* PHASE 2: Try fast adaptive hash index search if possible */

  /* Next test if this is the special case where we can use the fast
  adaptive hash index to try the search. Since we must release the
  search system latch when we retrieve an externally stored field, we
  cannot use the adaptive hash index in a search in the case the row
  may be long and there may be externally stored fields */

  if (UNIV_UNLIKELY(direction == 0) && unique_search && btr_search_enabled &&
      index->is_clustered() && !prebuilt->templ_contains_blob &&
      !prebuilt->used_in_HANDLER &&
      (prebuilt->mysql_row_len < UNIV_PAGE_SIZE / 8) && !prebuilt->innodb_api) {
    mode = PAGE_CUR_GE;

    if (trx->mysql_n_tables_locked == 0 && !prebuilt->ins_sel_stmt &&
        prebuilt->select_lock_type == LOCK_NONE &&
        trx->isolation_level > TRX_ISO_READ_UNCOMMITTED &&
        MVCC::is_view_active(trx->read_view)) {
      /* This is a SELECT query done as a consistent read,
      and the read view has already been allocated:
      let us try a search shortcut through the hash
      index.
      NOTE that we must also test that
      mysql_n_tables_locked == 0, because this might
      also be INSERT INTO ... SELECT ... or
      CREATE TABLE ... SELECT ... . Our algorithm is
      NOT prepared to inserts interleaved with the SELECT,
      and if we try that, we can deadlock on the adaptive
      hash index semaphore! */

      ut_a(!trx->has_search_latch);
      rw_lock_s_lock(btr_get_search_latch(index), UT_LOCATION_HERE);
      trx->has_search_latch = true;

      switch (row_sel_try_search_shortcut_for_mysql(&rec, prebuilt, &offsets,
                                                    &heap, &mtr)) {
        case SEL_FOUND:
          /* At this point, rec is protected by
          a page latch that was acquired by
          row_sel_try_search_shortcut_for_mysql().
          The latch will not be released until
          mtr_commit(&mtr). */
          ut_ad(!rec_get_deleted_flag(rec, comp));

          if (prebuilt->idx_cond) {
            switch (row_search_idx_cond_check(buf, prebuilt, rec, offsets)) {
              case ICP_NO_MATCH:
              case ICP_OUT_OF_RANGE:
                goto shortcut_mismatch;
              case ICP_MATCH:
                goto shortcut_match;
            }
          }

          if (!row_sel_store_mysql_rec(buf, prebuilt, rec, nullptr, false,
                                       index, prebuilt->index, offsets, false,
                                       nullptr, prebuilt->blob_heap)) {
            /* Only fresh inserts may contain
            incomplete externally stored
            columns. Pretend that such
            records do not exist. Such
            records may only be accessed
            at the READ UNCOMMITTED
            isolation level or when
            rolling back a recovered
            transaction. Rollback happens
            at a lower level, not here. */

            /* Proceed as in case SEL_RETRY. */
            break;
          }

        shortcut_match:
          mtr_commit(&mtr);

          /* NOTE that we do NOT store the cursor
          position */

          err = DB_SUCCESS;

          rw_lock_s_unlock(btr_get_search_latch(index));
          trx->has_search_latch = false;

          goto func_exit;

        case SEL_EXHAUSTED:
        shortcut_mismatch:
          mtr_commit(&mtr);

          err = DB_RECORD_NOT_FOUND;

          rw_lock_s_unlock(btr_get_search_latch(index));
          trx->has_search_latch = false;

          /* NOTE that we do NOT store the cursor
          position */

          goto func_exit;

        case SEL_RETRY:
          break;

        default:
          ut_d(ut_error);
      }

      mtr_commit(&mtr);
      mtr_start(&mtr);

      rw_lock_s_unlock(btr_get_search_latch(index));
      trx->has_search_latch = false;
    }
  }

  /*-------------------------------------------------------------*/
  /* PHASE 3: Open or restore index cursor position */

  spatial_search = dict_index_is_spatial(index) && mode >= PAGE_CUR_CONTAIN;

  /* The state of a running trx can only be changed by the
  thread that is currently serving the transaction. Because we
  are that thread, we can read trx->state without holding any
  mutex. */

  ut_ad(prebuilt->sql_stat_start ||
        trx->state.load(std::memory_order_relaxed) == TRX_STATE_ACTIVE);

  ut_ad(!trx_is_started(trx) ||
        trx->state.load(std::memory_order_relaxed) == TRX_STATE_ACTIVE);

  ut_ad(prebuilt->sql_stat_start || prebuilt->select_lock_type != LOCK_NONE ||
        MVCC::is_view_active(trx->read_view) || srv_read_only_mode);

  trx_start_if_not_started(trx, false, UT_LOCATION_HERE);

  if (prebuilt->table->skip_gap_locks() ||
      (trx->skip_gap_locks() && prebuilt->select_lock_type != LOCK_NONE &&
       trx->mysql_thd != nullptr && thd_is_query_block(trx->mysql_thd))) {
    /* It is a plain locking SELECT and the isolation
    level is low: do not lock gaps */

    /* Reads on DD tables dont require gap-locks as serializability
    between different DDL statements is achieved using
    metadata locks */
    set_also_gap_locks = false;
  }

  /* Note that if the search mode was GE or G, then the cursor
  naturally moves upward (in fetch next) in alphabetical order,
  otherwise downward */

  if (direction == 0) {
    if (mode == PAGE_CUR_GE || mode == PAGE_CUR_G || mode >= PAGE_CUR_CONTAIN) {
      moves_up = true;
    }

  } else if (direction == ROW_SEL_NEXT) {
    moves_up = true;
  }

  thr = que_fork_get_first_thr(prebuilt->sel_graph);

  que_thr_move_to_run_state_for_mysql(thr, trx);

  clust_index = index->table->first_index();

  clust_templ_for_sec =
      index != clust_index && prebuilt->need_to_access_clustered;

  /* Do some start-of-statement preparations */

  if (!prebuilt->sql_stat_start) {
    /* No need to set an intention lock or assign a read view */

    if (!MVCC::is_view_active(trx->read_view) && !srv_read_only_mode &&
        prebuilt->select_lock_type == LOCK_NONE) {
      ib::error(ER_IB_MSG_1031) << "MySQL is trying to perform a"
                                   " consistent read but the read view is not"
                                   " assigned!";
      trx_print(stderr, trx, 600);
      fputc('\n', stderr);
      ut_error;
    }
  } else if (prebuilt->select_lock_type == LOCK_NONE) {
    /* This is a consistent read */
    /* Assign a read view for the query */

    if (!srv_read_only_mode) {
      trx_assign_read_view(trx);
    }

    prebuilt->sql_stat_start = false;
  } else {
  wait_table_again:
    err = lock_table(0, index->table,
                     prebuilt->select_lock_type == LOCK_S ? LOCK_IS : LOCK_IX,
                     thr);

    if (err != DB_SUCCESS) {
      table_lock_waited = true;
      goto lock_table_wait;
    }
    prebuilt->sql_stat_start = false;
  }

  /* Open or restore index cursor position */

  if (UNIV_LIKELY(direction != 0)) {
    if (spatial_search) {
      /* R-Tree access does not need to do
      cursor position and resposition */
      goto next_rec;
    }

    auto need_to_process = sel_restore_position_for_mysql(
        &same_user_rec, BTR_SEARCH_LEAF, pcur, moves_up, &mtr);

    ut_ad(prev_rec == nullptr);

    if (UNIV_UNLIKELY(need_to_process)) {
      if (UNIV_UNLIKELY(prebuilt->row_read_type ==
                        ROW_READ_DID_SEMI_CONSISTENT)) {
        /* We did a semi-consistent read,
        but the record was removed in
        the meantime. */
        prebuilt->row_read_type = ROW_READ_TRY_SEMI_CONSISTENT;
      }
    } else if (UNIV_LIKELY(prebuilt->row_read_type !=
                           ROW_READ_DID_SEMI_CONSISTENT)) {
      /* The cursor was positioned on the record
      that we returned previously.  If we need
      to repeat a semi-consistent read as a
      pessimistic locking read, the record
      cannot be skipped. */

      goto next_rec;
    }

  } else if (dtuple_get_n_fields(search_tuple) > 0) {
    pcur->m_btr_cur.thr = thr;

    if (dict_index_is_spatial(index)) {
      bool need_pred_lock = set_also_gap_locks && !trx->skip_gap_locks() &&
                            prebuilt->select_lock_type != LOCK_NONE;

      if (!prebuilt->rtr_info) {
        prebuilt->rtr_info = rtr_create_rtr_info(need_pred_lock, true,
                                                 pcur->get_btr_cur(), index);
        prebuilt->rtr_info->search_tuple = search_tuple;
        prebuilt->rtr_info->search_mode = mode;
        rtr_info_update_btr(pcur->get_btr_cur(), prebuilt->rtr_info);
      } else {
        rtr_info_reinit_in_cursor(pcur->get_btr_cur(), index, need_pred_lock);
        prebuilt->rtr_info->search_tuple = search_tuple;
        prebuilt->rtr_info->search_mode = mode;
      }
    }

    pcur->open_no_init(index, search_tuple, mode, BTR_SEARCH_LEAF, 0, &mtr,
                       UT_LOCATION_HERE);

    pcur->m_trx_if_known = trx;

    rec = pcur->get_rec();

    if (!moves_up && !page_rec_is_supremum(rec) && set_also_gap_locks &&
        !trx->skip_gap_locks() && prebuilt->select_lock_type != LOCK_NONE &&
        !dict_index_is_spatial(index)) {
      /* Try to place a gap lock on the next index record
      to prevent phantoms in ORDER BY ... DESC queries */
      const rec_t *next_rec = page_rec_get_next_const(rec);

      offsets = rec_get_offsets(next_rec, index, offsets, ULINT_UNDEFINED,
                                UT_LOCATION_HERE, &heap);
      err = sel_set_rec_lock(pcur, next_rec, index, offsets,
                             prebuilt->select_mode, prebuilt->select_lock_type,
                             LOCK_GAP, thr, &mtr);

      switch (err) {
        case DB_SUCCESS_LOCKED_REC:
          err = DB_SUCCESS;
        case DB_SUCCESS:
          break;
        case DB_SKIP_LOCKED:
        case DB_LOCK_NOWAIT:
          ut_d(ut_error);
          ut_o(goto next_rec);
        default:
          goto lock_wait_or_error;
      }
    }
  } else if (mode == PAGE_CUR_G || mode == PAGE_CUR_L) {
    pcur->open_at_side(mode == PAGE_CUR_G, index, BTR_SEARCH_LEAF, false, 0,
                       &mtr);
  }

rec_loop:
  ut_ad(trx_can_be_handled_by_current_thread(trx));
  DEBUG_SYNC_C("row_search_rec_loop");

  prebuilt->lob_undo_reset();

  if (trx_is_interrupted(trx)) {
    if (!spatial_search) {
      pcur->store_position(&mtr);
    }
    err = DB_INTERRUPTED;
    goto normal_return;
  }

  /*-------------------------------------------------------------*/
  /* PHASE 4: Look for matching records in a loop */

  rec = pcur->get_rec();

  ut_ad(page_rec_is_comp(rec) == comp);

  if (page_rec_is_infimum(rec)) {
    /* The infimum record on a page cannot be in the result set,
    and neither can a record lock be placed on it: we skip such
    a record. */

    prev_rec = nullptr;
    goto next_rec;
  }

  if (page_rec_is_supremum(rec)) {
    DBUG_EXECUTE_IF(
        "compare_end_range", if (end_loop < 100) { end_loop = 100; });

    /** Compare the last record of the page with end range
    passed to InnoDB when there is no ICP and number of
    loops in row_search_mvcc for rows found but not
    reporting due to search views etc. */
    if (prev_rec != nullptr && !prebuilt->innodb_api &&
        prebuilt->m_mysql_handler->end_range != nullptr &&
        prebuilt->idx_cond == false && end_loop >= 100) {
      dict_index_t *key_index = prebuilt->index;

      if (end_range_cache == nullptr) {
        end_range_cache = static_cast<byte *>(ut::malloc_withkey(
            UT_NEW_THIS_FILE_PSI_KEY, prebuilt->mysql_row_len));
      }

      if (clust_templ_for_sec) {
        /** Secondary index record but the template
        based on PK. */
        key_index = clust_index;
      }

      /** Create offsets based on prebuilt index. */
      offsets = rec_get_offsets(prev_rec, prebuilt->index, offsets,
                                ULINT_UNDEFINED, UT_LOCATION_HERE, &heap);

      if (row_sel_store_mysql_rec(end_range_cache, prebuilt, prev_rec,
                                  prev_vrow, clust_templ_for_sec, key_index,
                                  prebuilt->index, offsets, clust_templ_for_sec,
                                  prebuilt->get_lob_undo(),
                                  prebuilt->blob_heap)) {
        if (row_search_end_range_check(end_range_cache, prev_rec, prebuilt,
                                       clust_templ_for_sec, offsets,
                                       record_buffer)) {
          /** In case of prebuilt->fetch,
          set the error in prebuilt->end_range. */
          if (next_buf != nullptr) {
            prebuilt->m_end_range = true;
          }

          err = DB_RECORD_NOT_FOUND;
          goto normal_return;
        }
      }
      DEBUG_SYNC_C("allow_insert");
    }

    if (set_also_gap_locks && !trx->skip_gap_locks() &&
        prebuilt->select_lock_type != LOCK_NONE &&
        !dict_index_is_spatial(index)) {
      /* Try to place a lock on the index record */

      offsets = rec_get_offsets(rec, index, offsets, ULINT_UNDEFINED,
                                UT_LOCATION_HERE, &heap);
      err = sel_set_rec_lock(pcur, rec, index, offsets, prebuilt->select_mode,
                             prebuilt->select_lock_type, LOCK_ORDINARY, thr,
                             &mtr);

      switch (err) {
        case DB_SUCCESS_LOCKED_REC:
          err = DB_SUCCESS;
        case DB_SUCCESS:
          break;
        case DB_SKIP_LOCKED:
        case DB_LOCK_NOWAIT:
          ut_d(ut_error);
        default:
          goto lock_wait_or_error;
      }
      DEBUG_SYNC_C("allow_insert");
    }

    /* A page supremum record cannot be in the result set: skip
    it now that we have placed a possible lock on it */

    prev_rec = nullptr;
    goto next_rec;
  }

  /*-------------------------------------------------------------*/
  /* Do sanity checks in case our cursor has bumped into page
  corruption */

  if (comp) {
    next_offs = rec_get_next_offs(rec, true);
    if (UNIV_UNLIKELY(next_offs < PAGE_NEW_SUPREMUM)) {
      goto wrong_offs;
    }
  } else {
    next_offs = rec_get_next_offs(rec, false);
    if (UNIV_UNLIKELY(next_offs < PAGE_OLD_SUPREMUM)) {
      goto wrong_offs;
    }
  }

  if (UNIV_UNLIKELY(next_offs >= UNIV_PAGE_SIZE - PAGE_DIR)) {
  wrong_offs:
    if (srv_force_recovery == 0 || moves_up == false) {
      ib::error(ER_IB_MSG_1032)
          << "Rec address " << static_cast<const void *>(rec)
          << ", buf block fix count "
          << btr_cur_get_block(pcur->get_btr_cur())->page.buf_fix_count;

      ib::error(ER_IB_MSG_1033)
          << "Index corruption: rec offs " << page_offset(rec) << " next offs "
          << next_offs << ", page no " << page_get_page_no(page_align(rec))
          << ", index " << index->name << " of table " << index->table->name
          << ". Run CHECK TABLE. You may need to"
             " restore from a backup, or dump + drop +"
             " reimport the table.";
      err = DB_CORRUPTION;

      ut_d(ut_error);
      ut_o(goto lock_wait_or_error);
    } else {
      /* The user may be dumping a corrupt table. Jump
      over the corruption to recover as much as possible. */

      ib::info(ER_IB_MSG_1034)
          << "Index corruption: rec offs " << page_offset(rec) << " next offs "
          << next_offs << ", page no " << page_get_page_no(page_align(rec))
          << ", index " << index->name << " of table " << index->table->name
          << ". We try to skip the rest of the page.";

      pcur->move_to_last_on_page(&mtr);

      prev_rec = nullptr;
      goto next_rec;
    }
  }
  /*-------------------------------------------------------------*/

  /* Calculate the 'offsets' associated with 'rec' */

  ut_ad(fil_page_index_page_check(pcur->get_page()));
  ut_ad(btr_page_get_index_id(pcur->get_page()) == index->id);

  offsets = rec_get_offsets(rec, index, offsets, ULINT_UNDEFINED,
                            UT_LOCATION_HERE, &heap);

  if (UNIV_UNLIKELY(srv_force_recovery > 0)) {
    if (!rec_validate(rec, offsets) ||
        !btr_index_rec_validate(rec, index, false)) {
      ib::info(ER_IB_MSG_1035)
          << "Index corruption: rec offs " << page_offset(rec) << " next offs "
          << next_offs << ", page no " << page_get_page_no(page_align(rec))
          << ", index " << index->name << " of table " << index->table->name
          << ". We try to skip the record.";

      prev_rec = nullptr;
      goto next_rec;
    }
  }

  prev_rec = rec;
  ut_d(prev_rec_debug = row_search_debug_copy_rec_order_prefix(
           pcur, index, prev_rec, &prev_rec_debug_n_fields, &prev_rec_debug_buf,
           &prev_rec_debug_buf_size));

  /* Note that we cannot trust the up_match value in the cursor at this
  place because we can arrive here after moving the cursor! Thus
  we have to recompare rec and search_tuple to determine if they
  match enough. */

  if (match_mode == ROW_SEL_EXACT) {
    /* Test if the index record matches completely to search_tuple
    in prebuilt: if not, then we return with DB_RECORD_NOT_FOUND */

    /* fputs("Comparing rec and search tuple\n", stderr); */

    if (0 != cmp_dtuple_rec(search_tuple, rec, index, offsets)) {
      if (set_also_gap_locks && !trx->skip_gap_locks() &&
          prebuilt->select_lock_type != LOCK_NONE &&
          !dict_index_is_spatial(index)) {
        err = sel_set_rec_lock(pcur, rec, index, offsets, prebuilt->select_mode,
                               prebuilt->select_lock_type, LOCK_GAP, thr, &mtr);

        switch (err) {
          case DB_SUCCESS_LOCKED_REC:
          case DB_SUCCESS:
            break;
          case DB_SKIP_LOCKED:
          case DB_LOCK_NOWAIT:
            ut_d(ut_error);
          default:
            goto lock_wait_or_error;
        }
      }

      pcur->store_position(&mtr);

      /* The found record was not a match, but may be used
      as NEXT record (index_next). Set the relative position
      to BTR_PCUR_BEFORE, to reflect that the position of
      the persistent cursor is before the found/stored row
      (pcur->m_old_rec). */
      ut_ad(pcur->m_rel_pos == BTR_PCUR_ON);
      pcur->m_rel_pos = BTR_PCUR_BEFORE;

      err = DB_RECORD_NOT_FOUND;
      goto normal_return;
    }

  } else if (match_mode == ROW_SEL_EXACT_PREFIX) {
    if (!cmp_dtuple_is_prefix_of_rec(search_tuple, rec, index, offsets)) {
      if (set_also_gap_locks && !trx->skip_gap_locks() &&
          prebuilt->select_lock_type != LOCK_NONE &&
          !dict_index_is_spatial(index)) {
        err = sel_set_rec_lock(pcur, rec, index, offsets, prebuilt->select_mode,
                               prebuilt->select_lock_type, LOCK_GAP, thr, &mtr);

        switch (err) {
          case DB_SUCCESS_LOCKED_REC:
          case DB_SUCCESS:
            break;
          case DB_SKIP_LOCKED:
          case DB_LOCK_NOWAIT:
            ut_d(ut_error);
          default:
            goto lock_wait_or_error;
        }
      }

      pcur->store_position(&mtr);

      /* The found record was not a match, but may be used
      as NEXT record (index_next). Set the relative position
      to BTR_PCUR_BEFORE, to reflect that the position of
      the persistent cursor is before the found/stored row
      (pcur->old_rec). */
      ut_ad(pcur->m_rel_pos == BTR_PCUR_ON);
      pcur->m_rel_pos = BTR_PCUR_BEFORE;

      err = DB_RECORD_NOT_FOUND;
      goto normal_return;
    }
  }

  /* We are ready to look at a possible new index entry in the result
  set: the cursor is now placed on a user record */

  if (prebuilt->select_lock_type != LOCK_NONE) {
    auto row_to_range_relation = row_compare_row_to_range(
        set_also_gap_locks, trx, unique_search, index, clust_index, rec, comp,
        mode, direction, search_tuple, offsets, moves_up, prebuilt);

    ulint lock_type;
    if (row_to_range_relation.row_can_be_in_range) {
      if (row_to_range_relation.gap_can_intersect_range) {
        lock_type = LOCK_ORDINARY;
      } else {
        lock_type = LOCK_REC_NOT_GAP;
      }
    } else {
      if (row_to_range_relation.gap_can_intersect_range) {
        lock_type = LOCK_GAP;
      } else {
        err = DB_RECORD_NOT_FOUND;
        goto normal_return;
      }
    }
    /* in case of semi-consistent read, we use SELECT_SKIP_LOCKED, so we don't
    waste time on creating a WAITING lock, as we won't wait on it anyway */
    const bool use_semi_consistent =
        prebuilt->row_read_type == ROW_READ_TRY_SEMI_CONSISTENT &&
        !unique_search && index == clust_index && !trx_is_high_priority(trx);
    err = sel_set_rec_lock(
        pcur, rec, index, offsets,
        use_semi_consistent ? SELECT_SKIP_LOCKED : prebuilt->select_mode,
        prebuilt->select_lock_type, lock_type, thr, &mtr);

    switch (err) {
      const rec_t *old_vers;
      case DB_SUCCESS_LOCKED_REC:
        if (trx->releases_non_matching_rows()) {
          /* Note that a record of
          prebuilt->index was locked. */
          ut_ad(!prebuilt->new_rec_lock[row_prebuilt_t::LOCK_PCUR]);
          prebuilt->new_rec_lock[row_prebuilt_t::LOCK_PCUR] = true;
        }
        err = DB_SUCCESS;
        [[fallthrough]];
      case DB_SUCCESS:
        if (row_to_range_relation.row_must_be_at_end) {
          prebuilt->m_stop_tuple_found = true;
        }
        break;
      case DB_SKIP_LOCKED:
        if (prebuilt->select_mode == SELECT_SKIP_LOCKED) {
          goto next_rec;
        }
        DEBUG_SYNC_C("semi_consistent_read_would_wait");
        ut_a(use_semi_consistent);
        ut_a(trx->allow_semi_consistent());
        /* The following call returns 'offsets' associated with 'old_vers' */
        row_sel_build_committed_vers_for_mysql(
            clust_index, prebuilt, rec, &offsets, &heap, &old_vers,
            need_vrow ? &vrow : nullptr, &mtr);

        ut_ad(!dict_index_is_spatial(index));
        err = DB_SUCCESS;

        if (old_vers == nullptr) {
          /* The row was not yet committed */
          goto next_rec;
        }

        did_semi_consistent_read = true;
        rec = old_vers;
        prev_rec = rec;
        ut_d(prev_rec_debug = row_search_debug_copy_rec_order_prefix(
                 pcur, index, prev_rec, &prev_rec_debug_n_fields,
                 &prev_rec_debug_buf, &prev_rec_debug_buf_size));
        break;
      case DB_LOCK_WAIT:
        /* Lock wait for R-tree should already
        be handled in sel_set_rtr_rec_lock() */
        ut_ad(!dict_index_is_spatial(index));
        /* Never unlock rows that were part of a conflict. */
        prebuilt->new_rec_lock.reset();
        ut_a(!use_semi_consistent);
        goto lock_wait_or_error;
      case DB_RECORD_NOT_FOUND:
        if (dict_index_is_spatial(index)) {
          goto next_rec;
        } else {
          goto lock_wait_or_error;
        }

      default:
        ut_a(!use_semi_consistent);
        goto lock_wait_or_error;
    }
    if (err == DB_SUCCESS && !row_to_range_relation.row_can_be_in_range) {
      err = DB_RECORD_NOT_FOUND;
      goto normal_return;
    }
  } else {
    /* This is a non-locking consistent read: if necessary, fetch
    a previous version of the record */

    if (trx->isolation_level == TRX_ISO_READ_UNCOMMITTED) {
      /* Do nothing: we let a non-locking SELECT read the
      latest version of the record */

    } else if (index == clust_index) {
      /* Fetch a previous version of the row if the current
      one is not visible in the snapshot; if we have a very
      high force recovery level set, we try to avoid crashes
      by skipping this lookup */

      if (srv_force_recovery < 5 &&
          !lock_clust_rec_cons_read_sees(rec, index, offsets,
                                         trx_get_read_view(trx))) {
        rec_t *old_vers;
        /* The following call returns 'offsets' associated with 'old_vers' */
        err = row_sel_build_prev_vers_for_mysql(
            trx->read_view, clust_index, prebuilt, rec, &offsets, &heap,
            &old_vers, need_vrow ? &vrow : nullptr, &mtr,
            prebuilt->get_lob_undo());

        if (err != DB_SUCCESS) {
          goto lock_wait_or_error;
        }

        if (old_vers == nullptr) {
          /* The row did not exist yet in
          the read view */

          goto next_rec;
        }

        rec = old_vers;
        prev_rec = rec;
        ut_d(prev_rec_debug = row_search_debug_copy_rec_order_prefix(
                 pcur, index, prev_rec, &prev_rec_debug_n_fields,
                 &prev_rec_debug_buf, &prev_rec_debug_buf_size));
      }
    } else {
      /* We are looking into a non-clustered index,
      and to get the right version of the record we
      have to look also into the clustered index: this
      is necessary, because we can only get the undo
      information via the clustered index record. */

      ut_ad(!index->is_clustered());

      if (!srv_read_only_mode &&
          !lock_sec_rec_cons_read_sees(rec, index, trx->read_view)) {
        /* We should look at the clustered index.
        However, as this is a non-locking read,
        we can skip the clustered index lookup if
        the condition does not match the secondary
        index entry. */
        switch (row_search_idx_cond_check(buf, prebuilt, rec, offsets)) {
          case ICP_NO_MATCH:
            goto next_rec;
          case ICP_OUT_OF_RANGE:
            err = DB_RECORD_NOT_FOUND;
            goto idx_cond_failed;
          case ICP_MATCH:
            goto requires_clust_rec;
        }

        ut_error;
      }
    }
  }

#ifdef UNIV_DEBUG
  if (did_semi_consistent_read) {
    ut_a(prebuilt->select_lock_type != LOCK_NONE);
    ut_a(!prebuilt->table->is_intrinsic());
    ut_a(prebuilt->row_read_type == ROW_READ_TRY_SEMI_CONSISTENT);
    ut_a(prebuilt->trx->allow_semi_consistent());
    ut_a(prebuilt->new_rec_locks_count() == 0);
  }
#endif /* UNIV_DEBUG */

  /* NOTE that at this point rec can be an old version of a clustered
  index record built for a consistent read. We cannot assume after this
  point that rec is on a buffer pool page. Functions like
  page_rec_is_comp() cannot be used! */

  if (rec_get_deleted_flag(rec, comp)) {
    /* The record is delete-marked: we can skip it */

    /* No need to keep a lock on a delete-marked record in lower isolation
    levels - it's similar to when Server sees the WHERE condition doesn't match
    and calls unlock_row(). */
    prebuilt->try_unlock(true);

    /* This is an optimization to skip setting the next key lock
    on the record that follows this delete-marked record. This
    optimization works because of the unique search criteria
    which precludes the presence of a range lock between this
    delete marked record and the record following it.

    For now this is applicable only to clustered indexes while
    doing a unique search except for HANDLER queries because
    HANDLER allows NEXT and PREV even in unique search on
    clustered index. There is scope for further optimization
    applicable to unique secondary indexes. Current behaviour is
    to widen the scope of a lock on an already delete marked record
    if the same record is deleted twice by the same transaction */
    if (index == clust_index && unique_search && !prebuilt->used_in_HANDLER) {
      err = DB_RECORD_NOT_FOUND;

      goto normal_return;
    }

    goto next_rec;
  }

  /* Check if the record matches the index condition. */
  switch (row_search_idx_cond_check(buf, prebuilt, rec, offsets)) {
    case ICP_NO_MATCH:
      prebuilt->try_unlock(true);
      goto next_rec;
    case ICP_OUT_OF_RANGE:
      err = DB_RECORD_NOT_FOUND;
      prebuilt->try_unlock(true);
      goto idx_cond_failed;
    case ICP_MATCH:
      break;
  }

  /* Get the clustered index record if needed, if we did not do the
  search using the clustered index. */

  if (index != clust_index && prebuilt->need_to_access_clustered) {
  requires_clust_rec:
    ut_ad(index != clust_index);
    /* We use a 'goto' to the preceding label if a consistent
    read of a secondary index record requires us to look up old
    versions of the associated clustered index record. */

    ut_ad(rec_offs_validate(rec, index, offsets));

    /* It was a non-clustered index and we must fetch also the
    clustered index record */

    mtr_has_extra_clust_latch = true;

    ut_ad(!vrow);

    /* The following call returns 'offsets' associated with
    'clust_rec'. Note that 'clust_rec' can be an old version
    built for a consistent read. */
    err = row_sel_get_clust_rec_for_mysql(
        prebuilt, index, rec, thr, &clust_rec, &offsets, &heap,
        need_vrow ? &vrow : nullptr, &mtr, prebuilt->get_lob_undo());
    switch (err) {
      case DB_SUCCESS:
        if (clust_rec == nullptr) {
          /* The record did not exist in the read view */
          ut_ad(prebuilt->select_lock_type == LOCK_NONE ||
                dict_index_is_spatial(index));

          goto next_rec;
        }
        break;
      case DB_SKIP_LOCKED:
        goto next_rec;
      case DB_SUCCESS_LOCKED_REC:
        ut_a(clust_rec != nullptr);
        if (trx->releases_non_matching_rows()) {
          /* Note that the clustered index record
          was locked. */
          ut_ad(!prebuilt->new_rec_lock[row_prebuilt_t::LOCK_CLUST_PCUR]);
          prebuilt->new_rec_lock[row_prebuilt_t::LOCK_CLUST_PCUR] = true;
        }
        err = DB_SUCCESS;
        break;
      default:
        vrow = nullptr;
        goto lock_wait_or_error;
    }

    if (rec_get_deleted_flag(clust_rec, comp)) {
      /* The record is delete marked: we can skip it */

      /* No need to keep a lock on a delete-marked record in lower isolation
      levels - it's similar to when Server sees the WHERE condition doesn't
      match and calls unlock_row(). */
      prebuilt->try_unlock(true);

      goto next_rec;
    }

    if (need_vrow && !vrow) {
      if (!heap) {
        heap = mem_heap_create(100, UT_LOCATION_HERE);
      }
      row_sel_fill_vrow(rec, index, &vrow, heap);
    }

    result_rec = clust_rec;
    ut_ad(rec_offs_validate(result_rec, clust_index, offsets));

    if (prebuilt->idx_cond) {
      /* Convert the record to MySQL format. We were
      unable to do this in row_search_idx_cond_check(),
      because the condition is on the secondary index
      and the requested column is in the clustered index.
      We convert all fields, including those that
      may have been used in ICP, because the
      secondary index may contain a column prefix
      rather than the full column. Also, as noted
      in Bug #56680, the column in the secondary
      index may be in the wrong case, and the
      authoritative case is in result_rec, the
      appropriate version of the clustered index record. */
      if (!row_sel_store_mysql_rec(buf, prebuilt, result_rec, vrow, true,
                                   clust_index, prebuilt->index, offsets, false,
                                   nullptr, prebuilt->blob_heap)) {
        goto next_rec;
      }
    }

    /* TODO: This is for a temporary fix, will be removed later */
    /* Check duplicate rec for spatial index. */
    if (dict_index_is_spatial(index) && rec_get_deleted_flag(rec, comp) &&
        prebuilt->rtr_info->is_dup) {
      dtuple_t *clust_row;
      row_ext_t *ext = nullptr;
      rtr_mbr_t clust_mbr;
      rtr_mbr_t index_mbr;
      ulint *index_offsets;
      const dtuple_t *index_entry;
      bool *is_dup_rec = prebuilt->rtr_info->is_dup;

      *is_dup_rec = false;

      if (!heap) {
        heap = mem_heap_create(100, UT_LOCATION_HERE);
      }

      clust_row = row_build(ROW_COPY_DATA, clust_index, clust_rec, offsets,
                            nullptr, nullptr, nullptr, &ext, heap);
      index_entry = row_build_index_entry(clust_row, ext, index, heap);
      rtr_get_mbr_from_tuple(index_entry, &clust_mbr);

      index_offsets = rec_get_offsets(rec, index, nullptr, ULINT_UNDEFINED,
                                      UT_LOCATION_HERE, &heap);
      rtr_get_mbr_from_rec(rec, index_offsets, &index_mbr);

      if (mbr_equal_cmp(index->rtr_srs.get(), &clust_mbr, &index_mbr)) {
        *is_dup_rec = true;
      }
    }
  } else {
    result_rec = rec;
  }

  /* We found a qualifying record 'result_rec'. At this point,
  'offsets' are associated with 'result_rec'. */

  ut_ad(rec_offs_validate(result_rec, result_rec != rec ? clust_index : index,
                          offsets));
  ut_ad(!rec_get_deleted_flag(result_rec, comp));

  /* If we cannot prefetch records, we should not have a record buffer.
  See ha_innobase::ha_is_record_buffer_wanted(). */
  ut_ad(prebuilt->can_prefetch_records() || record_buffer == nullptr);

  /* Decide whether to prefetch extra rows.
  At this point, the clustered index record is protected
  by a page latch that was acquired when pcur was positioned.
  The latch will not be released until mtr_commit(&mtr). */

  if (record_buffer != nullptr ||
      ((match_mode == ROW_SEL_EXACT ||
        prebuilt->n_rows_fetched >= MYSQL_FETCH_CACHE_THRESHOLD) &&
       prebuilt->can_prefetch_records())) {
    /* Inside an update, for example, we do not cache rows,
    since we may use the cursor position to do the actual
    update, that is why we require ...lock_type == LOCK_NONE.
    Since we keep space in prebuilt only for the BLOBs of
    a single row, we cannot cache rows in the case there
    are BLOBs in the fields to be fetched. In HANDLER (note:
    the HANDLER statement, not the handler class) we do
    not cache rows because there the cursor is a scrollable
    cursor. */

    const auto max_rows_to_cache =
        record_buffer ? record_buffer->max_records() : MYSQL_FETCH_CACHE_SIZE;
    ut_a(prebuilt->n_fetch_cached < max_rows_to_cache);

    /* We only convert from InnoDB row format to MySQL row
    format when ICP is disabled. */

    if (!prebuilt->idx_cond) {
      /* We use next_buf to track the allocation of buffers
      where we store and enqueue the buffers for our
      pre-fetch optimisation.

      If next_buf == 0 then we store the converted record
      directly into the MySQL record buffer (buf). If it is
      != 0 then we allocate a pre-fetch buffer and store the
      converted record there.

      If the conversion fails and the MySQL record buffer
      was not written to then we reset next_buf so that
      we can re-use the MySQL record buffer in the next
      iteration. */
      byte *prev_buf = next_buf;

      next_buf = next_buf ? row_sel_fetch_last_buf(prebuilt) : buf;

      if (!row_sel_store_mysql_rec(
              next_buf, prebuilt, result_rec, vrow, result_rec != rec,
              result_rec != rec ? clust_index : index, prebuilt->index, offsets,
              false, nullptr, prebuilt->blob_heap)) {
        if (next_buf == buf) {
          ut_a(prebuilt->n_fetch_cached == 0);
          next_buf = nullptr;
        }

        /* Only fresh inserts may contain incomplete
        externally stored columns. Pretend that such
        records do not exist. Such records may only be
        accessed at the READ UNCOMMITTED isolation
        level or when rolling back a recovered
        transaction. Rollback happens at a lower
        level, not here. */
        goto next_rec;
      }

      /* If we are filling a server-provided buffer, and the
      server has pushed down an end range condition, evaluate
      the condition to prevent that we read too many rows. */
      if (record_buffer != nullptr &&
          prebuilt->m_mysql_handler->end_range != nullptr) {
        /* If the end-range condition refers to a
        virtual column and we are reading from the
        clustered index, next_buf does not have the
        value of the virtual column. Get the offsets in
        the secondary index so that we can read the
        virtual column from the index. */
        if (clust_templ_for_sec &&
            prebuilt->m_mysql_handler->m_virt_gcol_in_end_range) {
          if (sec_offsets == nullptr) {
            rec_offs_init(sec_offsets_);
            sec_offsets = sec_offsets_;
          }
          sec_offsets =
              rec_get_offsets(rec, index, sec_offsets, ULINT_UNDEFINED,
                              UT_LOCATION_HERE, &heap);
        }

        if (row_search_end_range_check(next_buf, rec, prebuilt,
                                       clust_templ_for_sec, sec_offsets,
                                       record_buffer)) {
          if (next_buf != buf) {
            record_buffer->remove_last();
          }
          next_buf = prev_buf;
          err = DB_RECORD_NOT_FOUND;
          goto normal_return;
        }
      }

      if (next_buf != buf) {
        row_sel_enqueue_cache_row_for_mysql(next_buf, prebuilt);
      }
    } else {
      row_sel_enqueue_cache_row_for_mysql(buf, prebuilt);
    }

    if (prebuilt->n_fetch_cached < max_rows_to_cache) {
      goto next_rec;
    }

  } else {
    /* We cannot use a record buffer for this scan, so assert that
    we don't have one. If we have a record buffer here,
    ha_innobase::is_record_buffer_wanted() should be updated so
    that a buffer is not allocated unnecessarily. */
    ut_ad(record_buffer == nullptr);

    if (UNIV_UNLIKELY(prebuilt->template_type == ROW_MYSQL_DUMMY_TEMPLATE)) {
      /* CHECK TABLE: fetch the row */

      if (result_rec != rec && !prebuilt->need_to_access_clustered) {
        /* We used 'offsets' for the clust
        rec, recalculate them for 'rec' */
        offsets = rec_get_offsets(rec, index, offsets, ULINT_UNDEFINED,
                                  UT_LOCATION_HERE, &heap);
        result_rec = rec;
      }

      memcpy(buf + 4, result_rec - rec_offs_extra_size(offsets),
             rec_offs_size(offsets));
      mach_write_to_4(buf, rec_offs_extra_size(offsets) + 4);
    } else if (!prebuilt->idx_cond && !prebuilt->innodb_api) {
      /* The record was not yet converted to MySQL format. */
      if (!row_sel_store_mysql_rec(
              buf, prebuilt, result_rec, vrow, result_rec != rec,
              result_rec != rec ? clust_index : index, prebuilt->index, offsets,
              false, prebuilt->get_lob_undo(), prebuilt->blob_heap)) {
        /* Only fresh inserts may contain
        incomplete externally stored
        columns. Pretend that such records do
        not exist. Such records may only be
        accessed at the READ UNCOMMITTED
        isolation level or when rolling back a
        recovered transaction. Rollback
        happens at a lower level, not here. */
        goto next_rec;
      }
    }

    if (prebuilt->clust_index_was_generated) {
      row_sel_store_row_id_to_prebuilt(prebuilt, result_rec,
                                       result_rec == rec ? index : clust_index,
                                       offsets);
    }
  }

  /* From this point on, 'offsets' are invalid. */

  /* We have an optimization to save CPU time: if this is a consistent
  read on a unique condition on the clustered index, then we do not
  store the pcur position, because any fetch next or prev will anyway
  return 'end of file'. Exceptions are locking reads and the MySQL
  HANDLER command where the user can move the cursor with PREV or NEXT
  even after a unique search. */

  err = DB_SUCCESS;

idx_cond_failed:
  if (!unique_search || !index->is_clustered() || direction != 0 ||
      prebuilt->select_lock_type != LOCK_NONE || prebuilt->used_in_HANDLER ||
      prebuilt->innodb_api) {
    /* Inside an update always store the cursor position */

    if (!spatial_search) {
      pcur->store_position(&mtr);
    }

    if (prebuilt->innodb_api && (pcur->get_rec() != result_rec)) {
      ulint rec_size = rec_offs_size(offsets);
      if (!prebuilt->innodb_api_rec_size ||
          (prebuilt->innodb_api_rec_size < rec_size)) {
        prebuilt->innodb_api_buf = static_cast<byte *>(
            mem_heap_alloc(prebuilt->cursor_heap, rec_size));
        prebuilt->innodb_api_rec_size = rec_size;
      }
      prebuilt->innodb_api_rec =
          rec_copy(prebuilt->innodb_api_buf, result_rec, offsets);
    }
  }

  goto normal_return;

next_rec:

  if (end_loop >= 99 && need_vrow && vrow == nullptr && prev_rec != nullptr) {
    if (!heap) {
      heap = mem_heap_create(100, UT_LOCATION_HERE);
    }

    prev_vrow = nullptr;
    row_sel_fill_vrow(prev_rec, index, &prev_vrow, heap);
  } else {
    prev_vrow = vrow;
  }

  end_loop++;

  /* Reset the old and new "did semi-consistent read" flags. */
  if (UNIV_UNLIKELY(prebuilt->row_read_type == ROW_READ_DID_SEMI_CONSISTENT)) {
    prebuilt->row_read_type = ROW_READ_TRY_SEMI_CONSISTENT;
  }
  did_semi_consistent_read = false;
  prebuilt->new_rec_lock.reset();

  vrow = nullptr;

  /*-------------------------------------------------------------*/
  /* PHASE 5: Move the cursor to the next index record */

  /* NOTE: For moves_up==false, the mini-transaction will be
  committed and restarted every time when switching b-tree
  pages. For moves_up==true in index condition pushdown, we can
  scan an entire secondary index tree within a single
  mini-transaction. As long as the prebuilt->idx_cond does not
  match, we do not need to consult the clustered index or
  return records to MySQL, and thus we can avoid repositioning
  the cursor. What prevents us from buffer-fixing all leaf pages
  within the mini-transaction is the btr_leaf_page_release()
  call in btr_pcur::move_to_next_page(). Only the leaf page where
  the cursor is positioned will remain buffer-fixed.
  For R-tree spatial search, we also commit the mini-transaction
  each time  */

  if (mtr_has_extra_clust_latch || spatial_search) {
    /* If we have extra cluster latch, we must commit
    mtr if we are moving to the next non-clustered
    index record, because we could break the latching
    order if we would access a different clustered
    index page right away without releasing the previous. */

    bool is_pcur_rec = (pcur->get_rec() == prev_rec);

    /* No need to do store restore for R-tree */
    if (!spatial_search) {
      pcur->store_position(&mtr);
    }

    mtr_commit(&mtr);
    mtr_has_extra_clust_latch = false;

    DEBUG_SYNC_C("row_search_before_mtr_restart_for_extra_clust");

    mtr_start(&mtr);

    if (!spatial_search) {
      const auto result = sel_restore_position_for_mysql(
          &same_user_rec, BTR_SEARCH_LEAF, pcur, moves_up, &mtr);

      if (result) {
        prev_rec = nullptr;
        goto rec_loop;
      }

      ut_ad(same_user_rec);

      if (is_pcur_rec && pcur->get_rec() != prev_rec) {
        /* prev_rec is invalid. */
        prev_rec = nullptr;
      }

#ifdef UNIV_DEBUG
      if (prev_rec != nullptr && prev_rec_debug != nullptr) {
        const ulint *offsets1;
        const ulint *offsets2;

        auto heap_tmp = mem_heap_create(256, UT_LOCATION_HERE);

        offsets1 = rec_get_offsets(prev_rec_debug, index, nullptr,
                                   prev_rec_debug_n_fields, UT_LOCATION_HERE,
                                   &heap_tmp);

        offsets2 =
            rec_get_offsets(prev_rec, index, nullptr, prev_rec_debug_n_fields,
                            UT_LOCATION_HERE, &heap_tmp);

        ut_ad(!cmp_rec_rec(prev_rec_debug, prev_rec, offsets1, offsets2, index,
                           page_is_spatial_non_leaf(prev_rec, index), nullptr,
                           false));
        mem_heap_free(heap_tmp);
      }
#endif /* UNIV_DEBUG */
    }
  }

  if (moves_up) {
    bool move;

    if (spatial_search) {
      move = rtr_pcur_move_to_next(search_tuple, mode, prebuilt->select_mode,
                                   pcur, 0, &mtr);
    } else {
      move = pcur->move_to_next(&mtr);
    }

    if (!move) {
    not_moved:
      if (!spatial_search) {
        pcur->store_position(&mtr);
      }

      if (match_mode != 0) {
        err = DB_RECORD_NOT_FOUND;
      } else {
        err = DB_END_OF_INDEX;
      }

      goto normal_return;
    }
  } else {
    if (UNIV_UNLIKELY(!pcur->move_to_prev(&mtr))) {
      goto not_moved;
    }
  }

  goto rec_loop;

lock_wait_or_error:
  /* Reset the old and new "did semi-consistent read" flags. */
  if (UNIV_UNLIKELY(prebuilt->row_read_type == ROW_READ_DID_SEMI_CONSISTENT)) {
    prebuilt->row_read_type = ROW_READ_TRY_SEMI_CONSISTENT;
  }
  did_semi_consistent_read = false;

  /*-------------------------------------------------------------*/
  if (!dict_index_is_spatial(index)) {
    pcur->store_position(&mtr);
  }

lock_table_wait:
  mtr_commit(&mtr);
  mtr_has_extra_clust_latch = false;

  trx->error_state = err;

  /* The following is a patch for MySQL */

  if (thr->is_active) {
    que_thr_stop_for_mysql(thr);
  }

  thr->lock_state = QUE_THR_LOCK_ROW;

  if (row_mysql_handle_errors(&err, trx, thr, nullptr)) {
    /* It was a lock wait, and it ended */

    thr->lock_state = QUE_THR_LOCK_NOLOCK;
    mtr_start(&mtr);

    /* Table lock waited, go try to obtain table lock
    again */
    if (table_lock_waited) {
      table_lock_waited = false;

      goto wait_table_again;
    }

    if (!dict_index_is_spatial(index)) {
      sel_restore_position_for_mysql(&same_user_rec, BTR_SEARCH_LEAF, pcur,
                                     moves_up, &mtr);
      prev_rec = nullptr;
    }

    if (!same_user_rec && trx->releases_non_matching_rows()) {
      /* Since we were not able to restore the cursor
      on the same user record, we cannot use
      row_prebuilt_t::try_unlock() to unlock any records, and
      we must thus reset the new rec lock info. Since
      in lock0lock.cc we have blocked the inheriting of gap
      X-locks, we actually do not have any new record locks
      set in this case.

      Note that if we were able to restore on the 'same'
      user record, it is still possible that we were actually
      waiting on a delete-marked record, and meanwhile
      it was removed by purge and inserted again by some
      other user. But that is no problem, because in
      rec_loop we will again try to set a lock, and
      new_rec_lock_info in trx will be right at the end. */

      prebuilt->new_rec_lock.reset();
    }

    mode = pcur->m_search_mode;

    goto rec_loop;
  }

  thr->lock_state = QUE_THR_LOCK_NOLOCK;

  goto func_exit;

normal_return:
  /*-------------------------------------------------------------*/
  que_thr_stop_for_mysql_no_error(thr, trx);

  mtr_commit(&mtr);

  /* Rollback blocking transactions from hit list for high priority
  transaction, if any. We should not be holding latches here as
  we are going to rollback the blocking transactions. */
  trx_kill_blocking(trx);

  DEBUG_SYNC_C("row_search_for_mysql_before_return");

  if (prebuilt->idx_cond != 0) {
    /* When ICP is active we don't write to the MySQL buffer
    directly, only to buffers that are enqueued in the pre-fetch
    queue. We need to dequeue the first buffer and copy the contents
    to the record buffer that was passed in by MySQL. */

    if (prebuilt->n_fetch_cached > 0) {
      row_sel_dequeue_cached_row_for_mysql(buf, prebuilt);
      err = DB_SUCCESS;
    }

  } else if (next_buf != nullptr) {
    /* We may or may not have enqueued some buffers to the
    pre-fetch queue, but we definitely wrote to the record
    buffer passed to use by MySQL. */

    DEBUG_SYNC_C("row_search_cached_row");
    err = DB_SUCCESS;
  }

#ifdef UNIV_DEBUG
  if (dict_index_is_spatial(index) && err != DB_SUCCESS &&
      err != DB_END_OF_INDEX && err != DB_INTERRUPTED) {
    rtr_node_path_t *path = pcur->m_btr_cur.rtr_info->path;

    ut_ad(path->empty());
  }
#endif

func_exit:
  trx->op_info = "";

  if (end_range_cache != nullptr) {
    ut::free(end_range_cache);
  }

  if (heap != nullptr) {
    mem_heap_free(heap);
  }

#ifdef UNIV_DEBUG
  if (prev_rec_debug_buf != nullptr) {
    ut::free(prev_rec_debug_buf);
  }
#endif /* UNIV_DEBUG */

  /* Set or reset the "did semi-consistent read" flag on return.
  The flag did_semi_consistent_read is set if and only if
  the record being returned was fetched with a semi-consistent read. */
  ut_ad(prebuilt->row_read_type != ROW_READ_WITH_LOCKS ||
        !did_semi_consistent_read);

  if (prebuilt->row_read_type != ROW_READ_WITH_LOCKS) {
    if (did_semi_consistent_read) {
      prebuilt->row_read_type = ROW_READ_DID_SEMI_CONSISTENT;
    } else {
      prebuilt->row_read_type = ROW_READ_TRY_SEMI_CONSISTENT;
    }
  }

#ifdef UNIV_DEBUG
  {
    btrsea_sync_check check(trx->has_search_latch);

    ut_ad(!sync_check_iterate(check));
  }
#endif /* UNIV_DEBUG */

  DEBUG_SYNC_C("innodb_row_search_for_mysql_exit");

  prebuilt->lob_undo_reset();

  ut_a(!trx->has_search_latch);

  return err;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/row/row0mysql.cc
Function: row_rename_table_for_mysql
dberr_t row_rename_table_for_mysql(const char *old_name, const char *new_name,
                                   const dd::Table *dd_table, trx_t *trx,
                                   bool replay) {
  dict_table_t *table = nullptr;
  bool dict_locked = false;
  dberr_t err = DB_ERROR;
  int retry;

  ut_a(old_name != nullptr);
  ut_a(new_name != nullptr);
  ut_ad(trx_can_be_handled_by_current_thread_or_is_hp_victim(trx));
  ut_ad(trx->state.load(std::memory_order_relaxed) == TRX_STATE_ACTIVE);

  if (srv_force_recovery) {
    ib::info(ER_IB_MSG_995) << MODIFICATIONS_NOT_ALLOWED_MSG_FORCE_RECOVERY;
    return (DB_READ_ONLY);
  }

  trx->op_info = "renaming table";

  const bool old_is_tmp = row_is_mysql_tmp_table_name(old_name);
  const bool new_is_tmp = row_is_mysql_tmp_table_name(new_name);
  THD *thd = trx->mysql_thd;

  dict_locked = trx->dict_operation_lock_mode == RW_X_LATCH;

  /* thd could be NULL if these are FTS AUX tables */
  table = dd_table_open_on_name(thd, nullptr, old_name, dict_locked,
                                DICT_ERR_IGNORE_NONE);
  if (!table) {
    err = DB_TABLE_NOT_FOUND;
    goto funct_exit;

  } else if (table->ibd_file_missing && !dict_table_is_discarded(table)) {
    err = DB_TABLE_NOT_FOUND;

    ib::error(ER_IB_MSG_996) << "Table " << old_name
                             << " does not have an .ibd"
                                " file in the database directory. "
                             << TROUBLESHOOTING_MSG;

    goto funct_exit;
  }

  /* Is a foreign key check running on this table? */
  for (retry = 0; retry < 100 && table->n_foreign_key_checks_running > 0;
       ++retry) {
    row_mysql_unlock_data_dictionary(trx);
    std::this_thread::yield();
    row_mysql_lock_data_dictionary(trx, UT_LOCATION_HERE);
  }

  if (table->n_foreign_key_checks_running > 0) {
    ib::error(ER_IB_MSG_997) << "In ALTER TABLE " << ut_get_name(trx, old_name)
                             << " a FOREIGN KEY check is running. Cannot rename"
                                " table.";
    err = DB_TABLE_IN_FK_CHECK;
    goto funct_exit;
  }

  err = DB_SUCCESS;

  if ((dict_table_has_fts_index(table) ||
       DICT_TF2_FLAG_IS_SET(table, DICT_TF2_FTS_HAS_DOC_ID)) &&
      !dict_tables_have_same_db(old_name, new_name)) {
    err = fts_rename_aux_tables(table, new_name, trx, replay);
  }
  if (err != DB_SUCCESS) {
    if (err == DB_DUPLICATE_KEY) {
      ib::error(ER_IB_MSG_998) << "Possible reasons:";
      ib::error(ER_IB_MSG_999) << "(1) Table rename would cause two"
                                  " FOREIGN KEY constraints to have the same"
                                  " internal name in case-insensitive"
                                  " comparison.";
      ib::error(ER_IB_MSG_1000)
          << "(2) Table " << ut_get_name(trx, new_name)
          << " exists in the InnoDB internal data"
             " dictionary though MySQL is trying to rename"
             " table "
          << ut_get_name(trx, old_name) << " to it.";
      ib::info(ER_IB_MSG_1001) << TROUBLESHOOTING_MSG;
      ib::error(ER_IB_MSG_1002)
          << "If table " << ut_get_name(trx, new_name)
          << " is a temporary table #sql..., then"
             " it can be that there are still queries"
             " running on the table, and it will be dropped"
             " automatically when the queries end. You can"
             " drop the orphaned table inside InnoDB by"
             " creating an InnoDB table with the same name"
             " in another database. Then MySQL thinks"
             " the table exists, and DROP TABLE will"
             " succeed.";
    }
    trx->error_state = DB_SUCCESS;
  } else {
    /* The following call will also rename the .ibd data file if
    the table is stored in a single-table tablespace */

    err = dict_table_rename_in_cache(table, new_name,
                                     !table->refresh_fk && !new_is_tmp);
    if (err != DB_SUCCESS) {
      trx->error_state = DB_SUCCESS;
      goto funct_exit;
    }

    /* In case of copy alter, template db_name and
    table_name should be renamed only for newly
    created table. */
    if (table->vc_templ != nullptr && !new_is_tmp) {
      innobase_rename_vc_templ(table);
    }

    if (!dd_table) {
      goto funct_exit;
    }

    /* We only want to switch off some of the type checking in
    an ALTER TABLE...ALGORITHM=COPY, not in a RENAME. */
    dict_names_t fk_tables;

    THD *thd = current_thd;
    dd::cache::Dictionary_client *client = dd::get_dd_client(thd);
    dd::cache::Dictionary_client::Auto_releaser releaser(client);

    /* If neither the old table, nor the new table is temporary, then it is a
    table rename command. */
    const bool is_rename = (!old_is_tmp && !new_is_tmp);

    /* When table->refresh_fk is true, the foreign keys will be loaded when the
       table is opened. */
    if (is_rename || !table->refresh_fk) {
      if (dict_locked) {
        ut_ad(dict_sys_mutex_own());
        dict_sys_mutex_exit();
      }

      err = dd_table_load_fk(client, new_name, nullptr, table, dd_table, thd,
                             false, !old_is_tmp || trx->check_foreigns,
                             &fk_tables);

      if (dict_locked) {
        dict_sys_mutex_enter();
      }

      if (is_rename) {
        /* Ensure that old renamed table names are not in this list. */
        for (auto it = fk_tables.begin(); it != fk_tables.end();) {
          if (strcmp(*it, old_name) == 0) {
            it = fk_tables.erase(it);
          } else {
            ++it;
          }
        }
      }
    }

    if (err != DB_SUCCESS) {
      if (old_is_tmp) {
        ib::error(ER_IB_MSG_1003)
            << "In ALTER TABLE " << ut_get_name(trx, new_name)
            << " has or is referenced in foreign"
               " key constraints which are not"
               " compatible with the new table"
               " definition.";
      } else {
        ib::error(ER_IB_MSG_1004)
            << "In RENAME TABLE table " << ut_get_name(trx, new_name)
            << " is referenced in foreign key"
               " constraints which are not compatible"
               " with the new table definition.";
      }

      dberr_t error = dict_table_rename_in_cache(table, old_name, false);

      ut_a(error == DB_SUCCESS);
      goto funct_exit;
    }
    /* Check whether virtual column or stored column affects
    the foreign key constraint of the table. */

    if (dict_foreigns_has_s_base_col(table->foreign_set, table)) {
      err = DB_NO_FK_ON_S_BASE_COL;
      dberr_t error = dict_table_rename_in_cache(table, old_name, false);

      ut_a(error == DB_SUCCESS);
      goto funct_exit;
    }

    /* Fill the virtual column set in foreign when
    the table undergoes copy alter operation. */
    dict_mem_table_free_foreign_vcol_set(table);
    dict_mem_table_fill_foreign_vcol_set(table);

    dd_open_fk_tables(fk_tables, dict_locked, thd);
  }

funct_exit:
  if (table != nullptr) {
    dd_table_close(table, thd, nullptr, dict_locked);
  }

  trx->op_info = "";

  return (err);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/row/row0mysql.cc
Function: row_update_for_mysql_using_upd_graph not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/row/row0mysql.cc
Function: row_update_for_mysql_using_upd_graph not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/row/row0mysql.cc
Function: row_update_for_mysql_using_upd_graph not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/row/row0mysql.cc
Function: row_update_for_mysql_using_upd_graph not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/row/row0mysql.cc
Function: row_update_for_mysql_using_upd_graph not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/row/row0mysql.cc
Function: row_update_for_mysql_using_upd_graph not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/row/row0mysql.cc
Function: row_insert_for_mysql_using_ins_graph not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/row/row0mysql.cc
Function: row_insert_for_mysql_using_ins_graph not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/row/row0mysql.cc
Function: row_insert_for_mysql_using_ins_graph not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/row/row0mysql.cc
Function: row_insert_for_mysql_using_ins_graph not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/row/row0mysql.cc
Function: row_insert_for_mysql_using_ins_graph not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/row/row0mysql.cc
Function: row_insert_for_mysql_using_ins_graph not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/include/clone0repl.h
Function: Clone_persist_gtid::get_oldest_trx_no
  trx_id_t get_oldest_trx_no() {
    trx_id_t ret_no = m_gtid_trx_no.load();
    /* Should never be zero. It can be set to max only before
    GTID persister is active and no GTID is persisted. */
    ut_ad(ret_no > 0 || srv_force_recovery >= SRV_FORCE_NO_UNDO_LOG_SCAN);
    if (ret_no == TRX_ID_MAX) {
      ut_ad(!is_thread_active());
      ut_ad(m_num_gtid_mem.load() == 0);
    } else if (m_num_gtid_mem.load() == 0) {
      /* For all transactions that are committed before this function is called
      have their GTID flushed if flush is not in progress. "flush not in
      progress" is sufficient but not necessary condition here. This is mainly
      for cases when there is no GTID and purge doesn't need to wait. */
      if (!m_flush_in_progress.load()) {
        ret_no = TRX_ID_MAX;
      }
    }
    return (ret_no);
  }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/log/log0write.cc
Function: log_writer_wait_on_checkpoint_pessimistic
  return log_writer_wait_on_checkpoint_pessimistic(log, last_write_lsn,
                                                   next_write_lsn);
}

static void log_writer_wait_on_archiver(log_t &log, lsn_t next_write_lsn) {


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/log/log0recv.cc
Function: recv_init_crash_recovery
static void recv_init_crash_recovery() {
  ut_ad(!srv_read_only_mode);
  ut_a(!recv_needed_recovery);

  recv_needed_recovery = true;

  ib::info(ER_IB_MSG_726);
  ib::info(ER_IB_MSG_727);

  recv_sys->dblwr->recover();

  if (srv_force_recovery < SRV_FORCE_NO_LOG_REDO) {
    /* Spawn the background thread to flush dirty pages
    from the buffer pools. */

    srv_threads.m_recv_writer =
        os_thread_create(recv_writer_thread_key, 0, recv_writer_thread);

    srv_threads.m_recv_writer.start();
  }
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/log/log0recv.cc
Function: recv_report_corrupt_log not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/log/log0recv.cc
Function: recv_report_corrupt_log not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/log/log0recv.cc
Function: recv_report_corrupt_log not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/log/log0recv.cc
Function: recv_scan_log_recs not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/log/log0recv.cc
Function: recv_scan_log_recs not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/log/log0recv.cc
Function: recv_scan_log_recs not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/log/log0recv.cc
Function: recv_scan_log_recs not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/log/log0recv.cc
Function: recv_scan_log_recs not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/log/log0recv.cc
Function: recv_scan_log_recs not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/log/log0recv.cc
Function: recv_scan_log_recs not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/log/log0recv.cc
Function: recv_scan_log_recs not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/log/log0recv.cc
Function: recv_scan_log_recs not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/log/log0recv.cc
Function: recv_recovery_from_checkpoint_start
recv_recovery_from_checkpoint_start(). */
bool recv_lsn_checks_on;

/** If the following is true, the buffer pool file pages must be invalidated
after recovery and no ibuf operations are allowed; this becomes true if
the log record hash table becomes too full, and log records must be merged
to file pages already before the recovery is finished: in this case no
ibuf operations are allowed, as they could modify the pages read in the
buffer pool before the pages have been recovered to the up-to-date state.

true means that recovery is running and no operations on the log files
are allowed yet: the variable name is misleading. */
bool recv_no_ibuf_operations;

/** true When the redo log is being backed up */
bool recv_is_making_a_backup = false;

/** true when recovering from a backed up redo log file */
bool recv_is_from_backup = false;

/** The following counter is used to decide when to print info on
log scan */
static ulint recv_scan_print_counter;

/** The type of the previous parsed redo log record */
static mlog_id_t recv_previous_parsed_rec_type;

/** The offset of the previous parsed redo log record */
static ulint recv_previous_parsed_rec_offset;

/** The 'multi' flag of the previous parsed redo log record */
static ulint recv_previous_parsed_rec_is_multi;

/** This many frames must be left free in the buffer pool when we scan
the log and store the scanned log records in the buffer pool: we will
use these free frames to read in pages when we start applying the
log records to the database.
This is the default value. If the actual size of the buffer pool is
larger than 10 MB we'll set this value to 512. */
ulint recv_n_pool_free_frames;

/** The maximum lsn we see for a page during the recovery process. If this
is bigger than the lsn we are able to scan up to, that is an indication that
the recovery failed and the database may be corrupt. */
static lsn_t recv_max_page_lsn;

#ifndef UNIV_HOTBACKUP
#ifdef UNIV_PFS_THREAD
mysql_pfs_key_t recv_writer_thread_key;
#endif /* UNIV_PFS_THREAD */

static bool recv_writer_is_active() {
  return srv_thread_is_active(srv_threads.m_recv_writer);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/log/log0log.cc
Function: log_sys_check_format
static dberr_t log_sys_check_format(const log_t &log) {
  switch (log.m_format) {
    case Log_format::LEGACY:
      ib::error(ER_IB_MSG_LOG_FORMAT_BEFORE_5_7_9,
                ulong{to_int(Log_format::LEGACY)});
      return DB_ERROR;

    case Log_format::VERSION_5_7_9:
    case Log_format::VERSION_8_0_1:
    case Log_format::VERSION_8_0_3:
    case Log_format::VERSION_8_0_19:
    case Log_format::VERSION_8_0_28:
      ib::info(ER_IB_MSG_LOG_FORMAT_BEFORE_8_0_30, ulong{to_int(log.m_format)});
      break;

    case Log_format::CURRENT:
      break;

    default:
      /* The log_files_find_and_analyze() would return error if format
      was invalid, and InnoDB would quit in log_sys_init() before
      calling this function. */
      ut_error;
  }

  if (log.m_format < Log_format::CURRENT && srv_force_recovery != 0) {
    /* We say no to running with forced recovery and old format.
    User should rather use previous version of MySQL and recover
    properly before he switches to newer version. */
    const auto directory = log_directory_path(log.m_files_ctx);
    ib::error(ER_IB_MSG_LOG_UPGRADE_FORCED_RECV, ulong{to_int(log.m_format)});
    return DB_ERROR;
  }

  return DB_SUCCESS;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/log/log0log.cc
Function: log_sys_init
dberr_t log_sys_init(bool expect_no_files, lsn_t flushed_lsn,
                     lsn_t &new_files_lsn) {
  ut_a(log_is_data_lsn(flushed_lsn));
  ut_a(log_sys == nullptr);

  new_files_lsn = 0;

  Log_files_context log_files_ctx{srv_log_group_home_dir,
                                  Log_files_ruleset::PRE_8_0_30};

  std::string root_path;
  bool found_files_in_root{false};
  dberr_t err =
      log_sys_check_directory(log_files_ctx, root_path, found_files_in_root);

  /* Report error if innodb_log_group_home_dir / datadir has not been found or
  could not be listed. It's a proper decision for all redo format versions:
    - older formats store there ib_logfile* files directly,
    - newer formats store there #innodb_redo subdirectory. */
  if (err != DB_SUCCESS) {
    ib::error(ER_IB_MSG_LOG_INIT_DIR_LIST_FAILED, root_path.c_str());
    return err;
  }

  Log_file_handle::s_on_before_read = [](Log_file_id, Log_file_type file_type,
                                         os_offset_t, os_offset_t read_size) {
    ut_a(file_type == Log_file_type::NORMAL);
    ut_a(srv_is_being_started);
#ifndef UNIV_HOTBACKUP
    srv_stats.data_read.add(read_size);
#endif /* !UNIV_HOTBACKUP */
  };

  Log_file_handle::s_on_before_write =
      [](Log_file_id file_id, Log_file_type file_type, os_offset_t write_offset,
         os_offset_t write_size) {
        ut_a(!srv_read_only_mode);
        if (!srv_is_being_started) {
          ut_a(log_sys != nullptr);
          auto file = log_sys->m_files.file(file_id);
          if (file_type == Log_file_type::NORMAL) {
            ut_a(file != log_sys->m_files.end());
            ut_a((file_id == log_sys->m_current_file.m_id &&
                  write_offset + write_size <= file->m_size_in_bytes) ||
                 write_offset + write_size <= LOG_FILE_HDR_SIZE);
          } else {
            ut_a(file == log_sys->m_files.end());
            ut_a(file_id == log_sys->m_current_file.next_id());
          }
        }
#ifndef UNIV_HOTBACKUP
        srv_stats.data_written.add(write_size);
#endif
      };

#ifndef _WIN32
  Log_file_handle::s_skip_fsyncs =
      (srv_unix_file_flush_method == SRV_UNIX_O_DSYNC ||
       srv_unix_file_flush_method == SRV_UNIX_NOSYNC);
#endif /* !_WIN32 */

  if (!found_files_in_root) {
    log_files_ctx =
        Log_files_context{srv_log_group_home_dir, Log_files_ruleset::CURRENT};

    std::string subdir_path;
    bool found_files_in_subdir{false};
    err = log_sys_check_directory(log_files_ctx, subdir_path,
                                  found_files_in_subdir);

    switch (err) {
      case DB_SUCCESS:
        if (expect_no_files && found_files_in_subdir) {
          ib::error(ER_IB_MSG_LOG_INIT_DIR_NOT_EMPTY_WONT_INITIALIZE,
                    subdir_path.c_str());
          return DB_ERROR;
        }
        if (!srv_read_only_mode) {
          /* The problem is that a lot of people is not aware
          that sending SHUTDOWN command does not end when the
          server is no longer running, but earlier (obvious!).
          Starting MySQL without waiting on previous instance
          stopped, seems a bad idea and it often led to
          quick failures here if we did not retry. */
          for (size_t retries = 0;; ++retries) {
            const auto remove_unused_files_ret =
                log_remove_unused_files(log_files_ctx);
            if (remove_unused_files_ret.first == DB_SUCCESS) {
              break;
            }
            ut_a(retries < 300);
            std::this_thread::sleep_for(std::chrono::seconds(1));
          }
        }
        break;
      case DB_NOT_FOUND:
        /* The #innodb_redo directory has not been found. */
        if (expect_no_files) {
          /* InnoDB needs to create new directory #innodb_redo. */
          if (!os_file_create_directory(subdir_path.c_str(), false)) {
            return DB_ERROR;
          }
        } else {
          /* InnoDB does not start if neither ib_logfile* files were found,
          nor the #innodb_redo directory was found. User should be informed
          about the problem and decide to either:
            - use older version of MySQL (<= 8.0.29) and do a non-fast shutdown,
            - or create the missing #innodb_redo */
          ib::error(ER_IB_MSG_LOG_INIT_DIR_MISSING_SUBDIR, LOG_DIRECTORY_NAME,
                    log_pre_8_0_30::FILE_BASE_NAME, root_path.c_str());
          return DB_ERROR;
        }
        break;
      default:
        ib::error(ER_IB_MSG_LOG_INIT_DIR_LIST_FAILED, subdir_path.c_str());
        return err;
    }

  } else {
    /* Found existing files in old location for redo files (PRE_8_0_30).
    If expected to see no files (and create new), return error emitting
    the error message. */
    if (expect_no_files) {
      ib::error(ER_IB_MSG_LOG_INIT_DIR_NOT_EMPTY_WONT_INITIALIZE,
                root_path.c_str());
      return DB_ERROR;
    }
  }

  log_sys_create();
  ut_a(log_sys != nullptr);
  log_t &log = *log_sys;

  bool is_concurrency_margin_safe;
  log_concurrency_margin(
      Log_files_capacity::soft_logical_capacity_for_hard(
          Log_files_capacity::hard_logical_capacity_for_physical(
              srv_redo_log_capacity_used)),
      is_concurrency_margin_safe);

  if (!is_concurrency_margin_safe) {
    os_offset_t min_redo_log_capacity = srv_redo_log_capacity_used;
    os_offset_t max_redo_log_capacity = LOG_CAPACITY_MAX;
    while (min_redo_log_capacity < max_redo_log_capacity) {
      const os_offset_t capacity_to_check =
          (min_redo_log_capacity + max_redo_log_capacity) / 2;

      log_concurrency_margin(
          Log_files_capacity::soft_logical_capacity_for_hard(
              Log_files_capacity::hard_logical_capacity_for_physical(
                  capacity_to_check)),
          is_concurrency_margin_safe);

      if (is_concurrency_margin_safe) {
        max_redo_log_capacity = capacity_to_check;
      } else {
        min_redo_log_capacity = capacity_to_check + 1;
      }
    }

    /* The innodb_redo_log_capacity is always rounded to 1M */
    min_redo_log_capacity =
        ut_uint64_align_up(min_redo_log_capacity, 1024UL * 1024);

    ib::error(ER_IB_MSG_LOG_PARAMS_CONCURRENCY_MARGIN_UNSAFE,
              ulonglong{srv_redo_log_capacity_used / 1024 / 1024},
              ulong{srv_thread_concurrency},
              ulonglong{min_redo_log_capacity / 1024 / 1024},
              INNODB_PARAMETERS_MSG);

    return DB_ERROR;
  }

  log.m_files_ctx = std::move(log_files_ctx);

  if (expect_no_files) {
    ut_a(srv_force_recovery < SRV_FORCE_NO_LOG_REDO);
    ut_a(!srv_read_only_mode);

    ut_a(log.m_files_ctx.m_files_ruleset == Log_files_ruleset::CURRENT);

    new_files_lsn = flushed_lsn;
    return log_files_create(log, flushed_lsn);
  }

  if (srv_force_recovery >= SRV_FORCE_NO_LOG_REDO) {
    return DB_SUCCESS;
  }

  Log_files_dict files{log.m_files_ctx};
  Log_format format;
  std::string creator_name;
  Log_flags log_flags;
  Log_uuid log_uuid;

  ut_a(srv_force_recovery < SRV_FORCE_NO_LOG_REDO);

  auto res = log_files_find_and_analyze(
      srv_read_only_mode, log.m_encryption_metadata, files, format,
      creator_name, log_flags, log_uuid);
  switch (res) {
    case Log_files_find_result::FOUND_VALID_FILES:
      log.m_format = format;
      log.m_creator_name = creator_name;
      log.m_log_flags = log_flags;
      log.m_log_uuid = log_uuid;
      log.m_files = std::move(files);
      break;

    case Log_files_find_result::FOUND_UNINITIALIZED_FILES:
      ut_a(format == Log_format::CURRENT);
      [[fallthrough]];
    case Log_files_find_result::FOUND_NO_FILES:
      ut_a(log.m_files_ctx.m_files_ruleset == Log_files_ruleset::CURRENT);
      ut_a(files.empty());

      if (srv_read_only_mode) {
        ut_a(srv_force_recovery < SRV_FORCE_NO_LOG_REDO);
        ib::error(ER_IB_MSG_LOG_FILES_CREATE_AND_READ_ONLY_MODE);
        return DB_ERROR;
      }

      {
        const auto ret = log_remove_files(log.m_files_ctx);
        ut_a(ret.first == DB_SUCCESS);
      }
      new_files_lsn =
          flushed_lsn % OS_FILE_LOG_BLOCK_SIZE == LOG_BLOCK_HDR_SIZE
              ? flushed_lsn
              : ut_uint64_align_up(flushed_lsn, OS_FILE_LOG_BLOCK_SIZE) +
                    LOG_BLOCK_HDR_SIZE;
      return log_files_create(log, new_files_lsn);

    case Log_files_find_result::SYSTEM_ERROR:
    case Log_files_find_result::FOUND_CORRUPTED_FILES:
    case Log_files_find_result::FOUND_DISABLED_FILES:
    case Log_files_find_result::FOUND_VALID_FILES_BUT_MISSING_NEWEST:
      return DB_ERROR;
  }

  /* Check format of the redo log and emit information to the error log,
  if the format was not the newest one. */
  err = log_sys_check_format(log);
  if (err != DB_SUCCESS) {
    return err;
  }

  /* Check creator of log files and mark fields of recv_sys: is_cloned_db,
  is_meb_db if needed. */
  err = log_sys_handle_creator(log);
  if (err != DB_SUCCESS) {
    return err;
  }

  if (log_file_header_check_flag(log_flags, LOG_HEADER_FLAG_NO_LOGGING)) {
    auto result = mtr_t::s_logging.disable(nullptr);
    /* Currently never fails. */
    ut_a(result == 0);
    srv_redo_log = false;
  }

  return DB_SUCCESS;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/log/log0encryption.cc
Function: log_encryption_read
dberr_t log_encryption_read(log_t &log) {
  return log_encryption_read(log, *log_encryption_file(log));
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/log/log0ddl.cc
Function: Log_DDL::recover
dberr_t Log_DDL::recover() {
  if (srv_read_only_mode || srv_force_recovery > 0) {
    return (DB_SUCCESS);
  }

  ib::info(ER_IB_MSG_662) << "DDL log recovery : begin";

  thread_local_ddl_log_replay = true;
  s_in_recovery = true;

  dberr_t err = replay_all();

  thread_local_ddl_log_replay = false;
  s_in_recovery = false;

  ib::info(ER_IB_MSG_663) << "DDL log recovery : end";

  return (err);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/log/log0ddl.cc
Function: Log_DDL::post_ddl
dberr_t Log_DDL::post_ddl(THD *thd) {
  if (skip(nullptr, thd)) {
    return (DB_SUCCESS);
  }

  if (srv_read_only_mode || srv_force_recovery >= SRV_FORCE_NO_UNDO_LOG_SCAN) {
    return (DB_SUCCESS);
  }

  DEBUG_SYNC(thd, "innodb_ddl_log_before_enter");

  DBUG_EXECUTE_IF("ddl_log_before_post_ddl", DBUG_SUICIDE(););

  /* If srv_force_recovery > 0, DROP TABLE is allowed, and here only
  DELETE and DROP log can be replayed. */

  ulint thread_id = thd_get_thread_id(thd);

  if (srv_print_ddl_logs) {
    ib::info(ER_IB_MSG_660)
        << "DDL log post ddl : begin for thread id : " << thread_id;
  }

  thread_local_ddl_log_replay = true;

  dberr_t err = replay_by_thread_id(thread_id);

  thread_local_ddl_log_replay = false;

  if (srv_print_ddl_logs) {
    ib::info(ER_IB_MSG_661)
        << "DDL log post ddl : end for thread id : " << thread_id;
  }

  return (err);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/ibuf/ibuf0ibuf.cc
Function: ibuf_merge_or_delete_for_page
void ibuf_merge_or_delete_for_page(buf_block_t *block, const page_id_t &page_id,
                                   const page_size_t *page_size,
                                   bool update_ibuf_bitmap) {
  mem_heap_t *heap;
  btr_pcur_t pcur;
  dtuple_t *search_tuple;
#ifdef UNIV_IBUF_DEBUG
  ulint volume = 0;
#endif /* UNIV_IBUF_DEBUG */
  page_zip_des_t *page_zip = nullptr;
  fil_space_t *space = nullptr;
  bool corruption_noticed = false;
  bool success;
  mtr_t mtr;

  /* Counts for merged & discarded operations. */
  ulint mops[IBUF_OP_COUNT];
  ulint dops[IBUF_OP_COUNT];

  ut_ad(block == nullptr || page_id == block->page.id);
  ut_ad(block == nullptr || block->page.is_io_fix_read());

  if (srv_force_recovery >= SRV_FORCE_NO_IBUF_MERGE ||
      trx_sys_hdr_page(page_id) || fsp_is_system_temporary(page_id.space())) {
    return;
  }

  /* We cannot refer to page_size in the following, because it is passed
  as NULL (it is unknown) when buf_read_ibuf_merge_pages() is merging
  (discarding) changes for a dropped tablespace. When block != NULL or
  update_ibuf_bitmap is specified, then page_size must be known.
  That is why we will repeat the check below, with page_size in
  place of univ_page_size. Passing univ_page_size assumes that the
  uncompressed page size always is a power-of-2 multiple of the
  compressed page size. */

  if (ibuf_fixed_addr_page(page_id, univ_page_size) ||
      fsp_descr_page(page_id, univ_page_size)) {
    return;
  }

  if (update_ibuf_bitmap) {
    ut_ad(page_size != nullptr);

    if (ibuf_fixed_addr_page(page_id, *page_size) ||
        fsp_descr_page(page_id, *page_size)) {
      return;
    }

    space = fil_space_acquire_silent(page_id.space());

    if (space == nullptr) {
      /* Do not try to read the bitmap page from space;
      just delete the ibuf records for the page */

      block = nullptr;
      update_ibuf_bitmap = false;
    } else {
      page_t *bitmap_page;
      ulint bitmap_bits;

      ibuf_mtr_start(&mtr);

      bitmap_page =
          ibuf_bitmap_get_map_page(page_id, *page_size, UT_LOCATION_HERE, &mtr);

      bitmap_bits = ibuf_bitmap_page_get_bits(bitmap_page, page_id, *page_size,
                                              IBUF_BITMAP_BUFFERED, &mtr);

      ibuf_mtr_commit(&mtr);

      if (!bitmap_bits) {
        /* No inserts buffered for this page */

        fil_space_release(space);
        return;
      }
    }
  } else if (block != nullptr && (ibuf_fixed_addr_page(page_id, *page_size) ||
                                  fsp_descr_page(page_id, *page_size))) {
    return;
  }

  heap = mem_heap_create(512, UT_LOCATION_HERE);

  search_tuple =
      ibuf_search_tuple_build(page_id.space(), page_id.page_no(), heap);

  if (block != nullptr) {
    /* Move the ownership of the x-latch on the page to this OS
    thread, so that we can acquire a second x-latch on it. This
    is needed for the insert operations to the index page to pass
    the debug checks. */

    rw_lock_x_lock_move_ownership(&(block->lock));
    page_zip = buf_block_get_page_zip(block);

    if (!fil_page_index_page_check(block->frame) ||
        !page_is_leaf(block->frame)) {
      corruption_noticed = true;

      ib::error(ER_IB_MSG_624) << "Corruption in the tablespace. Bitmap"
                                  " shows insert buffer records to page "
                               << page_id << " though the page type is "
                               << fil_page_get_type(block->frame)
                               << ", which is not an index leaf page. We try"
                                  " to resolve the problem by skipping the"
                                  " insert buffer merge for this page. Please"
                                  " run CHECK TABLE on your tables to determine"
                                  " if they are corrupt after this.";

      ib::error(ER_IB_MSG_625) << "Please submit a detailed bug"
                                  " report to http://bugs.mysql.com";
      ut_d(ut_error);
    }
  }

  memset(mops, 0, sizeof(mops));
  memset(dops, 0, sizeof(dops));

loop:
  ibuf_mtr_start(&mtr);

  /* Position pcur in the insert buffer at the first entry for this
  index page */
  pcur.open_on_user_rec(ibuf->index, search_tuple, PAGE_CUR_GE, BTR_MODIFY_LEAF,
                        &mtr, UT_LOCATION_HERE);

  if (block != nullptr) {
    auto success = buf_page_get_known_nowait(
        RW_X_LATCH, block, Cache_hint::KEEP_OLD, __FILE__, __LINE__, &mtr);

    ut_a(success);

    /* This is a user page (secondary index leaf page),
    but we pretend that it is a change buffer page in
    order to obey the latching order. This should be OK,
    because buffered changes are applied immediately while
    the block is io-fixed. Other threads must not try to
    latch an io-fixed block. */
    buf_block_dbg_add_level(block, SYNC_IBUF_TREE_NODE);
  }

  if (!pcur.is_on_user_rec()) {
    ut_ad(pcur.is_after_last_in_tree(&mtr));

    goto reset_bit;
  }

  for (;;) {
    rec_t *rec;

    ut_ad(pcur.is_on_user_rec());

    rec = pcur.get_rec();

    /* Check if the entry is for this index page */
    if (ibuf_rec_get_page_no(&mtr, rec) != page_id.page_no() ||
        ibuf_rec_get_space(&mtr, rec) != page_id.space()) {
      if (block != nullptr) {
        page_header_reset_last_insert(block->frame, page_zip, &mtr);
      }

      goto reset_bit;
    }

    if (corruption_noticed) {
      fputs("InnoDB: Discarding record\n ", stderr);
      rec_print_old(stderr, rec);
      fputs("\nInnoDB: from the insert buffer!\n\n", stderr);
    } else if (block != nullptr && !rec_get_deleted_flag(rec, 0)) {
      /* Now we have at pcur a record which should be
      applied on the index page; NOTE that the call below
      copies pointers to fields in rec, and we must
      keep the latch to the rec page until the
      insertion is finished! */
      dtuple_t *entry;
      trx_id_t max_trx_id;
      dict_index_t *dummy_index;
      ibuf_op_t op = ibuf_rec_get_op_type(&mtr, rec);

      max_trx_id = page_get_max_trx_id(page_align(rec));
      page_update_max_trx_id(block, page_zip, max_trx_id, &mtr);

      ut_ad(page_validate(page_align(rec), ibuf->index));

      entry = ibuf_build_entry_from_ibuf_rec(&mtr, rec, heap, &dummy_index);

      ut_ad(page_validate(block->frame, dummy_index));

      switch (op) {
        case IBUF_OP_INSERT:
#ifdef UNIV_IBUF_DEBUG
          volume += rec_get_converted_size(dummy_index, entry);

          volume += page_dir_calc_reserved_space(1);

          ut_a(volume <= 4 * UNIV_PAGE_SIZE / IBUF_PAGE_SIZE_PER_FREE_SPACE);
#endif
          ibuf_insert_to_index_page(entry, block, dummy_index, &mtr);
          break;

        case IBUF_OP_DELETE_MARK:
          ibuf_set_del_mark(entry, block, dummy_index, &mtr);
          break;

        case IBUF_OP_DELETE:
          ibuf_delete(entry, block, dummy_index, &mtr);
          /* Because ibuf_delete() will latch an
          insert buffer bitmap page, commit mtr
          before latching any further pages.
          Store and restore the cursor position. */
          ut_ad(rec == pcur.get_rec());
          ut_ad(page_rec_is_user_rec(rec));
          ut_ad(ibuf_rec_get_page_no(&mtr, rec) == page_id.page_no());
          ut_ad(ibuf_rec_get_space(&mtr, rec) == page_id.space());

          /* Mark the change buffer record processed,
          so that it will not be merged again in case
          the server crashes between the following
          mtr_commit() and the subsequent mtr_commit()
          of deleting the change buffer record. */

          btr_cur_set_deleted_flag_for_ibuf(pcur.get_rec(), nullptr, true,
                                            &mtr);

          pcur.store_position(&mtr);
          ibuf_btr_pcur_commit_specify_mtr(&pcur, &mtr);

          ibuf_mtr_start(&mtr);

          success =
              buf_page_get_known_nowait(RW_X_LATCH, block, Cache_hint::KEEP_OLD,
                                        __FILE__, __LINE__, &mtr);
          ut_a(success);

          /* This is a user page (secondary
          index leaf page), but it should be OK
          to use too low latching order for it,
          as the block is io-fixed. */
          buf_block_dbg_add_level(block, SYNC_IBUF_TREE_NODE);

          if (!ibuf_restore_pos(page_id.space(), page_id.page_no(),
                                search_tuple, BTR_MODIFY_LEAF, &pcur, &mtr)) {
            ut_ad(mtr.has_committed());
            mops[op]++;
            ibuf_dummy_index_free(dummy_index);
            goto loop;
          }

          break;
        default:
          ut_error;
      }

      mops[op]++;

      ibuf_dummy_index_free(dummy_index);
    } else {
      dops[ibuf_rec_get_op_type(&mtr, rec)]++;
    }

    /* Delete the record from ibuf */
    if (ibuf_delete_rec(page_id.space(), page_id.page_no(), &pcur, search_tuple,
                        &mtr)) {
      /* Deletion was pessimistic and mtr was committed:
      we start from the beginning again */

      ut_ad(mtr.has_committed());
      goto loop;
    } else if (pcur.is_after_last_on_page()) {
      ibuf_mtr_commit(&mtr);
      pcur.close();

      goto loop;
    }
  }

reset_bit:
  if (update_ibuf_bitmap) {
    page_t *bitmap_page;

    bitmap_page =
        ibuf_bitmap_get_map_page(page_id, *page_size, UT_LOCATION_HERE, &mtr);

    ibuf_bitmap_page_set_bits(bitmap_page, page_id, *page_size,
                              IBUF_BITMAP_BUFFERED, false, &mtr);

    if (block != nullptr) {
      ulint old_bits = ibuf_bitmap_page_get_bits(
          bitmap_page, page_id, *page_size, IBUF_BITMAP_FREE, &mtr);

      ulint new_bits = ibuf_index_page_calc_free(block);

      if (old_bits != new_bits) {
        ibuf_bitmap_page_set_bits(bitmap_page, page_id, *page_size,
                                  IBUF_BITMAP_FREE, new_bits, &mtr);
      }
    }
  }

  ibuf_mtr_commit(&mtr);
  pcur.close();
  mem_heap_free(heap);

  ibuf->n_merges.fetch_add(1);
  ibuf_add_ops(ibuf->n_merged_ops, mops);
  ibuf_add_ops(ibuf->n_discarded_ops, dops);

  if (space != nullptr) {
    fil_space_release(space);
  }

#ifdef UNIV_IBUF_COUNT_DEBUG
  ut_a(ibuf_count_get(page_id) == 0);
#endif
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/handler0alter.cc
Function: ha_innobase::check_if_supported_inplace_alter
after check_if_supported_inplace_alter()
@param[in]      ha_alter_info   The DDL operation
@return whether it's an instant ALTER TABLE */
static inline bool is_instant(const Alter_inplace_info *ha_alter_info) {
  return (ha_alter_info->handler_trivial_ctx !=
          instant_type_to_int(Instant_Type::INSTANT_IMPOSSIBLE));
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/handler0alter.cc
Function: ha_innopart::exchange_partition_low
int ha_innopart::exchange_partition_low(uint part_id, dd::Table *part_table,
                                        dd::Table *swap_table) {
  DBUG_TRACE;

  ut_ad(part_table != nullptr);
  ut_ad(swap_table != nullptr);
  ut_ad(m_part_share != nullptr);
  ut_ad(dd_table_is_partitioned(*part_table));
  ut_ad(!dd_table_is_partitioned(*swap_table));
  ut_ad(innobase_strcasecmp(part_table->name().c_str(),
                            table_share->table_name.str) == 0);
  ut_ad(part_id < m_tot_parts);
  std::vector<dd::Partition_index *> part_indexes;
  std::vector<dd::Partition_index *>::iterator p_iter;
  std::vector<dd::Index *> swap_indexes;
  std::vector<dd::Index *>::iterator s_iter;
#ifdef UNIV_DEBUG
  std::vector<dd::Index *> part_table_indexes;
  std::vector<dd::Index *>::iterator pt_iter;
#endif

  if (high_level_read_only) {
    my_error(ER_READ_ONLY_MODE, MYF(0));
    return HA_ERR_TABLE_READONLY;
  }

  if (dd_table_has_instant_cols(*part_table) ||
      dd_table_has_instant_cols(*swap_table)) {
    my_error(ER_PARTITION_EXCHANGE_DIFFERENT_OPTION, MYF(0),
             "INSTANT COLUMN(s)");
    return true;
  }

  /* Find the specified dd::Partition object */
  uint id = 0;
  dd::Partition *dd_part = nullptr;
  for (auto part : *part_table->leaf_partitions()) {
    ut_d(dict_table_t *table = m_part_share->get_table_part(id));
    ut_ad(table->n_ref_count == 1);
    ut_ad(!table->is_temporary());

    if (++id > part_id) {
      dd_part = part;
      break;
    }
  }
  ut_ad(dd_part != nullptr);

  if (dd_part->options().exists(index_file_name_key) ||
      swap_table->options().exists(index_file_name_key)) {
    my_error(ER_PARTITION_EXCHANGE_DIFFERENT_OPTION, MYF(0), "INDEX DIRECTORY");
    ut_d(ut_error);
    ut_o(return true);
  }

  /* Get the innodb table objects of part_table and swap_table */
  const table_id_t table_id = swap_table->se_private_id();
  dict_table_t *part = m_part_share->get_table_part(part_id);
  dict_table_t *swap;
  const auto hash_value = ut::hash_uint64(table_id);

  dict_sys_mutex_enter();
  HASH_SEARCH(id_hash, dict_sys->table_id_hash, hash_value, dict_table_t *,
              swap, ut_ad(swap->cached), swap->id == table_id);
  dict_sys_mutex_exit();
  ut_ad(swap != nullptr);
  ut_ad(swap->n_ref_count == 1);

#ifdef UNIV_DEBUG
  /* Store and sort part_table indexes */
  std::copy(part_table->indexes()->begin(), part_table->indexes()->end(),
            std::back_inserter(part_table_indexes));
  std::sort(part_table_indexes.begin(), part_table_indexes.end(),
            [](dd::Index *a, dd::Index *b) { return (a->name() < b->name()); });
#endif
  dd::Object_id p_se_id = dd_part->se_private_id();

  /* Try to rename files. Tablespace checking ensures that
  both partition and table are of implicit tablespace. The plan is:
  1. Rename the swap table to the intermediate file
  2. Rename the partition to the swap table file
  3. Rename the intermediate file of swap table to the partition file */
  THD *thd = m_prebuilt->trx->mysql_thd;
  char *swap_name = strdup(swap->name.m_name);
  char *part_name = strdup(part->name.m_name);

  /* Define the temporary table name, by appending TMP_POSTFIX */
  char temp_name[FN_REFLEN];
  snprintf(temp_name, sizeof temp_name, "%s%s", swap_name,
           dict_name::TMP_POSTFIX);

  int error = 0;
  error = innobase_basic_ddl::rename_impl<dd::Table>(
      thd, swap_name, temp_name, swap_table, swap_table, nullptr);
  if (error != 0) {
    goto func_exit;
  }
  error = innobase_basic_ddl::rename_impl<dd::Partition>(
      thd, part_name, swap_name, dd_part, dd_part, nullptr);
  if (error != 0) {
    goto func_exit;
  }
  error = innobase_basic_ddl::rename_impl<dd::Table>(
      thd, temp_name, part_name, swap_table, swap_table, nullptr);
  if (error != 0) {
    goto func_exit;
  }

  if (dd_part_has_datadir(dd_part) ||
      swap_table->options().exists(data_file_name_key)) {
    /* after above swapping swap is now partition table and part is now normal
    table */
    exchange_partition_adjust_datadir(swap, part);
  }

  std::copy(dd_part->indexes()->begin(), dd_part->indexes()->end(),
            std::back_inserter(part_indexes));
  std::copy(swap_table->indexes()->begin(), swap_table->indexes()->end(),
            std::back_inserter(swap_indexes));

  /* Sort the index pointers according to the index names because the index
  ordanility of the partition being exchanged may be different than the
  table being swapped */
  std::sort(part_indexes.begin(), part_indexes.end(),
            [](dd::Partition_index *a, dd::Partition_index *b) {
              return (a->name() < b->name());
            });
  std::sort(swap_indexes.begin(), swap_indexes.end(),
            [](dd::Index *a, dd::Index *b) { return (a->name() < b->name()); });

  /* Swap the se_private_data and options between indexes.
  The se_private_data should be swapped between every index of
  dd_part and swap_table; however, options should be swapped(checked)
  between part_table and swap_table */
  ut_ad(part_indexes.size() == swap_indexes.size());
  for (p_iter = part_indexes.begin(), s_iter = swap_indexes.begin();
       p_iter < part_indexes.end() && s_iter < swap_indexes.end();
       p_iter++, s_iter++) {
    auto part_index = *p_iter;
    auto swap_index = *s_iter;
    dd::Object_id p_tablespace_id = part_index->tablespace_id();
    part_index->set_tablespace_id(swap_index->tablespace_id());
    swap_index->set_tablespace_id(p_tablespace_id);

    ut_ad(part_index->se_private_data().empty() ==
          swap_index->se_private_data().empty());
    ut_ad(part_index->se_private_data().size() ==
          swap_index->se_private_data().size());

    if (!part_index->se_private_data().empty()) {
      std::unique_ptr<dd::Properties> p_se_data(
          dd::Properties::parse_properties(""));
      p_se_data->insert_values(part_index->se_private_data());
      part_index->se_private_data().clear();
      part_index->set_se_private_data(swap_index->se_private_data());
      swap_index->se_private_data().clear();
      swap_index->set_se_private_data(*p_se_data);
    }
  }
#ifdef UNIV_DEBUG
  for (s_iter = swap_indexes.begin(), pt_iter = part_table_indexes.begin();
       s_iter < swap_indexes.end() && pt_iter < part_table_indexes.end();
       pt_iter++, s_iter++) {
    auto part_table_index = *pt_iter;
    auto swap_index = *s_iter;

    ut_ad(part_table_index->options().raw_string() ==
          swap_index->options().raw_string());
  }
#endif

  /* Swap the se_private_data and options of the two tables.
  Only the max autoinc should be set to both tables */
  if (m_part_share->get_table_share()->found_next_number_field) {
    uint64_t part_autoinc = part->autoinc;
    uint64_t swap_autoinc = swap->autoinc;
    uint64_t max_autoinc = std::max(part_autoinc, swap_autoinc);

    dd_set_autoinc(swap_table->se_private_data(), max_autoinc);
    dd_set_autoinc(
        part_table->se_private_data(),
        std::max<uint64>(swap_autoinc, m_part_share->next_auto_inc_val));

    dict_table_autoinc_lock(part);
    dict_table_autoinc_initialize(part, max_autoinc);
    dict_table_autoinc_unlock(part);

    if (m_part_share->next_auto_inc_val < swap_autoinc) {
      lock_auto_increment();
      m_part_share->next_auto_inc_val = swap_autoinc;
      unlock_auto_increment();
    }
  }

  /* Swap the se_private_id between partition and table */

  dd_part->set_se_private_id(swap_table->se_private_id());
  swap_table->set_se_private_id(p_se_id);

  for (auto dd_column : *swap_table->columns()) {
    dd_column->se_private_data().set(dd_index_key_strings[DD_TABLE_ID],
                                     p_se_id);
  }

  dd_part_adjust_table_id(part_table);

func_exit:
  free(swap_name);
  free(part_name);

  return error;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innopart.cc
Function: ha_innopart::info_low
int ha_innopart::info_low(uint flag, bool is_analyze) {
  dict_table_t *ib_table;
  uint64_t max_rows = 0;
  uint biggest_partition = 0;
  int error = 0;

  DBUG_TRACE;

  /* If we are forcing recovery at a high level, we will suppress
  statistics calculation on tables, because that may crash the
  server if an index is badly corrupted. */

  /* We do not know if MySQL can call this function before calling
  external_lock(). To be safe, update the thd of the current table
  handle. */

  update_thd(ha_thd());

  m_prebuilt->trx->op_info = (char *)"returning various info to MySQL";

  ut_ad(m_part_share->get_table_part(0)->n_ref_count > 0);

  if ((flag & HA_STATUS_TIME) != 0) {
    stats.update_time = 0;

    if (is_analyze) {
      /* Only analyze the given partitions. */
      int error = set_altered_partitions();
      if (error != 0) {
        /* Already checked in mysql_admin_table! */
        ut_d(ut_error);
        ut_o(return error);
      }
    }
    if (is_analyze || innobase_stats_on_metadata) {
      m_prebuilt->trx->op_info = "updating table statistics";
    }

    /* TODO: Only analyze the PK for all partitions,
    then the secondary indexes only for the largest partition! */
    for (uint i = m_part_info->get_first_used_partition(); i < m_tot_parts;
         i = m_part_info->get_next_used_partition(i)) {
      ib_table = m_part_share->get_table_part(i);
      if (is_analyze || innobase_stats_on_metadata) {
        error = update_table_stats(ib_table, is_analyze);
        if (error != 0) {
          m_prebuilt->trx->op_info = "";
          return error;
        }
      }
      stats.update_time = std::max(stats.update_time,
                                   ulong(std::chrono::system_clock::to_time_t(
                                       ib_table->update_time.load())));
    }

    if (is_analyze || innobase_stats_on_metadata) {
      m_prebuilt->trx->op_info = "returning various info to MySQL";
    }
  }

  if ((flag & HA_STATUS_VARIABLE) != 0) {
    /* TODO: If this is called after pruning, then we could
    also update the statistics according to the non-pruned
    partitions, by allocating new rec_per_key on the TABLE,
    instead of using the info from the TABLE_SHARE. */
    ulint stat_clustered_index_size = 0;
    ulint stat_sum_of_other_index_sizes = 0;
    uint64_t n_rows = 0;
    ulint avail_space = 0;
    bool checked_sys_tablespace = false;

    if ((flag & HA_STATUS_VARIABLE_EXTRA) != 0) {
      stats.delete_length = 0;
    }

    for (uint i = m_part_info->get_first_used_partition(); i < m_tot_parts;
         i = m_part_info->get_next_used_partition(i)) {
      ib_table = m_part_share->get_table_part(i);
      if ((flag & HA_STATUS_NO_LOCK) == 0) {
        dict_table_stats_lock(ib_table, RW_S_LATCH);
      }

      ut_ad(ib_table->stat_initialized);

      n_rows += ib_table->stat_n_rows;
      if (ib_table->stat_n_rows > max_rows) {
        max_rows = ib_table->stat_n_rows;
        biggest_partition = i;
      }

      stat_clustered_index_size += ib_table->stat_clustered_index_size;

      stat_sum_of_other_index_sizes += ib_table->stat_sum_of_other_index_sizes;

      if ((flag & HA_STATUS_NO_LOCK) == 0) {
        dict_table_stats_unlock(ib_table, RW_S_LATCH);
      }

      if ((flag & HA_STATUS_VARIABLE_EXTRA) != 0 &&
          (flag & HA_STATUS_NO_LOCK) == 0 &&
          srv_force_recovery < SRV_FORCE_NO_IBUF_MERGE &&
          avail_space != ULINT_UNDEFINED) {
        /* Only count system tablespace once! */
        if (fsp_is_system_or_temp_tablespace(ib_table->space)) {
          if (checked_sys_tablespace) {
            continue;
          }
          checked_sys_tablespace = true;
        }

        uintmax_t space =
            fsp_get_available_space_in_free_extents(ib_table->space);
        if (space == UINTMAX_MAX) {
          THD *thd = ha_thd();
          const char *table_name = ib_table->name.m_name;

          push_warning_printf(thd, Sql_condition::SL_WARNING, ER_CANT_GET_STAT,
                              "InnoDB: Trying to get the"
                              " free space for partition %s"
                              " but its tablespace has been"
                              " discarded or the .ibd file"
                              " is missing. Setting the free"
                              " space of the partition to"
                              " zero.",
                              ut_get_name(m_prebuilt->trx, table_name).c_str());
        } else {
          avail_space += static_cast<ulint>(space);
        }
      }
    }

    /*
    The MySQL optimizer seems to assume in a left join that n_rows
    is an accurate estimate if it is zero. Of course, it is not,
    since we do not have any locks on the rows yet at this phase.
    Since SHOW TABLE STATUS seems to call this function with the
    HA_STATUS_TIME flag set, while the left join optimizer does not
    set that flag, we add one to a zero value if the flag is not
    set. That way SHOW TABLE STATUS will show the best estimate,
    while the optimizer never sees the table empty. */

    if (n_rows == 0 && (flag & HA_STATUS_TIME) == 0) {
      n_rows++;
    }

    /* Fix bug#40386: Not flushing query cache after truncate.
    n_rows can not be 0 unless the table is empty, set to 1
    instead. The original problem of bug#29507 is actually
    fixed in the server code. */
    if (thd_sql_command(m_user_thd) == SQLCOM_TRUNCATE) {
      n_rows = 1;

      /* We need to reset the m_prebuilt value too, otherwise
      checks for values greater than the last value written
      to the table will fail and the autoinc counter will
      not be updated. This will force write_row() into
      attempting an update of the table's AUTOINC counter. */

      m_prebuilt->autoinc_last_value = 0;
    }

    /* Take page_size from first partition. */
    ib_table = m_part_share->get_table_part(0);
    const page_size_t &page_size = dict_table_page_size(ib_table);

    stats.records = (ha_rows)n_rows;
    stats.deleted = 0;
    stats.data_file_length =
        ((ulonglong)stat_clustered_index_size) * page_size.physical();
    stats.index_file_length =
        ((ulonglong)stat_sum_of_other_index_sizes) * page_size.physical();

    /* See ha_innobase::info_low() for comments! */
    if ((flag & HA_STATUS_NO_LOCK) == 0 &&
        (flag & HA_STATUS_VARIABLE_EXTRA) != 0 &&
        srv_force_recovery < SRV_FORCE_NO_IBUF_MERGE) {
      stats.delete_length = avail_space * 1024;
    }

    stats.check_time = 0;
    stats.mrr_length_per_rec =
        ref_length + sizeof(void *) - PARTITION_BYTES_IN_POS;

    if (stats.records == 0) {
      stats.mean_rec_length = 0;
    } else {
      stats.mean_rec_length = (ulong)(stats.data_file_length / stats.records);
    }
  }

  if ((flag & HA_STATUS_CONST) != 0) {
    /* Find max rows and biggest partition. */
    for (uint i = 0; i < m_tot_parts; i++) {
      /* Skip partitions from above. */
      if ((flag & HA_STATUS_VARIABLE) == 0 ||
          !bitmap_is_set(&(m_part_info->read_partitions), i)) {
        ib_table = m_part_share->get_table_part(i);
        if (ib_table->stat_n_rows > max_rows) {
          max_rows = ib_table->stat_n_rows;
          biggest_partition = i;
        }
      }
    }
    ib_table = m_part_share->get_table_part(biggest_partition);
    /* Verify the number of index in InnoDB and MySQL
    matches up. If m_prebuilt->clust_index_was_generated
    holds, InnoDB defines GEN_CLUST_INDEX internally. */
    ulint num_innodb_index = UT_LIST_GET_LEN(ib_table->indexes) -
                             m_prebuilt->clust_index_was_generated;
    if (table->s->keys < num_innodb_index) {
      /* If there are too many indexes defined
      inside InnoDB, ignore those that are being
      created, because MySQL will only consider
      the fully built indexes here. */

      for (const dict_index_t *index : ib_table->indexes) {
        /* First, online index creation is
        completed inside InnoDB, and then
        MySQL attempts to upgrade the
        meta-data lock so that it can rebuild
        the .frm file. If we get here in that
        time frame, dict_index_is_online_ddl()
        would not hold and the index would
        still not be included in TABLE_SHARE. */
        if (!index->is_committed()) {
          num_innodb_index--;
        }
      }

      if (table->s->keys < num_innodb_index &&
          (innobase_fts_check_doc_id_index(ib_table, nullptr, nullptr) ==
           FTS_EXIST_DOC_ID_INDEX)) {
        num_innodb_index--;
      }
    }

    if (table->s->keys != num_innodb_index) {
      ib::error(ER_IB_MSG_595)
          << "Table " << ib_table->name << " contains " << num_innodb_index
          << " indexes inside InnoDB, which"
             " is different from the number of"
             " indexes "
          << table->s->keys << " defined in the MySQL";
    }

    if ((flag & HA_STATUS_NO_LOCK) == 0) {
      dict_table_stats_lock(ib_table, RW_S_LATCH);
    }

    ut_ad(ib_table->stat_initialized);

    for (ulong i = 0; i < table->s->keys; i++) {
      ulong j;
      /* We could get index quickly through internal
      index mapping with the index translation table.
      The identity of index (match up index name with
      that of table->key_info[i]) is already verified in
      innopart_get_index(). */
      dict_index_t *index = innopart_get_index(biggest_partition, i);

      if (index == nullptr) {
        ib::error(ER_IB_MSG_596)
            << "Table " << ib_table->name
            << " contains fewer indexes than expected." << TROUBLESHOOTING_MSG;
        break;
      }

      KEY *key = &table->key_info[i];
      for (j = 0; j < key->actual_key_parts; j++) {
        if ((key->flags & HA_FULLTEXT) != 0) {
          /* The whole concept has no validity
          for FTS indexes. */
          key->set_records_per_key(j, 1.0f);
          continue;
        }

        if ((j + 1) > index->n_uniq) {
          ib::error(ER_IB_MSG_597)
              << "Index " << index->name << " of " << ib_table->name << " has "
              << index->n_uniq
              << " columns unique inside"
                 " InnoDB, but MySQL is"
                 " asking statistics for "
              << j + 1 << " columns." << TROUBLESHOOTING_MSG;
          break;
        }

        /* innodb_rec_per_key() will use
        index->stat_n_diff_key_vals[] and the value we
        pass index->table->stat_n_rows. Both are
        calculated by ANALYZE and by the background
        stats gathering thread (which kicks in when too
        much of the table has been changed). In
        addition table->stat_n_rows is adjusted with
        each DML (e.g. ++ on row insert). Those
        adjustments are not MVCC'ed and not even
        reversed on rollback. So,
        index->stat_n_diff_key_vals[] and
        index->table->stat_n_rows could have been
        calculated at different time. This is
        acceptable. */
        const rec_per_key_t rec_per_key =
            innodb_rec_per_key(index, j, max_rows);

        key->set_records_per_key(j, rec_per_key);
      }
    }

    if ((flag & HA_STATUS_NO_LOCK) == 0) {
      dict_table_stats_unlock(ib_table, RW_S_LATCH);
    }
  }

  if (srv_force_recovery >= SRV_FORCE_NO_IBUF_MERGE) {
    goto func_exit;
  }

  if ((flag & HA_STATUS_ERRKEY) != 0) {
    const dict_index_t *err_index;

    ut_a(m_prebuilt->trx);
    ut_a(m_prebuilt->trx->magic_n == TRX_MAGIC_N);

    err_index = trx_get_error_index(m_prebuilt->trx);

    if (err_index != nullptr) {
      errkey = m_part_share->get_mysql_key(m_last_part, err_index);
    } else {
      errkey =
          (unsigned int)((m_prebuilt->trx->error_key_num == ULINT_UNDEFINED)
                             ? UINT_MAX
                             : m_prebuilt->trx->error_key_num);
    }
  }

  if ((flag & HA_STATUS_AUTO) != 0) {
    /* auto_inc is only supported in first key for InnoDB! */
    ut_ad(table_share->next_number_keypart == 0);
    DBUG_PRINT("info", ("HA_STATUS_AUTO"));
    if (table->found_next_number_field == nullptr) {
      stats.auto_increment_value = 0;
    } else {
      /* Lock to avoid two concurrent initializations. */
      lock_auto_increment();
      if (m_part_share->auto_inc_initialized) {
        stats.auto_increment_value = m_part_share->next_auto_inc_val;
      } else {
        /* The auto-inc mutex in the table_share is
        locked, so we do not need to have the handlers
        locked. */

        error = initialize_auto_increment((flag & HA_STATUS_NO_LOCK) != 0);
        stats.auto_increment_value = m_part_share->next_auto_inc_val;
      }
      unlock_auto_increment();
    }
  }

func_exit:
  m_prebuilt->trx->op_info = (char *)"";

  return error;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innopart.cc
Function: ha_innopart::initialize_auto_increment
inline int ha_innopart::initialize_auto_increment(bool) {
  int error = 0;
  ulonglong auto_inc = 0;
  const Field *field = table->found_next_number_field;

#ifdef UNIV_DEBUG
  if (table_share->tmp_table == NO_TMP_TABLE) {
    mysql_mutex_assert_owner(m_part_share->auto_inc_mutex);
  }
#endif

  /* Since a table can already be "open" in InnoDB's internal
  data dictionary, we only init the autoinc counter once, the
  first time the table is loaded. We can safely reuse the
  autoinc value from a previous MySQL open. */

  if (m_part_share->auto_inc_initialized) {
    /* Already initialized, nothing to do. */
    return (0);
  }

  if (field == nullptr) {
    ib::info(ER_IB_MSG_586) << "Unable to determine the AUTOINC column name";
  }

  if (srv_force_recovery >= SRV_FORCE_NO_IBUF_MERGE) {
    /* If the recovery level is set so high that writes
    are disabled we force the AUTOINC counter to 0
    value effectively disabling writes to the table.
    Secondly, we avoid reading the table in case the read
    results in failure due to a corrupted table/index.

    We will not return an error to the client, so that the
    tables can be dumped with minimal hassle. If an error
    were returned in this case, the first attempt to read
    the table would fail and subsequent SELECTs would succeed. */

  } else if (field == nullptr) {
    /* This is a far more serious error, best to avoid
    opening the table and return failure. */

    my_error(ER_AUTOINC_READ_FAILED, MYF(0));
    error = HA_ERR_AUTOINC_READ_FAILED;
  } else {
    dict_index_t *index;
    const char *col_name;
    uint64_t read_auto_inc;
    uint64_t persisted_auto_inc;
    uint64_t max_auto_inc = 0;
    ulint err;
    dict_table_t *ib_table;
    ulonglong col_max_value;

    col_max_value = field->get_max_int_value();

    update_thd(ha_thd());

    col_name = field->field_name;
    for (uint part = 0; part < m_tot_parts; part++) {
      ib_table = m_part_share->get_table_part(part);

      dict_table_autoinc_set_col_pos(ib_table, field->field_index());

      dict_table_autoinc_lock(ib_table);
      read_auto_inc = dict_table_autoinc_read(ib_table);

      persisted_auto_inc = ib_table->autoinc_persisted;

      /* During startup, we may set both these two autoinc
      to same value after recovery of the counter. In this
      case, it's the first time we initialize the counter
      here, and we have to calculate the next counter.
      Otherwise, if they are not equal, we can use it
      directly. */
      if (read_auto_inc != 0 && read_auto_inc != persisted_auto_inc) {
        /* Sometimes, such as after UPDATE,
        we may have the persisted counter bigger
        than the in-memory one, because UPDATE in
        partition tables still doesn't modify the
        in-memory counter while persisted one could
        be updated if it's updated to larger value. */
        max_auto_inc =
            std::max(max_auto_inc, std::max(read_auto_inc, persisted_auto_inc));
        dict_table_autoinc_unlock(ib_table);
        continue;
      }

      if (persisted_auto_inc == 0) {
        /* Execute SELECT MAX(col_name) FROM TABLE; */
        index = m_part_share->get_index(part, table->s->next_number_index);
        err = row_search_max_autoinc(index, col_name, &read_auto_inc);
      } else {
        /* We have the persisted AUTOINC counter,
        have to calculate the next one. */
        ut_ad(read_auto_inc == persisted_auto_inc);
        err = DB_SUCCESS;
      }

      switch (err) {
        case DB_SUCCESS: {
          /* At the this stage we do not know the
          increment nor the offset,
          so use a default increment of 1. */

          auto_inc =
              innobase_next_autoinc(read_auto_inc, 1, 1, 0, col_max_value);
          max_auto_inc = std::max(max_auto_inc, uint64_t(auto_inc));
          dict_table_autoinc_initialize(ib_table, auto_inc);
          break;
        }
        case DB_RECORD_NOT_FOUND:
          ib::error(ER_IB_MSG_587)
              << "MySQL and InnoDB data"
                 " dictionaries are out of sync. Unable"
                 " to find the AUTOINC column "
              << col_name << " in the InnoDB table " << ib_table->name
              << ". We set the"
                 " next AUTOINC column value to 0, in"
                 " effect disabling the AUTOINC next"
                 " value generation.";

          ib::info(ER_IB_MSG_588) << "You can either set the next"
                                     " AUTOINC value explicitly using ALTER"
                                     " TABLE or fix the data dictionary by"
                                     " recreating the table.";

          /* We want the open to succeed, so that the
          user can take corrective action. ie. reads
          should succeed but updates should fail. */

          /* This will disable the AUTOINC generation. */
          auto_inc = 0;
          goto done;
        default:
          /* row_search_max_autoinc() should only return
          one of DB_SUCCESS or DB_RECORD_NOT_FOUND. */

          ut_error;
      }
      dict_table_autoinc_unlock(ib_table);
    }
    auto_inc = max_auto_inc;
  }

done:
  m_part_share->next_auto_inc_val = auto_inc;
  m_part_share->auto_inc_initialized = true;
  return (error);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innopart.cc
Function: ha_innopart::rename_table
int ha_innopart::rename_table(const char *from, const char *to,
                              const dd::Table *from_table,
                              dd::Table *to_table) {
  THD *thd = ha_thd();
  char norm_from[FN_REFLEN];
  char norm_to[FN_REFLEN];
  int error = 0;

  DBUG_TRACE;

  ut_ad(from_table != nullptr);
  ut_ad(to_table != nullptr);
  ut_ad(from_table->se_private_id() == to_table->se_private_id());
  ut_ad(from_table->se_private_data().raw_string() ==
        to_table->se_private_data().raw_string());
  ut_ad(from_table->partition_type() == to_table->partition_type());

  if (high_level_read_only) {
    ib_senderrf(thd, IB_LOG_LEVEL_WARN, ER_READ_ONLY_MODE);
    return HA_ERR_TABLE_READONLY;
  }

  if (!normalize_table_name(norm_from, from) ||
      !normalize_table_name(norm_to, to)) {
    return (HA_ERR_TOO_LONG_PATH);
  }

  /* Get the transaction associated with the current thd, or create one
  if not yet created */
  trx_t *trx = check_trx_exists(thd);

  trx_start_if_not_started(trx, false, UT_LOCATION_HERE);
  innobase_register_trx(ht, thd, trx);

  TrxInInnoDB trx_in_innodb(trx);
  dd::cache::Dictionary_client *client = dd::get_dd_client(thd);
  dd::cache::Dictionary_client::Auto_releaser releaser(client);

  TABLE_SHARE ts;
  TABLE td;
  error = acquire_uncached_table(thd, client, from_table, norm_from, &ts, &td);
  if (error != 0) {
    return (error);
  }

  auto to_part = to_table->leaf_partitions()->begin();

  for (const auto from_part : from_table->leaf_partitions()) {
    ut_ad((*to_part) != NULL);

    std::string partition;
    /* Build the old partition name. */
    dict_name::build_partition(from_part, partition);

    /* Build the old partitioned table name. */
    std::string from_name;
    dict_name::build_table("", from, partition, false, false, from_name);

    /* Build the new partition name. */
    dict_name::build_partition(*to_part, partition);

    /* Build the new partitioned table name. */
    std::string to_name;
    dict_name::build_table("", to, partition, false, false, to_name);

    if (from_name.length() >= FN_REFLEN || to_name.length() >= FN_REFLEN) {
      ut_d(ut_error);
      ut_o(return HA_ERR_INTERNAL_ERROR);
    }
    error = innobase_basic_ddl::rename_impl(
        thd, from_name.c_str(), to_name.c_str(), from_part, *to_part, &td);
    if (error != 0) {
      break;
    }

    ++to_part;
  }
  release_uncached_table(&ts, &td);
  return error;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innopart.cc
Function: ha_innopart::delete_table
int ha_innopart::delete_table(const char *name, const dd::Table *dd_table) {
  THD *thd = ha_thd();
  trx_t *trx = check_trx_exists(thd);
  char norm_name[FN_REFLEN];
  int error = 0;

  DBUG_TRACE;

  ut_ad(dd_table != nullptr);
  ut_ad(dd_table_is_partitioned(*dd_table));
  ut_ad(dd_table->is_persistent());

  if (high_level_read_only) {
    return HA_ERR_TABLE_READONLY;
  }

  if (!normalize_table_name(norm_name, name)) {
    return (HA_ERR_TOO_LONG_PATH);
  }

  innobase_register_trx(ht, thd, trx);
  TrxInInnoDB trx_in_innodb(trx);

  dd::cache::Dictionary_client *client = dd::get_dd_client(thd);
  dd::cache::Dictionary_client::Auto_releaser releaser(client);

  TABLE_SHARE ts;
  TABLE td;
  error = acquire_uncached_table(thd, client, dd_table, norm_name, &ts, &td);
  if (error != 0) {
    return (error);
  }

  for (const dd::Partition *dd_part : dd_table->leaf_partitions()) {
    std::string partition;
    /* Build the partition name. */
    dict_name::build_partition(dd_part, partition);

    std::string part_table;
    /* Build the partitioned table name. */
    dict_name::build_table("", name, partition, false, false, part_table);

    if (part_table.length() >= FN_REFLEN) {
      ut_d(ut_error);
      ut_o(release_uncached_table(&ts, &td));
      ut_o(return HA_ERR_INTERNAL_ERROR);
    }

    const char *partition_name = part_table.c_str();

    error = innobase_basic_ddl::delete_impl(thd, partition_name, dd_part, &td);

    if (error != 0) {
      break;
    }
  }
  release_uncached_table(&ts, &td);
  return error;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innopart.cc
Function: ha_innopart::truncate_impl
int ha_innopart::truncate_impl(const char *name, TABLE *form,
                               dd::Table *table_def) {
  DBUG_TRACE;

  ut_ad(table_def != nullptr);
  ut_ad(dd_table_is_partitioned(*table_def));
  ut_ad(table_def->is_persistent());

  if (high_level_read_only) {
    return HA_ERR_TABLE_READONLY;
  }

  THD *thd = ha_thd();
  trx_t *trx = check_trx_exists(thd);
  bool has_autoinc = false;
  int error = 0;

  innobase_register_trx(ht, thd, trx);

  const bool is_instant = dd_table_has_instant_cols(*table_def);

  for (const auto dd_part : *table_def->leaf_partitions()) {
    char norm_name[FN_REFLEN];
    dict_table_t *part_table = nullptr;

    std::string partition;
    /* Build the partition name. */
    dict_name::build_partition(dd_part, partition);

    std::string partition_name;
    /* Build the partitioned table name. */
    dict_name::build_table("", name, partition, false, false, partition_name);
    ut_ad(partition_name.length() < FN_REFLEN);

    if (!normalize_table_name(norm_name, partition_name.c_str())) {
      /* purecov: begin inspected */
      ut_d(ut_error);
      ut_o(return (HA_ERR_TOO_LONG_PATH));
      /* purecov: end */
    }

    innobase_truncate<dd::Partition> truncator(thd, norm_name, form, dd_part,
                                               false, true);

    error = truncator.open_table(part_table);
    if (error != 0) {
      return error;
    }

    has_autoinc = dict_table_has_autoinc_col(part_table);

    if (dict_table_is_discarded(part_table)) {
      ib_senderrf(thd, IB_LOG_LEVEL_ERROR, ER_TABLESPACE_DISCARDED, norm_name);
      return HA_ERR_NO_SUCH_TABLE;
    } else if (part_table->ibd_file_missing) {
      return HA_ERR_TABLESPACE_MISSING;
    }

    error = truncator.exec();

    if (error != 0) {
      return error;
    }
  }

  ut_ad(error == 0);

  if (has_autoinc) {
    dd_set_autoinc(table_def->se_private_data(), 0);
  }

  if (is_instant) {
    for (dd::Partition *dd_part : *table_def->leaf_partitions()) {
      if (dd_part_has_instant_cols(*dd_part)) {
        dd_clear_instant_part(*dd_part);
      }
    }

    if (dd_clear_instant_table(*table_def, true) != DB_SUCCESS) {
      error = HA_ERR_GENERIC;
    }
  }

  return error;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innopart.cc
Function: ha_innopart::create
int ha_innopart::create(const char *name, TABLE *form,
                        HA_CREATE_INFO *create_info, dd::Table *table_def) {
  int error;
  /** {database}/{tablename} */
  char table_name[FN_REFLEN];
  /** absolute path of table */
  char remote_path[FN_REFLEN];
  char tablespace_name[NAME_LEN + 1];
  char table_data_file_name[FN_REFLEN];
  char table_level_tablespace_name[NAME_LEN + 1];
  const char *table_index_file_name;
  uint created = 0;
  THD *thd = ha_thd();
  trx_t *trx;

  if (thd_sql_command(thd) == SQLCOM_TRUNCATE) {
    return (truncate_impl(name, form, table_def));
  }

  if (high_level_read_only) {
    return (HA_ERR_INNODB_READ_ONLY);
  }

  trx = check_trx_exists(thd);

  DBUG_TRACE;

  if (is_shared_tablespace(create_info->tablespace)) {
    my_printf_error(ER_ILLEGAL_HA_CREATE_OPTION, PARTITION_IN_SHARED_TABLESPACE,
                    MYF(0));
    return HA_ERR_INTERNAL_ERROR;
  }

  create_table_info_t info(thd, form, create_info, table_name, remote_path,
                           tablespace_name, srv_file_per_table, false, 0, 0,
                           true);

  ut_ad(create_info != nullptr);
  ut_ad(m_part_info == form->part_info);
  ut_ad(table_share != nullptr);

  /* Not allowed to create temporary partitioned tables. */
  if (create_info != nullptr &&
      (create_info->options & HA_LEX_CREATE_TMP_TABLE) != 0) {
    my_error(ER_PARTITION_NO_TEMPORARY, MYF(0));
    ut_d(ut_error);  // Can we support partitioned temporary tables?
    ut_o(return HA_ERR_INTERNAL_ERROR);
  }

  innobase_register_trx(ht, thd, trx);

  if (form->found_next_number_field) {
    dd_set_autoinc(table_def->se_private_data(),
                   create_info->auto_increment_value);
  }

  error = info.initialize();
  if (error != 0) {
    return error;
  }

  /* Setup and check table level options. */
  error = info.prepare_create_table(name);
  if (error != 0) {
    return error;
  }

  /* Save the original table name before adding partition information. */
  const std::string saved_table_name(table_name);

  if (create_info->data_file_name != nullptr) {
    /* Strip the tablename from the path. */
    strncpy(table_data_file_name, create_info->data_file_name, FN_REFLEN - 1);
    table_data_file_name[FN_REFLEN - 1] = '\0';
    char *ptr = strrchr(table_data_file_name, OS_PATH_SEPARATOR);
    ut_ad(ptr != nullptr);
    if (ptr != nullptr) {
      ptr++;
      *ptr = '\0';
      create_info->data_file_name = table_data_file_name;
    }
  } else {
    table_data_file_name[0] = '\0';
  }
  table_index_file_name = create_info->index_file_name;
  if (create_info->tablespace != nullptr) {
    strcpy(table_level_tablespace_name, create_info->tablespace);
  } else {
    table_level_tablespace_name[0] = '\0';
  }

  /* It's also doable to get tablespace names by accessing
  dd::Tablespace::name according to dd_part->tablespace_id().
  However, it costs more. So as long as partition_element contains
  tablespace name, it's easier to check it */
  std::vector<const char *> tablespace_names;
  List_iterator_fast<partition_element> part_it(form->part_info->partitions);
  partition_element *part_elem;
  for (part_elem = part_it++; part_elem != nullptr; part_elem = part_it++) {
    const char *tablespace;
    if (form->part_info->is_sub_partitioned()) {
      List_iterator_fast<partition_element> sub_it(part_elem->subpartitions);
      partition_element *sub_elem;
      for (sub_elem = sub_it++; sub_elem != nullptr; sub_elem = sub_it++) {
        tablespace = partition_get_tablespace(table_level_tablespace_name,
                                              part_elem, sub_elem);
        if (is_shared_tablespace(tablespace)) {
          tablespace_names.clear();
          error = HA_ERR_INTERNAL_ERROR;
          break;
        }
        tablespace_names.push_back(tablespace);
      }
    } else {
      tablespace = partition_get_tablespace(table_level_tablespace_name,
                                            part_elem, nullptr);
      if (is_shared_tablespace(tablespace)) {
        tablespace_names.clear();
        error = HA_ERR_INTERNAL_ERROR;
        break;
      }
      tablespace_names.push_back(tablespace);
    }
  }

  if (error) {
    my_printf_error(ER_ILLEGAL_HA_CREATE_OPTION, PARTITION_IN_SHARED_TABLESPACE,
                    MYF(0));
    return error;
  }

  for (const auto dd_part : *table_def->leaf_partitions()) {
    std::string partition;
    /* Build the partition name. */
    dict_name::build_partition(dd_part, partition);

    std::string part_table;
    /* Build the partitioned table name. */
    dict_name::build_table("", saved_table_name, partition, false, false,
                           part_table);

    if (part_table.length() + 1 >= FN_REFLEN - 1) {
      error = HA_ERR_INTERNAL_ERROR;
      my_error(ER_PATH_LENGTH, MYF(0), part_table.c_str());
      break;
    }

    const dd::Properties &options = dd_part->options();
    dd::String_type index_file_name;
    dd::String_type data_file_name;
    const char *tablespace_name;

    if (options.exists(index_file_name_key))
      (void)options.get(index_file_name_key, &index_file_name);
    if (options.exists(data_file_name_key))
      (void)options.get(data_file_name_key, &data_file_name);
    ut_ad(created < tablespace_names.size());
    tablespace_name = tablespace_names[created];

    if (!data_file_name.empty()) {
      create_info->data_file_name = data_file_name.c_str();
    }

    if (!index_file_name.empty()) {
      create_info->index_file_name = index_file_name.c_str();
    }

    if (!data_file_name.empty() &&
        dd_part->tablespace_id() == dd::INVALID_OBJECT_ID &&
        (tablespace_name == nullptr ||
         strcmp(tablespace_name, dict_sys_t::s_file_per_table_name) != 0)) {
      create_info->tablespace = nullptr;
    } else {
      create_info->tablespace = tablespace_name;
    }
    info.flags_reset();
    info.flags2_reset();

    if ((error = info.prepare_create_table(part_table.c_str())) != 0) {
      break;
    }

    info.set_remote_path_flags();

    if ((error = info.create_table(&dd_part->table(), nullptr)) != 0) {
      break;
    }

    if ((error = info.create_table_update_global_dd<dd::Partition>(
             const_cast<dd::Partition *>(dd_part))) != 0) {
      break;
    }

    if ((error = info.create_table_update_dict()) != 0) {
      break;
    }

    info.detach();

    ++created;
    create_info->data_file_name = table_data_file_name;
    create_info->index_file_name = table_index_file_name;
    create_info->tablespace = table_level_tablespace_name;
  }

  create_info->data_file_name = nullptr;
  create_info->index_file_name = nullptr;
  create_info->tablespace = nullptr;

  return error;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innopart.cc
Function: ha_innopart::truncate_partition_low
int ha_innopart::truncate_partition_low(dd::Table *dd_table) {
  int error = 0;
  const char *table_name = table->s->normalized_path.str;
  THD *thd = ha_thd();
  trx_t *trx = check_trx_exists(thd);
  uint part_num = 0;
  uint64_t autoinc = 0;
  bool truncate_all = (m_part_info->num_partitions_used() == m_tot_parts);

  DBUG_TRACE;

  if (high_level_read_only) {
    return HA_ERR_TABLE_READONLY;
  }

  innobase_register_trx(ht, thd, trx);

  const bool is_versioned = dd_table_has_row_versions(*dd_table);
  const bool is_instant = dd_table_is_upgraded_instant(*dd_table);

  for (const auto dd_part : *dd_table->leaf_partitions()) {
    char norm_name[FN_REFLEN];
    dict_table_t *part_table = nullptr;

    std::string partition;
    /* Build the partition name. */
    dict_name::build_partition(dd_part, partition);

    std::string partition_name;
    /* Build the partitioned table name. */
    dict_name::build_table("", table_name, partition, false, false,
                           partition_name);
    ut_ad(partition_name.length() < FN_REFLEN);

    if (!normalize_table_name(norm_name, partition_name.c_str())) {
      /* purecov: begin inspected */
      ut_d(ut_error);
      ut_o(return (HA_ERR_TOO_LONG_PATH));
      /* purecov: end */
    }

    innobase_truncate<dd::Partition> truncator(thd, norm_name, table, dd_part,
                                               !truncate_all, truncate_all);

    error = truncator.open_table(part_table);
    if (error != 0) {
      return error;
    }

    if (part_table->autoinc_persisted > autoinc) {
      autoinc = part_table->autoinc_persisted;
    }

    if (!m_part_info->is_partition_used(part_num++)) {
      continue;
    }

    if (dict_table_is_discarded(part_table)) {
      ib_senderrf(thd, IB_LOG_LEVEL_ERROR, ER_TABLESPACE_DISCARDED, table_name);
      return HA_ERR_NO_SUCH_TABLE;
    } else if (part_table->ibd_file_missing) {
      return HA_ERR_TABLESPACE_MISSING;
    }

    error = truncator.exec();

    if (error != 0) {
      return error;
    }

    if (is_instant && dd_part_has_instant_cols(*dd_part)) {
      dd_clear_instant_part(*dd_part);
    }
  }

  ut_ad(error == 0);

  /* If it's TRUNCATE PARTITION ALL, reset the AUTOINC */
  if (table->found_next_number_field) {
    dd_set_autoinc(dd_table->se_private_data(),
                   (truncate_all ? 0 : autoinc + 1));
  }

  if (is_instant || is_versioned) {
    if (truncate_all) {
      ut_ad(!dd_table_part_has_instant_cols(*dd_table));
      dd_clear_instant_table(*dd_table, is_versioned);
    } else {
      if (is_instant && !dd_table_part_has_instant_cols(*dd_table)) {
        /* Not all partition truncate. Don't clear the versioned metadata. */
        if (dd_clear_instant_table(*dd_table, false) != DB_SUCCESS) {
          error = HA_ERR_GENERIC;
        }
      }
    }
  }

  return error;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: int not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: int not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: int not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: innobase_alter_tablespace not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: innobase_alter_tablespace not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: innobase_alter_tablespace not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: Validate_files::check
dberr_t Compression::check(const char *algorithm, Compression *compression) {
  if (is_none(algorithm)) {
    compression->m_type = NONE;

  } else if (innobase_strcasecmp(algorithm, "zlib") == 0) {
    compression->m_type = ZLIB;

  } else if (innobase_strcasecmp(algorithm, "lz4") == 0) {
    compression->m_type = LZ4;

  } else {
    return (DB_UNSUPPORTED);
  }

  return (DB_SUCCESS);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: innobase_post_recover
static void innobase_post_recover() {
  if (srv_force_recovery < SRV_FORCE_NO_TRX_UNDO) {
    DBUG_EXECUTE_IF("DDL_Log_remove_inject_startup_error_2",
                    srv_inject_too_many_concurrent_trxs = true;);

    dberr_t err = log_ddl->recover();

    /* Abort post recovery startup if this is not successful. */
    if (err != DB_SUCCESS) {
      ib::fatal(UT_LOCATION_HERE, ER_IB_MSG_POST_RECOVER_DDL_LOG_RECOVER);
    }
  }

  fil_free_scanned_files();

  /* If undo tablespaces are to be encrypted, encrypt them now */
  if (srv_undo_log_encrypt) {
    ut_ad(Encryption::check_keyring());

    /* There would be at least 2 UNDO tablespaces */
    ut_ad(undo::spaces->size() >= FSP_IMPLICIT_UNDO_TABLESPACES);

    if (srv_read_only_mode) {
      ib::error(ER_IB_MSG_1051);
      srv_undo_log_encrypt = false;
    } else {
      /* Enable encryption for UNDO tablespaces */
      mutex_enter(&undo::ddl_mutex);
      if (srv_enable_undo_encryption()) {
        srv_undo_log_encrypt = false;
        ut_d(ut_error);
      }
      mutex_exit(&undo::ddl_mutex);

      /* We have to ensure that the first page of the undo tablespaces gets
       flushed to disk.  Otherwise during recovery, since we read the first
       page without applying the redo logs, it will be determined that
       encryption is off. */
      buf_flush_sync_all_buf_pools();
    }
  }

  /* If redo log is to be encrypted, encrypt it now */
  if (srv_redo_log_encrypt) {
    ut_ad(Encryption::check_keyring());

    if (srv_read_only_mode) {
      ib::error(ER_IB_MSG_LOG_FILES_CANNOT_ENCRYPT_IN_READ_ONLY);
      srv_redo_log_encrypt = false;
    } else {
      /* Enable encryption for REDO log */
      if (srv_enable_redo_encryption()) {
        srv_redo_log_encrypt = false;
        ut_d(ut_error);
      }
    }
  }

  if (srv_read_only_mode || srv_force_recovery >= SRV_FORCE_NO_BACKGROUND) {
    purge_sys->state = PURGE_STATE_DISABLED;
    return;
  }

  Auto_THD thd;
  if (dd_tablespace_update_cache(thd.thd)) {
    ut_d(ut_error);
  }

  srv_start_threads_after_ddl_recovery();

  ut_a(innodb_inited);

  if (!opt_initialize) {
    if (!log_pfs_create_tables()) {
      ib::warn(ER_IB_MSG_LOG_PFS_CREATE_TABLES_FAILED);
    }
  }
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: innobase_is_dict_readonly
static bool innobase_is_dict_readonly() {
  DBUG_TRACE;
  return srv_read_only_mode || srv_force_recovery > 0;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: update_innodb_temporary_metadata
static bool update_innodb_temporary_metadata(THD *thd) {
  if (innobase_is_dict_readonly()) {
    /* Metadata cannot be updated if the server is started in read_only
    mode. This means that the values for innodb_temp_data_file_path and
    file_name in information_schema.files will not be in same. */
    LogErr(WARNING_LEVEL, ER_SKIP_UPDATING_METADATA_IN_SE_RO_MODE,
           "information_schema");
    return false;
  }

  /* Get the filename from srv_tmp_space */
  auto fpath = srv_tmp_space.first_datafile()->filepath();
  auto &dc = *thd->dd_client();
  dd::cache::Dictionary_client::Auto_releaser releaser(&dc);
  const dd::String_type tbsp_name{dict_sys_t::s_temp_space_name};
  dd::Tablespace *tmp_tbsp{nullptr};

  if (!dc.acquire_for_modification<dd::Tablespace>(tbsp_name, &tmp_tbsp) &&
      tmp_tbsp != nullptr) {
    ut_ad(tmp_tbsp->files().size() == 1);

    /* Get the tablespace file for innodb_temporary tablespace. */
    dd::Tablespace_file *dd_file =
        const_cast<dd::Tablespace_file *>(*(tmp_tbsp->files().begin()));

    ut_ad(dd_file);

    dd_file->set_filename(fpath);

    if (dc.update(tmp_tbsp)) {
      /* Unable to update the metadata. */
      ut_d(ut_error);
      ut_o(return true);
    }
  } else {
    /* Unable to acquire innodb_temporary tablespace for modification. */
    ut_d(ut_error);
    ut_o(return true);
  }
  return false;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: innodb_init_params
are determined in innodb_init_params(). */

static char *innobase_data_home_dir = nullptr;
static char *innobase_data_file_path = nullptr;
static char *innobase_temp_data_file_path = nullptr;
static char *innobase_enable_monitor_counter = nullptr;
static char *innobase_disable_monitor_counter = nullptr;
static char *innobase_reset_monitor_counter = nullptr;
static char *innobase_reset_all_monitor_counter = nullptr;
static char *innobase_doublewrite_dir = nullptr;

static ulong innodb_flush_method;

/* This variable can be set in the server configure file, specifying
stopword table to be used */
static char *innobase_server_stopword_table = nullptr;

/* Below we have boolean-valued start-up parameters, and their default
values */

static bool innobase_rollback_on_timeout = false;
static bool innobase_create_status_file = false;
bool innobase_stats_on_metadata = true;
static bool innodb_optimize_fulltext_only = false;

static char *innodb_version_str = (char *)INNODB_VERSION_STR;

static Innodb_data_lock_inspector innodb_data_lock_inspector;

/** Note we cannot use rec_format_enum because we do not allow
COMPRESSED row format for innodb_default_row_format option. */
enum default_row_format_enum {
  DEFAULT_ROW_FORMAT_REDUNDANT = 0,
  DEFAULT_ROW_FORMAT_COMPACT = 1,
  DEFAULT_ROW_FORMAT_DYNAMIC = 2,
};


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: int not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: int not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: int not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: validate_create_tablespace_info not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: validate_create_tablespace_info not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: validate_create_tablespace_info not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: ha_innobase::rename_table
      error tweaking in rename_table(). */
      err = DB_ERROR;
    }
  }

  if (err == DB_SUCCESS && (m_flags2 & DICT_TF2_FTS)) {
    dict_sys_mutex_enter();
    fts_optimize_add_table(table);
    dict_sys_mutex_exit();
  }

  if (err == DB_SUCCESS) {
    m_table = table;
  }

error_ret:
  return convert_error_code_to_mysql(err, m_flags, m_thd);
}

template <typename Index>
const dd::Index *get_my_dd_index(const Index *index);

template <>
const dd::Index *get_my_dd_index<dd::Index>(const dd::Index *dd_index) {
  return dd_index;
}

template <>
const dd::Index *get_my_dd_index<dd::Partition_index>(
    const dd::Partition_index *dd_index) {
  return (dd_index != nullptr) ? &dd_index->index() : nullptr;
}

/** Creates an index in an InnoDB database. */
inline int create_index(
    trx_t *trx,                /*!< in: InnoDB transaction handle */
    const TABLE *form,         /*!< in: information on table
                               columns and indexes */
    uint32_t flags,            /*!< in: InnoDB table flags */
    const char *table_name,    /*!< in: table name */
    uint key_num,              /*!< in: index number */
    const dd::Table *dd_table) /*!< in: dd::Table for the table*/
{
  dict_index_t *index;
  int error;
  const KEY *key;
  ulint ind_type;
  ulint *field_lengths;
  uint32_t srid = 0;
  bool has_srid = false;
  bool multi_val_idx = false;

  DBUG_TRACE;

  key = form->key_info + key_num;

  /* Assert that "GEN_CLUST_INDEX" cannot be used as non-primary index */
  ut_a(innobase_strcasecmp(key->name, innobase_index_reserve_name) != 0);

  if (key->key_length == 0) {
    my_error(ER_WRONG_KEY_COLUMN, MYF(0), key->key_part->field->field_name);
    return ER_WRONG_KEY_COLUMN;
  }
  ind_type = 0;
  if (key->flags & HA_SPATIAL) {
    ind_type = DICT_SPATIAL;
  } else if (key->flags & HA_FULLTEXT) {
    ind_type = DICT_FTS;
  }

  if (ind_type == DICT_SPATIAL) {
    ulint dd_index_num = key_num + ((form->s->primary_key == MAX_KEY) ? 1 : 0);

    const auto *dd_index_auto = dd_table->indexes()[dd_index_num];

    const dd::Index *dd_index = get_my_dd_index(dd_index_auto);
    ut_ad(dd_index->name() == key->name);

    size_t geom_col_idx;
    for (geom_col_idx = 0; geom_col_idx < dd_index->elements().size();
         ++geom_col_idx) {


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: ha_innobase::write_row
    in ha_innobase::write_row(). */
    m_prebuilt->template_type = ROW_MYSQL_NO_TEMPLATE;
  }
}

/** Call this when you have opened a new table handle in HANDLER, before you
 call index_read_map() etc. Actually, we can let the cursor stay open even
 over a transaction commit! Then you should call this before every operation,
 fetch next etc. This function inits the necessary things even after a
 transaction commit. */

void ha_innobase::init_table_handle_for_HANDLER(void) {
  /* If current thd does not yet have a trx struct, create one.
  If the current handle does not yet have a m_prebuilt struct, create
  one. Update the trx pointers in the m_prebuilt struct. Normally
  this operation is done in external_lock. */

  update_thd(ha_thd());

  /* Initialize the m_prebuilt struct much like it would be inited in
  external_lock */

  innobase_srv_conc_force_exit_innodb(m_prebuilt->trx);

  /* If the transaction is not started yet, start it */

  trx_start_if_not_started_xa(m_prebuilt->trx, false, UT_LOCATION_HERE);

  TrxInInnoDB trx_in_innodb(m_prebuilt->trx);

  /* Assign a read view if the transaction does not have it yet */

  trx_assign_read_view(m_prebuilt->trx);

  innobase_register_trx(ht, m_user_thd, m_prebuilt->trx);

  /* We did the necessary inits in this function, no need to repeat them
  in row_search_for_mysql */

  m_prebuilt->sql_stat_start = false;

  /* We let HANDLER always to do the reads as consistent reads, even
  if the trx isolation level would have been specified as SERIALIZABLE */

  m_prebuilt->select_lock_type = LOCK_NONE;
  m_prebuilt->select_mode = SELECT_ORDINARY;
  m_stored_select_lock_type = LOCK_NONE;

  /* Always fetch all columns in the index record */

  m_prebuilt->hint_need_to_fetch_extra_cols = ROW_RETRIEVE_ALL_COLS;

  /* We want always to fetch all columns in the whole row? Or do
  we???? */

  m_prebuilt->used_in_HANDLER = true;

  reset_template();
}

/** Free any resources that were allocated and return failure.
@return always return 1 */
static int innodb_init_abort() {
  DBUG_TRACE;
  srv_shutdown_exit_threads();
  innodb_space_shutdown();
  innobase::component_services::deinitialize_service_handles();
  release_plugin_services();
  return 1;
}

/** Open or create InnoDB data files.
@param[in]      dict_init_mode  whether to create or open the files
@param[in,out]  tablespaces     predefined tablespaces created by the DDSE
@return 0 on success, 1 on failure */
[[nodiscard]] static int innobase_init_files(
    dict_init_mode_t dict_init_mode,
    List<const Plugin_tablespace> *tablespaces);

/** Initialize InnoDB for being used to store the DD tables.
Create the required files according to the dict_init_mode.
Create strings representing the required DDSE tables, i.e.,
tables that InnoDB expects to exist in the DD,
and add them to the appropriate out parameter.

@param[in]      dict_init_mode  How to initialize files

@param[in]      version         Target DD version if a new server
                                is being installed.
                                0 if restarting an existing server.

@param[out]     tables          List of SQL DDL statements
                                for creating DD tables that
                                are needed by the DDSE.

@param[out]     tablespaces     List of meta data for predefined
                                tablespaces created by the DDSE.

@retval true                    An error occurred.
@retval false                   Success - no errors. */
static bool innobase_ddse_dict_init(dict_init_mode_t dict_init_mode,
                                    uint version,
                                    List<const dd::Object_table> *tables,
                                    List<const Plugin_tablespace> *tablespaces);

/** Save the state of undo tablespaces from the dd to the undo::Tablespace
@param[in]  space_id    tablespace ID
@param[in]  dd_space    dd::Tablespace object
@return true if success and false if the undo tablespace state is not saved. */
bool apply_dd_undo_state(space_id_t space_id, const dd::Tablespace *dd_space) {
  bool success = true;
  if (!fsp_is_undo_tablespace(space_id)) {


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: ha_innobase::update_row
int ha_innobase::update_row(const uchar *old_row, uchar *new_row) {
  int err;

  dberr_t error;
  trx_t *trx = thd_to_trx(m_user_thd);
  uint64_t new_counter = 0;

  DBUG_TRACE;

  ut_a(m_prebuilt->trx == trx);

  if (high_level_read_only && !m_prebuilt->table->is_intrinsic()) {
    ib_senderrf(ha_thd(), IB_LOG_LEVEL_WARN, ER_READ_ONLY_MODE);
    return HA_ERR_TABLE_READONLY;
  } else if (!trx_is_started(trx)) {
    ++trx->will_lock;
  }

  if (m_upd_buf == nullptr) {
    ut_ad(m_upd_buf_size == 0);

    /* Create a buffer for packing the fields of a record. Why
    table->reclength did not work here? Obviously, because char
    fields when packed actually became 1 byte longer, when we also
    stored the string length as the first byte. */

    m_upd_buf_size =
        table->s->reclength + table->s->max_key_length + MAX_REF_PARTS * 3;

    m_upd_buf = reinterpret_cast<uchar *>(
        my_malloc(PSI_INSTRUMENT_ME, m_upd_buf_size, MYF(MY_WME)));

    if (m_upd_buf == nullptr) {
      m_upd_buf_size = 0;
      return HA_ERR_OUT_OF_MEM;
    }
  }

  ha_statistic_increment(&System_status_var::ha_update_count);

  upd_t *uvect;

  if (m_prebuilt->upd_node) {
    uvect = m_prebuilt->upd_node->update;
  } else {
    uvect = row_get_prebuilt_update_vector(m_prebuilt);
  }

  uvect->table = m_prebuilt->table;
  uvect->mysql_table = table;

  /* Build an update vector from the modified fields in the rows
  (uses m_upd_buf of the handle) */

  error = calc_row_difference(uvect, old_row, new_row, table, m_upd_buf,
                              m_upd_buf_size, m_prebuilt, m_user_thd);

  if (error != DB_SUCCESS) {
    goto func_exit;
  }

  if (!m_prebuilt->table->is_intrinsic() && TrxInInnoDB::is_aborted(trx)) {
    innobase_rollback(ht, m_user_thd, false);

    return convert_error_code_to_mysql(DB_FORCED_ABORT, 0, m_user_thd);
  }

  /* This is not a delete */
  m_prebuilt->upd_node->is_delete = false;

  error = innobase_srv_conc_enter_innodb(m_prebuilt);

  if (error != DB_SUCCESS) {
    goto func_exit;
  }

  error = row_update_for_mysql((byte *)old_row, m_prebuilt);

  if (dict_table_has_autoinc_col(m_prebuilt->table)) {
    new_counter = row_upd_get_new_autoinc_counter(
        uvect, m_prebuilt->table->autoinc_field_no);
  } else {
    new_counter = 0;
  }

  /* We should handle the case if the AUTOINC counter has been
  updated, we want to update the counter accordingly.

  We need to do some special AUTOINC handling for the following case:

  INSERT INTO t (c1,c2) VALUES(x,y) ON DUPLICATE KEY UPDATE ...

  We need to use the AUTOINC counter that was actually used by
  MySQL in the UPDATE statement, which can be different from the
  value used in the INSERT statement. */

  if (error == DB_SUCCESS &&
      (new_counter != 0 ||
       (table->next_number_field && new_row == table->record[0] &&
        thd_sql_command(m_user_thd) == SQLCOM_INSERT &&
        m_prebuilt->allow_duplicates()))) {
    ulonglong auto_inc;
    ulonglong col_max_value;

    if (new_counter != 0) {
      auto_inc = new_counter;
    } else {
      ut_ad(table->next_number_field != nullptr);
      auto_inc = table->next_number_field->val_int();
    }

    /* We need the upper limit of the col type to check for
    whether we update the table autoinc counter or not. */
    col_max_value = table->found_next_number_field->get_max_int_value();

    if (auto_inc <= col_max_value && auto_inc != 0) {
      ulonglong offset;
      ulonglong increment;

      offset = m_prebuilt->autoinc_offset;
      increment = m_prebuilt->autoinc_increment;

      auto_inc =
          innobase_next_autoinc(auto_inc, 1, increment, offset, col_max_value);

      error = innobase_set_max_autoinc(auto_inc);
    }
  }

  innobase_srv_conc_exit_innodb(m_prebuilt);

func_exit:

  err =
      convert_error_code_to_mysql(error, m_prebuilt->table->flags, m_user_thd);

  /* If success and no columns were updated. */
  if (err == 0 && uvect->n_fields == 0) {
    /* This is the same as success, but instructs
    MySQL that the row is not really updated and it
    should not increase the count of updated rows.
    This is fix for http://bugs.mysql.com/29157 */
    err = HA_ERR_RECORD_IS_THE_SAME;
  } else if (err == HA_FTS_INVALID_DOCID) {
    my_error(HA_FTS_INVALID_DOCID, MYF(0));
  }

  /* Tell InnoDB server that there might be work for
  utility threads: */

  innobase_active_small();

  return err;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: ha_innobase::delete_row
int ha_innobase::delete_row(
    const uchar *record) /*!< in: a row in MySQL format */
{
  dberr_t error;
  trx_t *trx = thd_to_trx(m_user_thd);
  TrxInInnoDB trx_in_innodb(trx);

  DBUG_TRACE;

  if (!m_prebuilt->table->is_intrinsic() && trx_in_innodb.is_aborted()) {
    innobase_rollback(ht, m_user_thd, false);

    return convert_error_code_to_mysql(DB_FORCED_ABORT, 0, m_user_thd);
  }

  ut_a(m_prebuilt->trx == trx);

  if (high_level_read_only && !m_prebuilt->table->is_intrinsic()) {
    ib_senderrf(ha_thd(), IB_LOG_LEVEL_WARN, ER_READ_ONLY_MODE);
    return HA_ERR_TABLE_READONLY;
  } else if (!trx_is_started(trx)) {
    ++trx->will_lock;
  }

  ha_statistic_increment(&System_status_var::ha_delete_count);

  if (!m_prebuilt->upd_node) {
    row_get_prebuilt_update_vector(m_prebuilt);
  }

  /* This is a delete */

  m_prebuilt->upd_node->is_delete = true;

  error = innobase_srv_conc_enter_innodb(m_prebuilt);

  if (error == DB_SUCCESS) {
    error = row_update_for_mysql((byte *)record, m_prebuilt);
    innobase_srv_conc_exit_innodb(m_prebuilt);
  }

  /* Tell the InnoDB server that there might be work for
  utility threads: */

  innobase_active_small();

  return convert_error_code_to_mysql(error, m_prebuilt->table->flags,
                                     m_user_thd);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: ha_innobase::discard_or_import_tablespace
int ha_innobase::discard_or_import_tablespace(bool discard,
                                              dd::Table *table_def) {
  DBUG_TRACE;

  ut_a(m_prebuilt->trx != nullptr);
  ut_a(m_prebuilt->trx->magic_n == TRX_MAGIC_N);
  ut_a(m_prebuilt->trx == thd_to_trx(ha_thd()));

  if (high_level_read_only) {
    return HA_ERR_TABLE_READONLY;
  }

  dict_table_t *dict_table = m_prebuilt->table;

  if (dict_table->is_temporary()) {
    ib_senderrf(m_prebuilt->trx->mysql_thd, IB_LOG_LEVEL_ERROR,
                ER_CANNOT_DISCARD_TEMPORARY_TABLE);

    return HA_ERR_TABLE_NEEDS_UPGRADE;
  }

  if (dict_table->space == TRX_SYS_SPACE) {
    ib_senderrf(m_prebuilt->trx->mysql_thd, IB_LOG_LEVEL_ERROR,
                ER_TABLE_IN_SYSTEM_TABLESPACE, dict_table->name.m_name);

    return HA_ERR_TABLE_NEEDS_UPGRADE;
  }

  if (DICT_TF_HAS_SHARED_SPACE(dict_table->flags)) {
    my_printf_error(ER_NOT_ALLOWED_COMMAND,
                    "InnoDB: Cannot %s table `%s` because it is in"
                    " a general tablespace. It must be file-per-table.",
                    MYF(0), discard ? "discard" : "import",
                    dict_table->name.m_name);

    return HA_ERR_NOT_ALLOWED_COMMAND;
  }

  TrxInInnoDB trx_in_innodb(m_prebuilt->trx);

  if (trx_in_innodb.is_aborted()) {
    innobase_rollback(ht, m_user_thd, false);

    return convert_error_code_to_mysql(DB_FORCED_ABORT, 0, m_user_thd);
  }

  trx_start_if_not_started(m_prebuilt->trx, true, UT_LOCATION_HERE);

  /* Obtain an exclusive lock on the table. */
  dberr_t err = row_mysql_lock_table(
      m_prebuilt->trx, dict_table, LOCK_X,
      discard ? "setting table lock for DISCARD TABLESPACE"
              : "setting table lock for IMPORT TABLESPACE");

  if (err != DB_SUCCESS) {
    /* unable to lock the table: do nothing */
    /* purecov: begin inspected */
    return convert_error_code_to_mysql(err, dict_table->flags, nullptr);
    /* purecov: end */
  }

  /* Concurrent clone operation is not supported. */
  Clone_notify notifier(Clone_notify::Type::SPACE_IMPORT,
                        dict_sys_t::s_invalid_space_id, false);
  if (notifier.failed()) {
    return notifier.get_error();
  }

  if (discard) {
    /* Discarding an already discarded tablespace should be an
    idempotent operation. Also, if the .ibd file is missing the
    user may want to set the DISCARD flag in order to IMPORT
    a new tablespace. */

    if (dict_table->ibd_file_missing) {
      ib_senderrf(m_prebuilt->trx->mysql_thd, IB_LOG_LEVEL_WARN,
                  ER_TABLESPACE_MISSING, dict_table->name.m_name);
    }

    err = row_discard_tablespace_for_mysql(dict_table->name.m_name,
                                           m_prebuilt->trx);

  } else if (!dict_table->ibd_file_missing) {
    ib::error(ER_IB_MSG_567)
        << "Unable to import tablespace " << dict_table->name
        << " because it already"
           " exists.  Please DISCARD the tablespace"
           " before IMPORT.";
    ib_senderrf(m_prebuilt->trx->mysql_thd, IB_LOG_LEVEL_ERROR,
                ER_TABLESPACE_EXISTS, dict_table->name.m_name);

    return HA_ERR_TABLE_EXIST;
  } else {
    err = row_import_for_mysql(dict_table, table_def, m_prebuilt);

    if (err == DB_SUCCESS) {
      info(HA_STATUS_TIME | HA_STATUS_CONST | HA_STATUS_VARIABLE |
           HA_STATUS_AUTO);
    }
  }

  /* Set the TABLESPACE DISCARD flag in the table definition
  on disk. */
  if (err == DB_SUCCESS) {
    dd_table_discard_tablespace(m_prebuilt->trx->mysql_thd, dict_table,
                                table_def, discard);
  }

  if (err == DB_SUCCESS && !discard &&
      dict_stats_is_persistent_enabled(dict_table)) {
    dberr_t ret;

    /* Adjust the persistent statistics. */
    ret = dict_stats_update(dict_table, DICT_STATS_RECALC_PERSISTENT);

    if (ret != DB_SUCCESS) {
      push_warning_printf(ha_thd(), Sql_condition::SL_WARNING, ER_ALTER_INFO,
                          "Error updating stats for table '%s'"
                          " after table rebuild: %s",
                          dict_table->name.m_name, ut_strerr(ret));
    }
  }

  return convert_error_code_to_mysql(err, dict_table->flags, nullptr);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: ha_innobase::truncate_impl
int ha_innobase::truncate_impl(const char *name, TABLE *form,
                               dd::Table *table_def) {
  DBUG_TRACE;

  /* Truncate of intrinsic table or hard-coded DD tables is not allowed
  for now. */
  if (table_def == nullptr ||
      dict_sys_t::is_dd_table_id(table_def->se_private_id())) {
    my_error(ER_NOT_ALLOWED_COMMAND, MYF(0));
    return HA_ERR_UNSUPPORTED;
  }

  if (high_level_read_only) {
    return HA_ERR_TABLE_READONLY;
  }

  char norm_name[FN_REFLEN];
  THD *thd = ha_thd();
  dict_table_t *innodb_table = nullptr;
  bool has_autoinc = false;
  int error = 0;
  const bool is_instant = dd_table_has_instant_cols(*table_def);

  if (!normalize_table_name(norm_name, name)) {
    /* purecov: begin inspected */
    ut_d(ut_error);
    ut_o(return (HA_ERR_TOO_LONG_PATH));
    /* purecov: end */
  }

  innobase_truncate<dd::Table> truncator(thd, norm_name, form, table_def, false,
                                         true);

  error = truncator.open_table(innodb_table);

  if (error != 0) {
    return error;
  }

  has_autoinc = dict_table_has_autoinc_col(innodb_table);

  if (dict_table_is_discarded(innodb_table)) {
    ib_senderrf(thd, IB_LOG_LEVEL_ERROR, ER_TABLESPACE_DISCARDED, norm_name);
    return HA_ERR_NO_SUCH_TABLE;
  } else if (innodb_table->ibd_file_missing) {
    return HA_ERR_TABLESPACE_MISSING;
  }

  trx_t *trx = check_trx_exists(thd);
  innobase_register_trx(ht, thd, trx);

  error = truncator.exec();

  if (error == 0) {
    if (has_autoinc) {
      dd_set_autoinc(table_def->se_private_data(), 0);
    }

    if (is_instant) {
      if (dd_clear_instant_table(*table_def, true) != DB_SUCCESS) {
        error = HA_ERR_GENERIC;
      }
    }
  }

  return error;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: create_table_info_t::prepare_create_table
int create_table_info_t::prepare_create_table(const char *name) {
  DBUG_TRACE;

  ut_ad(m_thd != nullptr);
  ut_ad(m_form->s->row_type == m_create_info->row_type);

  if (!normalize_table_name(m_table_name, name)) {
    /* purecov: begin inspected */
    ut_d(ut_error);
    ut_o(return (HA_ERR_TOO_LONG_PATH));
    /* purecov: end */
  }

  set_tablespace_type(false);

  /* Validate the create options if innodb_strict_mode is set.
  Do not use the regular message for ER_ILLEGAL_HA_CREATE_OPTION
  because InnoDB might actually support the option, but not under
  the current conditions.  The messages revealing the specific
  problems are reported inside this function. */
  if (create_options_are_invalid()) {
    return HA_WRONG_CREATE_OPTION;
  }

  /* Create the table flags and flags2 */
  if (flags() == 0 && flags2() == 0) {
    if (!innobase_table_flags()) {
      return HA_WRONG_CREATE_OPTION;
    }
  }

  ut_ad(!high_level_read_only || is_intrinsic_temp_table());

  return parse_table_name(name);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: int not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: int not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: int not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: innodb_rollback_segments_update not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: innodb_rollback_segments_update not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: innodb_rollback_segments_update not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: int not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: int not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: int not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: convert_error_code_to_mysql
int convert_error_code_to_mysql(dberr_t error, uint32_t flags, THD *thd) {
  switch (error) {
    case DB_SUCCESS:
      return (0);

    case DB_INTERRUPTED:
      thd_set_kill_status(thd != nullptr ? thd : current_thd);
      return (HA_ERR_GENERIC);

    case DB_FOREIGN_EXCEED_MAX_CASCADE:
      ut_ad(thd);
      my_error(ER_FK_DEPTH_EXCEEDED, MYF(0), FK_MAX_CASCADE_DEL);
      return (HA_ERR_FK_DEPTH_EXCEEDED);

    case DB_CANT_CREATE_GEOMETRY_OBJECT:
      my_error(ER_CANT_CREATE_GEOMETRY_OBJECT, MYF(0));
      return (HA_ERR_NULL_IN_SPATIAL);

    case DB_ERROR:
    default:
      return (HA_ERR_GENERIC); /* unspecified error */

    case DB_DUPLICATE_KEY:
      /* Be cautious with returning this error, since
      mysql could re-enter the storage layer to get
      duplicated key info, the operation requires a
      valid table handle and/or transaction information,
      which might not always be available in the error
      handling stage. */
      return (HA_ERR_FOUND_DUPP_KEY);

    case DB_READ_ONLY:
      if (srv_force_recovery) {
        return (HA_ERR_INNODB_FORCED_RECOVERY);
      }
      return (HA_ERR_TABLE_READONLY);

    case DB_FOREIGN_DUPLICATE_KEY:
      return (HA_ERR_FOREIGN_DUPLICATE_KEY);

    case DB_MISSING_HISTORY:
      return (HA_ERR_TABLE_DEF_CHANGED);

    case DB_RECORD_NOT_FOUND:
      return (HA_ERR_NO_ACTIVE_RECORD);

    case DB_FORCED_ABORT:
    case DB_DEADLOCK:
      /* Since we rolled back the whole transaction, we must
      tell it also to MySQL so that MySQL knows to empty the
      cached binlog for this transaction */

      if (thd != nullptr) {
        thd_mark_transaction_to_rollback(thd, 1);
      }

      return (HA_ERR_LOCK_DEADLOCK);

    case DB_LOCK_WAIT_TIMEOUT:
      /* Starting from 5.0.13, we let MySQL just roll back the
      latest SQL statement in a lock wait timeout. Previously, we
      rolled back the whole transaction. */

      if (thd) {
        thd_mark_transaction_to_rollback(thd, (int)row_rollback_on_timeout);
      }

      return (HA_ERR_LOCK_WAIT_TIMEOUT);

    case DB_NO_REFERENCED_ROW:
      return (HA_ERR_NO_REFERENCED_ROW);

    case DB_ROW_IS_REFERENCED:
      return (HA_ERR_ROW_IS_REFERENCED);

    case DB_NO_FK_ON_S_BASE_COL:
    case DB_CANNOT_ADD_CONSTRAINT:
    case DB_CHILD_NO_INDEX:
    case DB_PARENT_NO_INDEX:
      return (HA_ERR_CANNOT_ADD_FOREIGN);

    case DB_CANNOT_DROP_CONSTRAINT:

      return (HA_ERR_ROW_IS_REFERENCED); /* TODO: This is a bit
                                       misleading, a new MySQL error
                                       code should be introduced */

    case DB_CORRUPTION:
      return (HA_ERR_CRASHED);

    case DB_OUT_OF_FILE_SPACE:
      return (HA_ERR_RECORD_FILE_FULL);

    case DB_OUT_OF_DISK_SPACE:
      return (HA_ERR_DISK_FULL_NOWAIT);

    case DB_TEMP_FILE_WRITE_FAIL:
      return (HA_ERR_TEMP_FILE_WRITE_FAILURE);

    case DB_TABLE_IN_FK_CHECK:
      return (HA_ERR_TABLE_IN_FK_CHECK);

    case DB_TABLE_IS_BEING_USED:
      return (HA_ERR_WRONG_COMMAND);

    case DB_TABLE_NOT_FOUND:
      return (HA_ERR_NO_SUCH_TABLE);

    case DB_TABLESPACE_NOT_FOUND:
      return (HA_ERR_TABLESPACE_MISSING);

    case DB_TOO_BIG_RECORD: {
      /* If prefix is true then a 768-byte prefix is stored
      locally for BLOB fields. Refer to dict_table_get_format().
      We limit max record size to 16k for 64k page size. */
      bool prefix = !DICT_TF_HAS_ATOMIC_BLOBS(flags);
      my_printf_error(
          ER_TOO_BIG_ROWSIZE,
          "Row size too large (> " ULINTPF
          "). Changing some columns"
          " to TEXT or BLOB %smay help. In current row"
          " format, BLOB prefix of %d bytes is stored inline.",
          MYF(0),
          srv_page_size == UNIV_PAGE_SIZE_MAX
              ? REC_MAX_DATA_SIZE - 1
              : page_get_free_space_of_empty(flags & DICT_TF_COMPACT) / 2,
          prefix ? "or using ROW_FORMAT=DYNAMIC or"
                   " ROW_FORMAT=COMPRESSED "
                 : "",
          prefix ? DICT_MAX_FIXED_COL_LEN : 0);
      return (HA_ERR_TOO_BIG_ROW);
    }

    case DB_TOO_BIG_INDEX_COL:
      my_error(ER_INDEX_COLUMN_TOO_LONG, MYF(0),
               DICT_MAX_FIELD_LEN_BY_FORMAT_FLAG(flags));
      return (HA_ERR_INDEX_COL_TOO_LONG);

    case DB_NO_SAVEPOINT:
      return (HA_ERR_NO_SAVEPOINT);

    case DB_LOCK_TABLE_FULL:
      /* Since we rolled back the whole transaction, we must
      tell it also to MySQL so that MySQL knows to empty the
      cached binlog for this transaction */

      if (thd) {
        thd_mark_transaction_to_rollback(thd, 1);
      }

      return (HA_ERR_LOCK_TABLE_FULL);

    case DB_FTS_INVALID_DOCID:
      return (HA_FTS_INVALID_DOCID);
    case DB_FTS_EXCEED_RESULT_CACHE_LIMIT:
      return (HA_ERR_FTS_EXCEED_RESULT_CACHE_LIMIT);
    case DB_TOO_MANY_CONCURRENT_TRXS:
      return (HA_ERR_TOO_MANY_CONCURRENT_TRXS);
    case DB_UNSUPPORTED:
      return (HA_ERR_UNSUPPORTED);
    case DB_INDEX_CORRUPT:
      return (HA_ERR_INDEX_CORRUPT);
    case DB_UNDO_RECORD_TOO_BIG:
      return (HA_ERR_UNDO_REC_TOO_BIG);
    case DB_OUT_OF_MEMORY:
      return (HA_ERR_OUT_OF_MEM);
    case DB_TABLESPACE_EXISTS:
      return (HA_ERR_TABLESPACE_EXISTS);
    case DB_TABLESPACE_DELETED:
      return (HA_ERR_TABLESPACE_MISSING);
    case DB_IDENTIFIER_TOO_LONG:
      return (HA_ERR_INTERNAL_ERROR);
    case DB_TOO_LONG_PATH:
      return (HA_ERR_TOO_LONG_PATH);
    case DB_TABLE_CORRUPT:
      return (HA_ERR_TABLE_CORRUPT);
    case DB_FTS_TOO_MANY_WORDS_IN_PHRASE:
      return (HA_ERR_FTS_TOO_MANY_WORDS_IN_PHRASE);
    case DB_WRONG_FILE_NAME:
      return (HA_ERR_WRONG_FILE_NAME);
    case DB_COMPUTE_VALUE_FAILED:
      return (HA_ERR_COMPUTE_FAILED);
    case DB_LOCK_NOWAIT:
      my_error(ER_LOCK_NOWAIT, MYF(0));
      return (HA_ERR_NO_WAIT_LOCK);
    case DB_NO_SESSION_TEMP:
      return (HA_ERR_NO_SESSION_TEMP);
    case DB_BTREE_LEVEL_LIMIT_EXCEEDED:
      return (HA_ERR_INTERNAL_ERROR);
    case DB_FTS_TOO_MANY_NESTED_EXP:
      return (HA_ERR_FTS_TOO_MANY_NESTED_EXP);
    case DB_IO_NO_PUNCH_HOLE:
    case DB_IO_NO_PUNCH_HOLE_FS:
    case DB_IO_NO_PUNCH_HOLE_TABLESPACE:
      return HA_ERR_UNSUPPORTED;
  }
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: ha_innobase::innobase_initialize_autoinc
void ha_innobase::innobase_initialize_autoinc() {
  ulonglong auto_inc;
  const Field *field = table->found_next_number_field;

  if (field != nullptr) {
    auto_inc = field->get_max_int_value();

    /* autoinc column cannot be virtual column */
    ut_ad(!innobase_is_v_fld(field));
  } else {
    /* We have no idea what's been passed in to us as the
    autoinc column. We set it to the 0, effectively disabling
    updates to the table. */
    auto_inc = 0;

    ib::info(ER_IB_MSG_552) << "Unable to determine the AUTOINC column name";
  }

  if (srv_force_recovery >= SRV_FORCE_NO_IBUF_MERGE) {
    /* If the recovery level is set so high that writes
    are disabled we force the AUTOINC counter to 0
    value effectively disabling writes to the table.
    Secondly, we avoid reading the table in case the read
    results in failure due to a corrupted table/index.

    We will not return an error to the client, so that the
    tables can be dumped with minimal hassle.  If an error
    were returned in this case, the first attempt to read
    the table would fail and subsequent SELECTs would succeed. */
    auto_inc = 0;
  } else if (field == nullptr) {
    /* This is a far more serious error, best to avoid
    opening the table and return failure. */
    my_error(ER_AUTOINC_READ_FAILED, MYF(0));
  } else {
    dict_index_t *index = nullptr;
    const char *col_name;
    uint64_t read_auto_inc;
    ulint err;

    update_thd(ha_thd());

    col_name = field->field_name;

    read_auto_inc = dict_table_autoinc_read(m_prebuilt->table);

    if (read_auto_inc == 0) {
      index = innobase_get_index(table->s->next_number_index);

      /* Execute SELECT MAX(col_name) FROM TABLE;
      This is necessary when an imported tablespace
      doesn't have a correct cfg file so autoinc
      has not been initialized, or the table is empty. */
      err = row_search_max_autoinc(index, col_name, &read_auto_inc);

      if (read_auto_inc > 0) {
        ib::warn(ER_IB_MSG_553)
            << "Reading max(auto_inc_col) = " << read_auto_inc << " for table "
            << index->table->name << ", because there was an IMPORT"
            << " without cfg file.";
      }

    } else {
      err = DB_SUCCESS;
    }

    switch (err) {
      case DB_SUCCESS: {
        ulonglong col_max_value;

        col_max_value = field->get_max_int_value();

        /* At the this stage we do not know the increment
        nor the offset, so use a default increment of 1. */

        auto_inc = innobase_next_autoinc(read_auto_inc, 1, 1, 0, col_max_value);

        break;
      }
      case DB_RECORD_NOT_FOUND:
        ib::error(ER_IB_MSG_554) << "MySQL and InnoDB data dictionaries are"
                                    " out of sync. Unable to find the AUTOINC"
                                    " column "
                                 << col_name
                                 << " in the InnoDB"
                                    " table "
                                 << index->table->name
                                 << ". We set"
                                    " the next AUTOINC column value to 0, in"
                                    " effect disabling the AUTOINC next value"
                                    " generation.";

        ib::info(ER_IB_MSG_555) << "You can either set the next AUTOINC"
                                   " value explicitly using ALTER TABLE or fix"
                                   " the data dictionary by recreating the"
                                   " table.";

        /* This will disable the AUTOINC generation. */
        auto_inc = 0;

        /* We want the open to succeed, so that the user can
        take corrective action. ie. reads should succeed but
        updates should fail. */
        err = DB_SUCCESS;
        break;
      default:
        /* row_search_max_autoinc() should only return
        one of DB_SUCCESS or DB_RECORD_NOT_FOUND. */
        ut_error;
    }
  }

  dict_table_autoinc_initialize(m_prebuilt->table, auto_inc);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/handler/ha_innodb.cc
Function: ha_innobase::info_low
int ha_innobase::info_low(uint flag, bool is_analyze) {
  dict_table_t *ib_table;
  uint64_t n_rows;

  DBUG_TRACE;

  DEBUG_SYNC_C("ha_innobase_info_low");

  /* If we are forcing recovery at a high level, we will suppress
  statistics calculation on tables, because that may crash the
  server if an index is badly corrupted. */

  /* We do not know if MySQL can call this function before calling
  external_lock(). To be safe, update the thd of the current table
  handle. */

  update_thd(ha_thd());

  m_prebuilt->trx->op_info = (char *)"returning various info to MySQL";

  ib_table = m_prebuilt->table;
  assert(ib_table->n_ref_count > 0);

  if (flag & HA_STATUS_TIME) {
    if (is_analyze || innobase_stats_on_metadata) {
      dict_stats_upd_option_t opt;
      dberr_t ret;

      m_prebuilt->trx->op_info = "updating table statistics";

      if (dict_stats_is_persistent_enabled(ib_table)) {
        if (is_analyze) {
          opt = DICT_STATS_RECALC_PERSISTENT;
        } else {
          /* This is e.g. 'SHOW INDEXES', fetch
          the persistent stats from disk. */
          opt = DICT_STATS_FETCH_ONLY_IF_NOT_IN_MEMORY;
        }
      } else {
        opt = DICT_STATS_RECALC_TRANSIENT;
      }

      ut_ad(!dict_sys_mutex_own());
      ret = dict_stats_update(ib_table, opt);

      if (ret != DB_SUCCESS) {
        m_prebuilt->trx->op_info = "";
        return HA_ERR_GENERIC;
      }

      m_prebuilt->trx->op_info = "returning various info to MySQL";
    }

    stats.update_time = (ulong)std::chrono::system_clock::to_time_t(
        ib_table->update_time.load());
  }

  if (flag & HA_STATUS_VARIABLE) {
    ulint stat_clustered_index_size;
    ulint stat_sum_of_other_index_sizes;

    if (!(flag & HA_STATUS_NO_LOCK)) {
      dict_table_stats_lock(ib_table, RW_S_LATCH);
    }

    ut_a(ib_table->stat_initialized);

    n_rows = ib_table->stat_n_rows;

    stat_clustered_index_size = ib_table->stat_clustered_index_size;

    stat_sum_of_other_index_sizes = ib_table->stat_sum_of_other_index_sizes;

    if (!(flag & HA_STATUS_NO_LOCK)) {
      dict_table_stats_unlock(ib_table, RW_S_LATCH);
    }

    /*
    The MySQL optimizer seems to assume in a left join that n_rows
    is an accurate estimate if it is zero. Of course, it is not,
    since we do not have any locks on the rows yet at this phase.
    Since SHOW TABLE STATUS seems to call this function with the
    HA_STATUS_TIME flag set, while the left join optimizer does not
    set that flag, we add one to a zero value if the flag is not
    set. That way SHOW TABLE STATUS will show the best estimate,
    while the optimizer never sees the table empty.
    However, if it is internal temporary table used by optimizer,
    the count should be accurate */

    if (n_rows == 0 && !(flag & HA_STATUS_TIME) &&
        table_share->table_category != TABLE_CATEGORY_TEMPORARY) {
      n_rows++;
    }

    stats.records = (ha_rows)n_rows;
    stats.deleted = 0;

    calculate_index_size_stats(ib_table, n_rows, stat_clustered_index_size,
                               stat_sum_of_other_index_sizes, &stats);

    /* Since fsp_get_available_space_in_free_extents() is
    acquiring latches inside InnoDB, we do not call it if we
    are asked by MySQL to avoid locking. Another reason to
    avoid the call is that it uses quite a lot of CPU.
    See Bug#38185. */
    if (flag & HA_STATUS_NO_LOCK || !(flag & HA_STATUS_VARIABLE_EXTRA)) {
      /* We do not update delete_length if no
      locking is requested so the "old" value can
      remain. delete_length is initialized to 0 in
      the ha_statistics' constructor. Also we only
      need delete_length to be set when
      HA_STATUS_VARIABLE_EXTRA is set */
    } else if (srv_force_recovery >= SRV_FORCE_NO_IBUF_MERGE) {
      /* Avoid accessing the tablespace if
      innodb_crash_recovery is set to a high value. */
      stats.delete_length = 0;
    } else {
      calculate_delete_length_stat(ib_table, &stats, ha_thd());
    }

    stats.check_time = 0;
    stats.mrr_length_per_rec = ref_length + sizeof(void *);
  }

  /* Verify the number of indexes in InnoDB and MySQL
  matches up. If m_prebuilt->clust_index_was_generated
  holds, InnoDB defines GEN_CLUST_INDEX internally. */
  ulint num_innodb_index = UT_LIST_GET_LEN(ib_table->indexes) -
                           m_prebuilt->clust_index_was_generated;
  if (table->s->keys < num_innodb_index) {
    /* If there are too many indexes defined
    inside InnoDB, ignore those that are being
    created, because MySQL will only consider
    the fully built indexes here. */

    for (const dict_index_t *index : ib_table->indexes) {
      /* First, online index creation is
      completed inside InnoDB, and then
      MySQL attempts to upgrade the
      meta-data lock so that it can rebuild
      the .frm file. If we get here in that
      time frame, dict_index_is_online_ddl()
      would not hold and the index would
      still not be included in TABLE_SHARE. */
      if (!index->is_committed()) {
        num_innodb_index--;
      }
    }

    if (table->s->keys < num_innodb_index &&
        innobase_fts_check_doc_id_index(ib_table, nullptr, nullptr) ==
            FTS_EXIST_DOC_ID_INDEX) {
      num_innodb_index--;
    }
  }

  if (table->s->keys != num_innodb_index) {
    log_errlog(ERROR_LEVEL, ER_INNODB_IDX_CNT_MORE_THAN_DEFINED_IN_MYSQL,
               ib_table->name.m_name, num_innodb_index, table->s->keys);
  }

  if (!(flag & HA_STATUS_NO_LOCK)) {
    dict_table_stats_lock(ib_table, RW_S_LATCH);
  }

  ut_a(ib_table->stat_initialized);

  const dict_index_t *pk = UT_LIST_GET_FIRST(ib_table->indexes);

  for (uint i = 0; i < table->s->keys; i++) {
    ulong j;
    /* We could get index quickly through internal
    index mapping with the index translation table.
    The identity of index (match up index name with
    that of table->key_info[i]) is already verified in
    innobase_get_index().  */
    dict_index_t *index = innobase_get_index(i);

    if (index == nullptr) {
      log_errlog(ERROR_LEVEL, ER_INNODB_IDX_CNT_FEWER_THAN_DEFINED_IN_MYSQL,
                 ib_table->name.m_name, TROUBLESHOOTING_MSG);
      break;
    }

    KEY *key = &table->key_info[i];

    double pct_cached;

    /* We do not maintain stats for fulltext or spatial indexes.
    Thus, we can't calculate pct_cached below because we need
    dict_index_t::stat_n_leaf_pages for that. See
    dict_stats_should_ignore_index(). */
    if ((key->flags & HA_FULLTEXT) || (key->flags & HA_SPATIAL)) {
      pct_cached = IN_MEMORY_ESTIMATE_UNKNOWN;
    } else {
      pct_cached = index_pct_cached(index);
    }

    key->set_in_memory_estimate(pct_cached);

    if (index == pk) {
      stats.table_in_mem_estimate = pct_cached;
    }

    if (flag & HA_STATUS_CONST) {
      if (!key->supports_records_per_key()) {
        continue;
      }

      for (j = 0; j < key->actual_key_parts; j++) {
        if ((key->flags & HA_FULLTEXT) || (key->flags & HA_SPATIAL)) {
          /* The record per key does not apply to
          FTS or Spatial indexes. */
          key->set_records_per_key(j, 1.0f);
          continue;
        }

        if (j + 1 > index->n_uniq) {
          log_errlog(ERROR_LEVEL, ER_INNODB_IDX_COLUMN_CNT_DIFF, index->name(),
                     ib_table->name.m_name, (unsigned long)index->n_uniq, j + 1,
                     TROUBLESHOOTING_MSG);
          break;
        }

        /* innodb_rec_per_key() will use
        index->stat_n_diff_key_vals[] and the value we
        pass index->table->stat_n_rows. Both are
        calculated by ANALYZE and by the background
        stats gathering thread (which kicks in when too
        much of the table has been changed). In
        addition table->stat_n_rows is adjusted with
        each DML (e.g. ++ on row insert). Those
        adjustments are not MVCC'ed and not even
        reversed on rollback. So,
        index->stat_n_diff_key_vals[] and
        index->table->stat_n_rows could have been
        calculated at different time. This is
        acceptable. */
        const rec_per_key_t rec_per_key =
            innodb_rec_per_key(index, (ulint)j, index->table->stat_n_rows);

        key->set_records_per_key(j, rec_per_key);

        /* The code below is legacy and should be
        removed together with this comment once we
        are sure the new floating point rec_per_key,
        set via set_records_per_key(), works fine. */

        ulong rec_per_key_int = static_cast<ulong>(
            innodb_rec_per_key(index, (ulint)j, stats.records));

        /* Since MySQL seems to favor table scans
        too much over index searches, we pretend
        index selectivity is 2 times better than
        our estimate: */

        rec_per_key_int = rec_per_key_int / 2;

        if (rec_per_key_int == 0) {
          rec_per_key_int = 1;
        }

        key->rec_per_key[j] = rec_per_key_int;
      }
    }
  }

  if (!(flag & HA_STATUS_NO_LOCK)) {
    dict_table_stats_unlock(ib_table, RW_S_LATCH);
  }

  if (srv_force_recovery >= SRV_FORCE_NO_IBUF_MERGE) {
    goto func_exit;

  } else if (flag & HA_STATUS_ERRKEY) {
    const dict_index_t *err_index;

    ut_a(m_prebuilt->trx);
    ut_a(m_prebuilt->trx->magic_n == TRX_MAGIC_N);

    err_index = trx_get_error_index(m_prebuilt->trx);

    if (err_index) {
      errkey = innobase_get_mysql_key_number_for_index(m_share, table, ib_table,
                                                       err_index);
    } else {
      errkey =
          (unsigned int)((m_prebuilt->trx->error_key_num == ULINT_UNDEFINED)
                             ? ~0
                             : m_prebuilt->trx->error_key_num);
    }
  }

  if ((flag & HA_STATUS_AUTO) && table->found_next_number_field) {
    ulonglong auto_inc_val = innobase_peek_autoinc(ib_table, true);
    /* Initialize autoinc value if not set. */
    if (auto_inc_val == 0) {
      dict_table_autoinc_lock(m_prebuilt->table);
      innobase_initialize_autoinc();
      dict_table_autoinc_unlock(m_prebuilt->table);

      auto_inc_val = innobase_peek_autoinc(ib_table, true);
    }
    stats.auto_increment_value = auto_inc_val;
  }

func_exit:
  m_prebuilt->trx->op_info = (char *)"";

  return 0;
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/srv/srv0srv.cc
Function: srv_master_do_shutdown_tasks
         srv_master_do_shutdown_tasks(&last_print_time)) {
    /* Shouldn't loop here in case of very fast shutdown */
    ut_ad(srv_fast_shutdown < 2);
  }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/srv/srv0srv.cc
Function: srv_master_do_pre_dd_shutdown_tasks
         srv_master_do_pre_dd_shutdown_tasks(&last_print_time)) {
    /* Shouldn't loop here in case of very fast shutdown */
    ut_ad(srv_fast_shutdown < 2);
  }


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/srv/srv0srv.cc
Function: srv_master_main_loop
static void srv_master_main_loop(srv_slot_t *slot) {
  if (srv_force_recovery >= SRV_FORCE_NO_BACKGROUND) {
    /* When innodb_force_recovery is at least SRV_FORCE_NO_BACKGROUND,
    we avoid performing active/idle master's tasks. However, we still
    need to ensure that:
      srv_shutdown_state >= SRV_SHUTDOWN_PRE_DD_AND_SYSTEM_TRANSACTIONS,
    after we exited srv_master_main_loop(). Keep waiting until that
    is satisfied and then exit. */
    while (srv_shutdown_state.load() <
           SRV_SHUTDOWN_PRE_DD_AND_SYSTEM_TRANSACTIONS) {
      srv_master_wait(slot);
    }
    return;
  }

  ulint old_activity_count = srv_get_activity_count();

  while (srv_shutdown_state.load() <
         SRV_SHUTDOWN_PRE_DD_AND_SYSTEM_TRANSACTIONS) {
    srv_master_sleep();

    MONITOR_INC(MONITOR_MASTER_THREAD_SLEEP);

    /* Just in case - if there is not much free space in redo,
    try to avoid asking for troubles because of extra work
    performed in such background thread. */
    srv_main_thread_op_info = "checking free log space";
    log_free_check();

    if (srv_check_activity(old_activity_count)) {
      old_activity_count = srv_get_activity_count();
      srv_master_do_active_tasks();
    } else {
      srv_master_do_idle_tasks();
    }

    /* Purge any deleted tablespace pages. */
    fil_purge();
  }
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/srv/srv0srv.cc
Function: srv_worker_thread
void srv_worker_thread() {
  srv_slot_t *slot;

  ut_ad(!srv_read_only_mode);
  ut_a(srv_force_recovery < SRV_FORCE_NO_BACKGROUND);

  THD *thd = create_internal_thd();

  purge_sys->is_this_a_purge_thread = true;

  slot = srv_reserve_slot(SRV_WORKER);

  ut_a(srv_n_purge_threads > 1);

  srv_sys_mutex_enter();

  ut_a(srv_sys->n_threads_active[SRV_WORKER] < srv_n_purge_threads);

  srv_sys_mutex_exit();

  /* We need to ensure that the worker threads exit after the
  purge coordinator thread. Otherwise the purge coordinaor can
  end up waiting forever in trx_purge_wait_for_workers_to_complete() */

  do {
    srv_suspend_thread(slot);

    os_event_wait(slot->event);

    if (srv_task_execute()) {
      /* If there are tasks in the queue, wakeup
      the purge coordinator thread. */

      srv_wake_purge_thread_if_not_active();
    }

    /* Note: we are checking the state without holding the
    purge_sys->latch here. */
  } while (purge_sys->state != PURGE_STATE_EXIT);

  srv_free_slot(slot);

  rw_lock_x_lock(&purge_sys->latch, UT_LOCATION_HERE);

  ut_a(!purge_sys->running);
  ut_a(purge_sys->state == PURGE_STATE_EXIT);
  ut_a(srv_shutdown_state.load() >= SRV_SHUTDOWN_PURGE);

  rw_lock_x_unlock(&purge_sys->latch);

  destroy_internal_thd(thd);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/srv/srv0srv.cc
Function: srv_task_execute
static bool srv_task_execute(void) {
  que_thr_t *thr = nullptr;

  ut_ad(!srv_read_only_mode);
  ut_a(srv_force_recovery < SRV_FORCE_NO_BACKGROUND);

  if (UT_LIST_GET_LEN(srv_sys->tasks) == 0) {
    return false;
  }

  mutex_enter(&srv_sys->tasks_mutex);

  if (UT_LIST_GET_LEN(srv_sys->tasks) > 0) {
    thr = UT_LIST_GET_FIRST(srv_sys->tasks);

    ut_a(que_node_get_type(thr->child) == QUE_NODE_PURGE);

    UT_LIST_REMOVE(srv_sys->tasks, thr);
  }

  mutex_exit(&srv_sys->tasks_mutex);

  if (thr != nullptr) {
    que_run_threads(thr);

    purge_sys->n_completed.fetch_add(1);
  }

  return (thr != nullptr);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/srv/srv0srv.cc
Function: srv_purge_coordinator_thread
void srv_purge_coordinator_thread() {
  srv_slot_t *slot;

  THD *thd = create_internal_thd();

  purge_sys->is_this_a_purge_thread = true;

  ulint n_total_purged = ULINT_UNDEFINED;

  ut_ad(!srv_read_only_mode);
  ut_a(srv_n_purge_threads >= 1);
  ut_a(trx_purge_state() == PURGE_STATE_INIT);
  ut_a(srv_force_recovery < SRV_FORCE_NO_BACKGROUND);

  rw_lock_x_lock(&purge_sys->latch, UT_LOCATION_HERE);

  purge_sys->running = true;
  purge_sys->state = PURGE_STATE_RUN;

  rw_lock_x_unlock(&purge_sys->latch);

  slot = srv_reserve_slot(SRV_PURGE);

  ulint rseg_history_len = trx_sys->rseg_history_len;

  do {
    /* If there are no records to purge or the last
    purge didn't purge any records then wait for activity. */

    if (srv_shutdown_state.load() < SRV_SHUTDOWN_PURGE &&
        (purge_sys->state == PURGE_STATE_STOP || n_total_purged == 0)) {
      srv_purge_coordinator_suspend(slot, rseg_history_len);
    }

    if (srv_purge_should_exit(n_total_purged)) {
      ut_a(!slot->suspended);
      break;
    }

    n_total_purged = 0;

    rseg_history_len = srv_do_purge(&n_total_purged);

  } while (!srv_purge_should_exit(n_total_purged));

  /* This is just for test scenarios. Do not pass thd here,
  because it would lead to wait on event then, and we would
  never exit the srv_pre_dd_shutdown() which waits for this
  thread to exit. That's because the signal for which we
  would wait is signalled in srv_shutdown which happens
  after the srv_pre_dd_shutdown is ended. */
  srv_thread_delay_cleanup_if_needed(false);

  /* Ensure that we don't jump out of the loop unless the
  exit condition is satisfied. */

  ut_a(srv_purge_should_exit(n_total_purged));

  ulint n_pages_purged = ULINT_MAX;

  /* Ensure that all records are purged if it is not a fast shutdown.
  This covers the case where a record can be added after we exit the
  loop above. */
  while (srv_fast_shutdown == 0 && n_pages_purged > 0) {
    n_pages_purged = trx_purge(1, srv_purge_batch_size, false);
  }

  /* This trx_purge is called to remove any undo records (added by
  background threads) after completion of the above loop. When
  srv_fast_shutdown != 0, a large batch size can cause significant
  delay in shutdown, so reducing the batch size to magic number 20
  (which was default in 5.5), which we hope will be sufficient to
  remove all the undo records */
  const uint temp_batch_size = 20;

  n_pages_purged =
      trx_purge(1,
                srv_purge_batch_size <= temp_batch_size ? srv_purge_batch_size
                                                        : temp_batch_size,
                true);
  ut_a(n_pages_purged == 0 || srv_fast_shutdown != 0);

  /* The task queue should always be empty, independent of fast
  shutdown state. */
  ut_a(srv_get_task_queue_length() == 0);

  srv_free_slot(slot);

  /* Note that we are shutting down. */
  rw_lock_x_lock(&purge_sys->latch, UT_LOCATION_HERE);

  purge_sys->state = PURGE_STATE_EXIT;

  /* Clear out any pending undo-tablespaces to truncate and reset
  the list as we plan to shutdown the purge thread. */
  purge_sys->undo_trunc.reset();

  purge_sys->running = false;

  rw_lock_x_unlock(&purge_sys->latch);

  /* Ensure that all the worker threads quit. */
  if (srv_n_purge_threads > 1) {
    srv_release_threads(SRV_WORKER, srv_n_purge_threads - 1);
  }

  /* This is just for test scenarios. Do not pass thd here.
  For explanation look at comment for similar usage above. */
  srv_thread_delay_cleanup_if_needed(false);

  destroy_internal_thd(thd);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/srv/srv0srv.cc
Function: srv_purge_wakeup
void srv_purge_wakeup(void) {
  ut_ad(!srv_read_only_mode);

  if (srv_force_recovery < SRV_FORCE_NO_BACKGROUND) {
    srv_release_threads(SRV_PURGE, 1);

    if (srv_threads.m_purge_workers_n > 1) {
      /* SRV_PURGE is not counted here. */
      ulint n_workers = srv_threads.m_purge_workers_n - 1;

      srv_release_threads(SRV_WORKER, n_workers);
    }
  }
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/srv/srv0start.cc
Function: srv_undo_tablespaces_construct
static dberr_t srv_undo_tablespaces_construct() {
  mtr_t mtr;

  if (undo::s_under_construction.empty()) {
    return (DB_SUCCESS);
  }

  ut_a(!srv_read_only_mode);
  ut_a(!srv_force_recovery);

  if (srv_undo_log_encrypt && Encryption::check_keyring() == false) {
    my_error(ER_CANNOT_FIND_KEY_IN_KEYRING, MYF(0));
    return (DB_ERROR);
  }

  for (auto space_id : undo::s_under_construction) {
    /* Enable undo log encryption if it's ON. */
    if (srv_undo_log_encrypt) {
      dberr_t err = srv_undo_tablespace_enable_encryption(space_id);

      if (err != DB_SUCCESS) {
        ib::error(ER_IB_MSG_1091, ulong{undo::id2num(space_id)});

        return (err);
      }
    }

    log_free_check();

    mtr_start(&mtr);

    mtr_x_lock(fil_space_get_latch(space_id), &mtr, UT_LOCATION_HERE);

    if (!fsp_header_init(space_id, UNDO_INITIAL_SIZE_IN_PAGES, &mtr)) {
      ib::error(ER_IB_MSG_1093, ulong{undo::id2num(space_id)});

      mtr_commit(&mtr);
      return (DB_ERROR);
    }

    /* Add the RSEG_ARRAY page. */
    trx_rseg_array_create(space_id, &mtr);

    mtr_commit(&mtr);

    /* The rollback segments will get created later in
    trx_rseg_add_rollback_segments(). */
  }

  if (srv_undo_log_encrypt) {
    ut_d(bool ret =) srv_enable_undo_encryption();
    ut_ad(!ret);
  }

  return (DB_SUCCESS);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/srv/srv0start.cc
Function: srv_undo_tablespace_create
static dberr_t srv_undo_tablespace_create(undo::Tablespace &undo_space) {
  pfs_os_file_t fh;
  bool ret;
  dberr_t err = DB_SUCCESS;
  char *file_name = undo_space.file_name();
  space_id_t space_id = undo_space.id();

  ut_a(!srv_read_only_mode);
  ut_a(!srv_force_recovery);

  os_file_create_subdirs_if_needed(file_name);

  /* Until this undo tablespace can become active, keep a truncate log
  file around so that if a crash happens it can be rebuilt at startup. */
  err = undo::start_logging(&undo_space);
  if (err != DB_SUCCESS) {
    ib::error(ER_IB_MSG_1070, undo_space.log_file_name(),
              undo_space.space_name());
  }
  ut_ad(err == DB_SUCCESS);

  fh = os_file_create(innodb_data_file_key, file_name,
                      (srv_read_only_mode ? OS_FILE_OPEN : OS_FILE_CREATE) |
                          OS_FILE_ON_ERROR_NO_EXIT,
                      OS_FILE_NORMAL, OS_DATA_FILE, srv_read_only_mode, &ret);

  if (ret == false) {
    std::ostringstream stmt;

    if (os_file_get_last_error(false) == OS_FILE_ALREADY_EXISTS) {
      stmt << " since '" << file_name << "' already exists.";
    } else {
      stmt << ". os_file_create() returned " << ret << ".";
    }

    ib::error(ER_IB_MSG_1214, undo_space.space_name(), stmt.str().c_str());

    err = DB_ERROR;
  } else {
    ut_a(!srv_read_only_mode);

    /* We created the data file and now write it full of zeros */
    undo_space.set_new();

    ib::info(ER_IB_MSG_1071, file_name);

    ulint size_mb = UNDO_INITIAL_SIZE >> 20;

    ib::info(ER_IB_MSG_1072, file_name, ulonglong{size_mb});

    ib::info(ER_IB_MSG_1073);

    ret = os_file_set_size(file_name, fh, 0, UNDO_INITIAL_SIZE, true);

    DBUG_EXECUTE_IF("ib_undo_tablespace_create_fail", ret = false;);

    if (!ret) {
      ib::info(ER_IB_MSG_1074, file_name);
      err = DB_OUT_OF_FILE_SPACE;
    }

    os_file_close(fh);

    /* Add this space to the list of undo tablespaces to
    construct by creating header pages. If an old undo
    tablespace needed fixup before it is upgraded,
    there is no need to construct it.*/
    if (undo::is_reserved(space_id)) {
      undo::add_space_to_construction_list(space_id);
    }
  }

  return (err);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/srv/srv0start.cc
Function: srv_start
called once during srv_start(). */
void undo_spaces_init() {
  ut_ad(undo::spaces == nullptr);

  undo::spaces = ut::new_withkey<undo::Tablespaces>(
      ut::make_psi_memory_key(mem_key_undo_spaces));

  trx_sys_undo_spaces_init();

  undo::init_space_id_bank();
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/srv/srv0start.cc
Function: srv_undo_tablespaces_create
static dberr_t srv_undo_tablespaces_create() {
  dberr_t err = DB_SUCCESS;

  undo::spaces->x_lock();

  ulint initial_implicit_undo_spaces = 0;
  for (auto undo_space : undo::spaces->m_spaces) {
    if (undo_space->num() <= FSP_IMPLICIT_UNDO_TABLESPACES) {
      initial_implicit_undo_spaces++;
    }
  }

  if (initial_implicit_undo_spaces >= FSP_IMPLICIT_UNDO_TABLESPACES) {
    undo::spaces->x_unlock();
    return (DB_SUCCESS);
  }

  if (srv_read_only_mode || srv_force_recovery > 0) {
    const char *mode;

    mode = srv_read_only_mode ? "read_only" : "force_recovery",

    ib::warn(ER_IB_MSG_1086, mode, ulonglong{initial_implicit_undo_spaces});

    if (initial_implicit_undo_spaces == 0) {
      ib::error(ER_IB_MSG_1087, mode);

      undo::spaces->x_unlock();
      return (DB_ERROR);
    }

    undo::spaces->x_unlock();
    return (DB_SUCCESS);
  }

  /* Create all implicit undo tablespaces that are needed. */
  for (space_id_t num = 1; num <= FSP_IMPLICIT_UNDO_TABLESPACES; ++num) {
    /* If the trunc log file is present, the fixup process will be
    finished later. */
    if (undo::is_active_truncate_log_present(num)) {
      continue;
    }

    /* Check if an independent undo space for this space_id
    has already been found. */
    if (undo::spaces->contains(num)) {
      continue;
    }

    /* Mark this implicit undo space number as used and return the next
    available space_id. */
    space_id_t space_id = undo::use_next_space_id(num);

    /* Since it is not found, create it. */
    undo::Tablespace undo_space(space_id);
    undo_space.set_new();
    err = srv_undo_tablespace_create(undo_space);
    if (err != DB_SUCCESS) {
      ib::info(ER_IB_MSG_1088, undo_space.space_name());
      break;
    }

    /* Open this new undo tablespace. */
    err = srv_undo_tablespace_open(undo_space);
    if (err != DB_SUCCESS) {
      ib::info(ER_IB_MSG_1089, int{err}, ut_strerr(err),
               undo_space.space_name());

      break;
    }
  }

  undo::spaces->x_unlock();

  ulint new_spaces =
      FSP_IMPLICIT_UNDO_TABLESPACES - initial_implicit_undo_spaces;

  ib::info(ER_IB_MSG_1090, ulonglong{new_spaces});

  return (err);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/srv/srv0start.cc
Function: srv_dict_recover_on_restart
void srv_dict_recover_on_restart() {
  /* Resurrect locks for dictionary transactions */
  trx_resurrect_locks(false);

  /* Roll back any recovered data dictionary transactions, so
  that the data dictionary tables will be free of any locks.
  The data dictionary latch should guarantee that there is at
  most one data dictionary transaction active at a time. */
  if (srv_force_recovery < SRV_FORCE_NO_TRX_UNDO && trx_sys_need_rollback()) {
    trx_rollback_or_clean_recovered(false);
  }

  /* Resurrect locks for non-dictionary transactions only after rolling back all
  dictionary transactions. This is required as of today since we read
  uncommitted data while constructing table object in dd_table_open_on_id_low.
  This is done only while looking for the DD space object
  client->acquire_uncached_uncommitted<dd::Tablespace>().

  TODO-1: dd_table_open_on_id_low : Reading uncommitted data doesn't seem
  correct and needs to be analyzed and possibly fixed.

  Till that time we let all DD transactions to rollback to avoid reading dirty
  data from incomplete DDL commands while resurrecting locks. It essentially
  fixes two independent issues.

  1. Not able to resurrect table locks for uncommitted transaction.

  2. Not able to load innodb dict_* object for the table involved in the DDL.
     This could result in much more serious issue when binary log is enabled
     and crash happens after the transaction is prepared. Currently in binlog
     transaction recovery path no session THD is created and we rely on cached
     dict_* object to find out if a table is dropped. If the dict_table_t
     object is not already loaded, the table is considered dropped and undo
     apply is skipped. This would further result in uncommitted but prepared
     transaction data being committed and persisted.

  TODO-2: Have session (THD) while doing binary log recovery. The lack of
  THD seems not correct since rollback requires DD metadata. This alone would
  have prevented transaction inconsistency between innodb and binlog even if we
  failed to resurrect the table locks.
  binlog_recover->ha_recover->xarecover_handlerton->innobase_rollback_by_xid
  ->innobase_rollback_trx

  Note: The current work around fixes both issues but ideally should not be
  required if base issues [TODOs] are fixed. */
  trx_resurrect_locks(true);

  trx_clear_resurrected_table_ids();

  /* Do after all DD transactions recovery, to get consistent metadata */
  apply_dynamic_metadata();

  if (srv_force_recovery < SRV_FORCE_NO_IBUF_MERGE) {
    srv_sys_tablespaces_open = true;
  }
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/srv/srv0start.cc
Function: srv_start_wait_for_purge_to_start
static void srv_start_wait_for_purge_to_start() {
  /* Wait for the purge coordinator and master thread to startup. */

  purge_state_t state = trx_purge_state();

  ut_a(state != PURGE_STATE_DISABLED);

  while (srv_shutdown_state.load() < SRV_SHUTDOWN_PURGE &&
         srv_force_recovery < SRV_FORCE_NO_BACKGROUND &&
         state == PURGE_STATE_INIT) {
    switch (state = trx_purge_state()) {
      case PURGE_STATE_RUN:
      case PURGE_STATE_STOP:
        break;

      case PURGE_STATE_INIT:
        ib::info(ER_IB_MSG_1097);

        std::this_thread::sleep_for(std::chrono::milliseconds(50));
        break;

      case PURGE_STATE_EXIT:
      case PURGE_STATE_DISABLED:
        ut_error;
    }
  }
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/srv/srv0start.cc
Function: srv_start_threads
void srv_start_threads() {
  if (!srv_read_only_mode) {
    /* Before 8.0, it was master thread that was doing periodical
    checkpoints (every 7s). Since 8.0, it is the log checkpointer
    thread, which is owned by log_sys, that is responsible for
    periodical checkpoints (every innodb_log_checkpoint_every ms).
    Note that the log checkpointer thread was created earlier and
    is already active, but the periodical checkpoints were disabled.
    Only the required checkpoints were allowed, which includes:
            - checkpoints because of too old last_checkpoint_lsn,
            - checkpoints explicitly requested (because of call to
              log_make_latest_checkpoint()).
    The reason was to make the situation more deterministic during
    the startup, because then:
            - it is easier to write mtr tests,
            - there are less possible flows - smaller risk of bug.
    Now we start allowing periodical checkpoints! Since now, it's
    hard to predict when checkpoints are written! */
    log_limits_mutex_enter(*log_sys);
    log_sys->periodical_checkpoints_enabled = true;
    log_limits_mutex_exit(*log_sys);
  }

  srv_threads.m_buf_resize =
      os_thread_create(buf_resize_thread_key, 0, buf_resize_thread);

  srv_threads.m_buf_resize.start();

  if (srv_read_only_mode) {
    purge_sys->state = PURGE_STATE_DISABLED;
    return;
  }

  /* Create the master thread which does purge and other utility
  operations */
  srv_threads.m_master =
      os_thread_create(srv_master_thread_key, 0, srv_master_thread);

  srv_threads.m_master.start();

  if (srv_force_recovery == 0) {
    /* In the insert buffer we may have even bigger tablespace
    id's, because we may have dropped those tablespaces, but
    insert buffer merge has not had time to clean the records from
    the ibuf tree. */

    ibuf_update_max_tablespace_id();
  }

  /* Create the dict stats gathering thread */
  srv_threads.m_dict_stats =
      os_thread_create(dict_stats_thread_key, 0, dict_stats_thread);

  dict_stats_thread_init();

  srv_threads.m_dict_stats.start();

  /* Create the thread that will optimize the FTS sub-system. */
  fts_optimize_init();

  srv_start_state_set(SRV_START_STATE_STAT);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/srv/srv0start.cc
Function: srv_start_threads_after_ddl_recovery
void srv_start_threads_after_ddl_recovery() {
  if (srv_force_recovery < SRV_FORCE_NO_TRX_UNDO && trx_sys_need_rollback()) {
    /* Rollback all recovered transactions that are
    not in committed nor in XA PREPARE state. */
    srv_threads.m_trx_recovery_rollback = os_thread_create(
        trx_recovery_rollback_thread_key, 0, trx_recovery_rollback_thread);

    srv_threads.m_trx_recovery_rollback.start();
    /* Wait till shared MDL is taken by background thread for all tables,
    for which rollback is to be performed. */
    os_event_wait(recovery_lock_taken);
  }

  /* Start the buffer pool dump/load thread, which will access spaces thus
        must wait for DDL recovery */
  srv_threads.m_buf_dump =
      os_thread_create(buf_dump_thread_key, 0, buf_dump_thread);

  srv_threads.m_buf_dump.start();

  /* Resume unfinished (un)encryption process in background thread. */
  if (!ts_encrypt_ddl_records.empty()) {
    srv_threads.m_ts_alter_encrypt =
        os_thread_create(srv_ts_alter_encrypt_thread_key, 0,
                         fsp_init_resume_alter_encrypt_tablespace);

    mysql_mutex_lock(&resume_encryption_cond_m);
    srv_threads.m_ts_alter_encrypt.start();
    /* Wait till shared MDL is taken by background thread for all tablespaces,
    for which (un)encryption is to be rolled forward. */
    mysql_cond_wait(&resume_encryption_cond, &resume_encryption_cond_m);
    mysql_mutex_unlock(&resume_encryption_cond_m);
  }

  /* Start and consume all GTIDs for recovered transactions. */
  auto &gtid_persistor = clone_sys->get_gtid_persistor();
  gtid_persistor.start();

  DBUG_EXECUTE_IF("crash_before_purge_thread", DBUG_SUICIDE(););

  /* Now the InnoDB Metadata and file system should be consistent.
  Start the Purge thread */
  srv_start_purge_threads();

  /* If recovered, should do write back the dynamic metadata. */
  dict_persist_to_dd_table_buffer();
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/srv/srv0start.cc
Function: srv_shutdown_waits_for_rollback_of_recovered_transactions
bool srv_shutdown_waits_for_rollback_of_recovered_transactions() {
  return (srv_force_recovery < SRV_FORCE_NO_TRX_UNDO && srv_fast_shutdown == 0);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/srv/srv0start.cc
Function: srv_shutdown_log
static lsn_t srv_shutdown_log() {
  ut_a(srv_shutdown_state.load() == SRV_SHUTDOWN_FLUSH_PHASE);
  ut_a(!buf_flush_page_cleaner_is_active());
  ut_ad(buf_pool_pending_io_reads_count() == 0);
  ut_ad(buf_pool_pending_io_writes_count() == 0);

  if (srv_fast_shutdown == 2) {
    if (!srv_read_only_mode) {
      ib::info(ER_IB_MSG_1253);

      /* In this fastest shutdown we do not flush the
      buffer pool:

      it is essentially a 'crash' of the InnoDB server.
      Make sure that the log is all flushed to disk, so
      that we can recover all committed transactions in
      a crash recovery. We must not write the lsn stamps
      to the data files, since at a startup InnoDB deduces
      from the stamps if the previous shutdown was clean. */

      log_stop_background_threads(*log_sys);
    }

    /* No redo log might be generated since now. */
    log_background_threads_inactive_validate();

    srv_shutdown_set_state(SRV_SHUTDOWN_LAST_PHASE);

    return (log_get_lsn(*log_sys));
  }

  if (!srv_read_only_mode) {
    log_make_empty_and_stop_background_threads(*log_sys);
  }

  /* No redo log might be generated since now. */
  log_background_threads_inactive_validate();
  buf_must_be_all_freed();

  const lsn_t lsn = log_get_lsn(*log_sys);

  if (!srv_read_only_mode) {
    /* Redo log has been flushed at the log_flusher's exit. */
    fil_flush_file_spaces();
  }

  srv_shutdown_set_state(SRV_SHUTDOWN_LAST_PHASE);

  /* Validate lsn and write it down. */
  ut_a(log_is_data_lsn(lsn) || srv_force_recovery >= SRV_FORCE_NO_LOG_REDO);

  ut_a(lsn == log_sys->last_checkpoint_lsn.load() ||
       srv_force_recovery >= SRV_FORCE_NO_LOG_REDO);

  ut_a(lsn == log_get_lsn(*log_sys));

  if (!srv_read_only_mode) {
    ut_a(srv_force_recovery < SRV_FORCE_NO_LOG_REDO);

    auto err = fil_write_flushed_lsn(lsn);
    ut_a(err == DB_SUCCESS);
  }

  buf_must_be_all_freed();
  ut_a(lsn == log_get_lsn(*log_sys));

  if (srv_downgrade_logs) {
    ut_a(!srv_read_only_mode);

    /* InnoDB in any version is able to start on empty set of redo files. */
    log_files_remove(*log_sys);
  }

  return (lsn);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/trx/trx0roll.cc
Function: trx_rollback_or_clean_recovered
void trx_rollback_or_clean_recovered(
    bool all) /*!< in: false=roll back dictionary transactions;
               true=roll back all non-PREPARED transactions */
{
  ut_ad(!srv_read_only_mode);

  ut_a(srv_force_recovery < SRV_FORCE_NO_TRX_UNDO);
  ut_ad(!all || trx_sys_need_rollback());

  if (all) {
    ib::info(ER_IB_MSG_1189) << "Starting in background the rollback"
                                " of uncommitted transactions";
  }

  /* Note: For XA recovered transactions, we rely on MySQL to
  do rollback. They will be in TRX_STATE_PREPARED state. If the server
  is shutdown and they are still lingering in trx_sys_t::trx_list
  then the shutdown will hang. */

  /* Loop over the transaction list as long as there are
  recovered transactions to clean up or recover. */

  trx_sys_mutex_enter();
  for (bool need_one_more_scan = true; need_one_more_scan;) {
    need_one_more_scan = false;
    for (auto trx : trx_sys->rw_trx_list) {
      assert_trx_in_rw_list(trx);

      /* In case of slow shutdown, we have to wait for the background
      thread (trx_recovery_rollback) which is doing the rollbacks of
      recovered transactions. Note that it can add undo to purge.
      In case of fast shutdown we do not care if we left transactions
      not rolled back. But still we want to stop the thread, so since
      certain point of shutdown we might be sure there are no changes
      to transactions / undo. */
      if (srv_shutdown_state.load() >= SRV_SHUTDOWN_RECOVERY_ROLLBACK &&
          srv_fast_shutdown != 0) {
        ut_a(srv_shutdown_state_matches([](auto state) {
          return state == SRV_SHUTDOWN_RECOVERY_ROLLBACK ||
                 state == SRV_SHUTDOWN_EXIT_THREADS;
        }));

        trx_sys_mutex_exit();

        if (all) {
          ib::info(ER_IB_MSG_TRX_RECOVERY_ROLLBACK_NOT_COMPLETED);
        }
        return;
      }

      /* If this function does a cleanup or rollback
      then it will release the trx_sys->mutex, therefore
      we need to reacquire it before retrying the loop. */
      if (trx_rollback_or_clean_resurrected(trx, all)) {
        trx_sys_mutex_enter();
        need_one_more_scan = true;
        break;
      }
    }
  }
  trx_sys_mutex_exit();

  if (all) {
    ib::info(ER_IB_MSG_TRX_RECOVERY_ROLLBACK_COMPLETED);
  }
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/trx/trx0rseg.cc
Function: trx_rseg_add_rollback_segments
bool trx_rseg_add_rollback_segments(space_id_t space_id, ulong target_rsegs,
                                    Rsegs *rsegs,
                                    ulint *const n_total_created) {
  bool success = true;
  mtr_t mtr;
  page_no_t page_no;
  trx_rseg_t *rseg;
  ulint n_created = 0;
  ulint n_tracked = 0;

  enum space_type_t { TEMP, UNDO } type;

  ut_ad(space_id != TRX_SYS_SPACE);

  type = (fsp_is_undo_tablespace(space_id) ? UNDO : TEMP);
  ut_ad(type == UNDO || fsp_is_system_temporary(space_id));

  /* Protect against two threads trying to add rollback segments
  at the same time. */
  rsegs->x_lock();

  for (ulint num = 0; num < FSP_MAX_ROLLBACK_SEGMENTS; num++) {
    if (rsegs->size() >= target_rsegs) {
      break;
    }

    ulint rseg_id = num;

    /* If the rseg object exists, move to the next rseg_id. */
    rseg = rsegs->find(rseg_id);
    if (rseg != nullptr) {
      ut_ad(rseg->id == rseg_id);
      continue;
    }

    /* Look in the tablespace to discover if the rollback segment
    already exists. */
    if (type == UNDO) {
      page_no = trx_rseg_get_page_no(space_id, rseg_id);

    } else {
      /* There is no durable list of rollback segments in
      the temporary tablespace. Since it was not found in
      the rsegs vector, assume the rollback segment does
      not exist in the temp tablespace. */
      page_no = FIL_NULL;
    }

    if (page_no == FIL_NULL) {
      /* Create the missing rollback segment if allowed. */
      if (type == TEMP || (!srv_read_only_mode && srv_force_recovery == 0)) {
        page_no = trx_rseg_create(space_id, rseg_id);
        if (page_no == FIL_NULL) {
          /* There may not be enough space in
          the temporary tablespace since it is
          possible to limit its size. */
          ut_ad(type == TEMP);
          continue;
        }
        n_created++;
      } else {
        /* trx_rseg_create() is being prevented
        in an UNDO tablespace. Don't try to create
        any more. */
        break;
      }
    }

    /* Create the trx_rseg_t object. */
    mtr.start();

    fil_space_t *space = fil_space_get(space_id);
    ut_ad(univ_page_size.equals_to(page_size_t(space->flags)));
    mtr_x_lock(&space->latch, &mtr, UT_LOCATION_HERE);

    if (type == TEMP) {
      mtr_set_log_mode(&mtr, MTR_LOG_NO_REDO);
    }

    rseg = trx_rseg_mem_create(rseg_id, space_id, page_no, univ_page_size, 0,
                               purge_sys->purge_queue, &mtr);

    mtr.commit();

    if (rseg != nullptr) {
      ut_a(rseg->id == rseg_id);
      rsegs->push_back(rseg);
      n_tracked++;
    }
  }

  rsegs->x_unlock();

  std::ostringstream loc;
  switch (type) {
    case UNDO:
      loc << "undo tablespace number " << undo::id2num(space_id);
      break;
    case TEMP:
      loc << "the temporary tablespace";
      break;
  }

  ulint n_known = rsegs->size();
  if (n_known < target_rsegs) {
    if (srv_read_only_mode || srv_force_recovery > 0) {
      bool use_and = srv_read_only_mode && srv_force_recovery > 0;

      ib::info(ER_IB_MSG_1191)
          << "Could not create all " << target_rsegs << " rollback segments in "
          << loc.str() << " because "
          << (srv_read_only_mode ? " read-only mode is set" : "")
          << (use_and ? " and" : "")
          << (srv_force_recovery > 0 ? " innodb_force_recovery is set" : "")
          << ". Only " << n_known << " are active.";

      srv_rollback_segments =
          std::min(srv_rollback_segments, static_cast<ulong>(n_known));

    } else {
      ib::warn(ER_IB_MSG_1192)
          << "Could not create all " << target_rsegs << " rollback segments in "
          << loc.str() << ". Only " << n_known << " are active.";

      srv_rollback_segments =
          std::min(srv_rollback_segments, static_cast<ulong>(n_known));

      success = false;
    }

  } else if (n_created > 0) {
    ib::info(ER_IB_MSG_1193)
        << "Created " << n_created << " and tracked " << n_tracked
        << " new rollback segment(s) in " << loc.str() << ". " << target_rsegs
        << " are now active.";

  } else if (n_tracked > 0) {
    ib::info(ER_IB_MSG_1194)
        << "Using " << n_tracked << " more rollback segment(s) in " << loc.str()
        << ". " << target_rsegs << " are now active.";

  } else if (target_rsegs < n_known) {
    ib::info(ER_IB_MSG_1195)
        << target_rsegs << " rollback segment(s) are now active in "
        << loc.str() << ".";
  }

  if (n_total_created != nullptr) {
    *n_total_created += n_created;
  }

  /* Save the size of the undo tablespace now that all rsegs have been created.
  No need to do this for the system temporary tablespace. */
  if (type == UNDO) {
    fil_space_set_undo_size(space_id, true);
  }
  return (success);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/trx/trx0rseg.cc
Function: trx_rseg_adjust_rollback_segments
bool trx_rseg_adjust_rollback_segments(ulong target_rollback_segments) {
  /** The number of rollback segments created in the datafile. */
  ulint n_total_created = 0;

  /* Make sure Temporary Tablespace has enough rsegs. */
  if (!trx_rseg_add_rollback_segments(srv_tmp_space.space_id(),
                                      target_rollback_segments,
                                      &(trx_sys->tmp_rsegs), nullptr)) {
    return (false);
  }

  /* Only the temp rsegs are used with a high force_recovery. */
  if (srv_force_recovery >= SRV_FORCE_NO_UNDO_LOG_SCAN) {
    return (true);
  }

  /* Adjust the number of rollback segments in each Undo Tablespace
  whether or not it is currently active. If rollback segments are written
  to the tablespace, they will be checkpointed. But we cannot hold
  undo::spaces->s_lock while doing a checkpoint because of latch order
  violation.  So traverse the list by ID. */
  undo::spaces->s_lock();
  for (auto undo_space : undo::spaces->m_spaces) {
    if (!trx_rseg_add_rollback_segments(
            undo_space->id(), target_rollback_segments, undo_space->rsegs(),
            &n_total_created)) {
      undo::spaces->s_unlock();
      return (false);
    }
  }
  undo::spaces->s_unlock();

  /* Make sure these rollback segments are checkpointed. */
  if (n_total_created > 0 && !srv_read_only_mode && srv_force_recovery == 0) {
    log_make_latest_checkpoint();
  }

  return (true);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/trx/trx0sys.cc
Function: trx_sys_init_at_db_start
purge_pq_t *trx_sys_init_at_db_start(void) {
  purge_pq_t *purge_queue;
  trx_sysf_t *sys_header;
  uint64_t rows_to_undo = 0;
  const char *unit = "";

  /* We create the min binary heap here and pass ownership to
  purge when we init the purge sub-system. Purge is responsible
  for freeing the binary heap. */
  purge_queue = ut::new_withkey<purge_pq_t>(UT_NEW_THIS_FILE_PSI_KEY);
  ut_a(purge_queue != nullptr);

  if (srv_force_recovery < SRV_FORCE_NO_UNDO_LOG_SCAN) {
    /* Create the memory objects for all the rollback segments
    referred to in the TRX_SYS page or any undo tablespace
    RSEG_ARRAY page. */
    srv_rseg_init_threads =
        std::min(std::thread::hardware_concurrency(), max_rseg_init_threads);

    /* Test hook to initialize the rollback segments using a single
    thread. */
    DBUG_EXECUTE_IF("rseg_init_single_thread", srv_rseg_init_threads = 1;);

    using Clock = std::chrono::high_resolution_clock;
    using Clock_point = std::chrono::time_point<Clock>;
    Clock_point start = Clock::now();
    if (srv_rseg_init_threads > 1) {
      trx_rsegs_parallel_init(purge_queue);
    } else {
      trx_rsegs_init(purge_queue);
    }
    Clock_point end = Clock::now();
    const auto time_diff =
        std::chrono::duration_cast<std::chrono::microseconds>(end - start)
            .count();
    ib::info(ER_IB_MSG_PAR_RSEG_INIT_TIME_MSG, srv_rseg_init_threads,
             (uint32_t)time_diff);
  }

  mtr_t mtr;
  mtr.start();

  sys_header = trx_sysf_get(&mtr);

  const trx_id_t max_trx_id =
      mach_read_from_8(sys_header + TRX_SYS_TRX_ID_STORE);

  /* VERY important: after the database is started, next_trx_id_or_no value
  needs to be set to a higher value than the maximum of values that have ever
  been used for either trx->id or trx->no. After that, it needs to be written
  to the transaction system header page, before it is used the first time to
  assign a new value for trx->id or trx->no. This way trx id values will not
  overlap when the database is repeatedly crashed and restarted!

  Note, that the factor 2 in 2 * TRX_SYS_TRX_ID_WRITE_MARGIN is required,
  because the next_trx_id_or_no might be increased concurrently in two
  threads:
    - one that has acquired trx_sys_mutex,
    - and one that has acquired the trx_sys_serialisation_mutex.
  If you decreased the factor 2, the test innodb.max_trx_id should fail. */

  trx_sys->next_trx_id_or_no.store(max_trx_id +
                                   2 * trx_sys_get_trx_id_write_margin());

  trx_sys->serialisation_min_trx_no.store(trx_sys->next_trx_id_or_no.load());

  mtr.commit();

#ifdef UNIV_DEBUG
  /* max_trx_id is the next transaction ID to assign. Initialize maximum
  transaction number to one less if all transactions are already purged. */
  if (trx_sys->rw_max_trx_no == 0) {
    trx_sys->rw_max_trx_no = trx_sys_get_next_trx_id_or_no() - 1;
  }
#endif /* UNIV_DEBUG */

  trx_sys_mutex_enter();
  trx_sys_write_max_trx_id();
  trx_sys_mutex_exit();

  trx_dummy_sess = sess_open();

  trx_lists_init_at_db_start();

  /* This mutex is not strictly required, it is here only to satisfy
  the debug code (assertions). We are still running in single threaded
  bootstrap mode. */

  trx_sys_mutex_enter();

  if (UT_LIST_GET_LEN(trx_sys->rw_trx_list) > 0) {
    for (auto trx : trx_sys->rw_trx_list) {
      ut_ad(trx->is_recovered);
      assert_trx_in_rw_list(trx);

      if (trx_state_eq(trx, TRX_STATE_ACTIVE)) {
        rows_to_undo += trx->undo_no;
      }
    }

    if (rows_to_undo > 1000000000) {
      unit = "M";
      rows_to_undo = rows_to_undo / 1000000;
    }

    ib::info(ER_IB_MSG_1198)
        << UT_LIST_GET_LEN(trx_sys->rw_trx_list)
        << " transaction(s) which must be rolled back or"
           " cleaned up in total "
        << rows_to_undo << unit << " row operations to undo";

    ib::info(ER_IB_MSG_1199)
        << "Trx id counter is " << trx_sys_get_next_trx_id_or_no();
  }

  trx_sys->found_prepared_trx = trx_sys->n_prepared_trx > 0;

  trx_sys_mutex_exit();

  return (purge_queue);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/trx/trx0trx.cc
Function: trx_resurrect_insert not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/trx/trx0trx.cc
Function: trx_resurrect_insert not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/trx/trx0trx.cc
Function: trx_resurrect_insert not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/trx/trx0trx.cc
Function: trx_start_low not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/trx/trx0trx.cc
Function: trx_start_low not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/trx/trx0trx.cc
Function: trx_start_low not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/trx/trx0trx.cc
Function: trx_start_low not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/trx/trx0trx.cc
Function: trx_start_low not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/trx/trx0trx.cc
Function: trx_start_low not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/trx/trx0trx.cc
Function: trx_set_rw_mode
void trx_set_rw_mode(trx_t *trx) /*!< in/out: transaction that is RW */
{
  ut_ad(trx->rsegs.m_redo.rseg == nullptr);
  ut_ad(!trx->in_rw_trx_list);
  ut_ad(!trx_is_autocommit_non_locking(trx));
  ut_ad(!trx->read_only);
  ut_ad(trx_can_be_handled_by_current_thread_or_is_hp_victim(trx));

  if (srv_force_recovery >= SRV_FORCE_NO_TRX_UNDO) {
    return;
  }

  /* Function is promoting existing trx from ro mode to rw mode.
  In this process it has acquired trx_sys->mutex as it plan to
  move trx from ro list to rw list. If in future, some other thread
  looks at this trx object while it is being promoted then ensure
  that both threads are synced by acquiring trx->mutex to avoid decision
  based on in-consistent view formed during promotion. */

  trx_assign_rseg_durable(trx);

  ut_ad(trx->rsegs.m_redo.rseg != nullptr);

  DEBUG_SYNC_C("trx_sys_before_assign_id");

  trx_sys_mutex_enter();

  ut_ad(trx->id == 0);
  trx->id = trx_sys_allocate_trx_id();

  trx_sys->rw_trx_ids.push_back(trx->id);

  /* So that we can see our own changes. */
  if (MVCC::is_view_active(trx->read_view)) {
    MVCC::set_view_creator_trx_id(trx->read_view, trx->id);
  }
  trx_add_to_rw_trx_list(trx);

  trx_sys_mutex_exit();

  trx_sys_rw_trx_add(trx);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/trx/trx0undo.cc
Function: trx_undo_lists_init
ulint trx_undo_lists_init(
    trx_rseg_t *rseg) /*!< in: rollback segment memory object */
{
  ulint size = 0;
  trx_rsegf_t *rseg_header;
  ulint i;
  mtr_t mtr;

  mtr.start();

  rseg_header =
      trx_rsegf_get_new(rseg->space_id, rseg->page_no, rseg->page_size, &mtr);

  for (i = 0; i < TRX_RSEG_N_SLOTS; i++) {
    page_no_t page_no;

    page_no = trx_rsegf_get_nth_undo(rseg_header, i, &mtr);

    /* In forced recovery: try to avoid operations which look
    at database pages; undo logs are rapidly changing data, and
    the probability that they are in an inconsistent state is
    high */

    if (page_no != FIL_NULL &&
        srv_force_recovery < SRV_FORCE_NO_UNDO_LOG_SCAN) {
      trx_undo_t *undo;

      undo = trx_undo_mem_init(rseg, i, page_no, &mtr);

      size += undo->size;

      mtr.commit();

      mtr.start();

      rseg_header =
          trx_rsegf_get(rseg->space_id, rseg->page_no, rseg->page_size, &mtr);

      /* Found a used slot */
      MONITOR_INC(MONITOR_NUM_UNDO_SLOT_USED);
    }
  }

  mtr.commit();

  return (size);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/include/ibuf0ibuf.ic
Function: ibuf_should_try not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/include/ibuf0ibuf.ic
Function: ibuf_should_try not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/include/ibuf0ibuf.ic
Function: ibuf_should_try not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/include/ibuf0ibuf.ic
Function: ibuf_should_try not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/btr/btr0cur.cc
Function: btr_cur_search_to_nth_level
btr_cur_search_to_nth_level(). */
ulint btr_cur_n_sea = 0;
/** Old value of btr_cur_n_non_sea.  Copied by
srv_refresh_innodb_monitor_stats().  Referenced by
srv_printf_innodb_monitor(). */
ulint btr_cur_n_non_sea_old = 0;
/** Old value of btr_cur_n_sea.  Copied by
srv_refresh_innodb_monitor_stats().  Referenced by
srv_printf_innodb_monitor(). */
ulint btr_cur_n_sea_old = 0;

#ifdef UNIV_DEBUG
/* Flag to limit optimistic insert records */
uint btr_cur_limit_optimistic_insert_debug = 0;
#endif /* UNIV_DEBUG */

/** In the optimistic insert, if the insert does not fit, but this much space
can be released by page reorganize, then it is reorganized */
#define BTR_CUR_PAGE_REORGANIZE_LIMIT (UNIV_PAGE_SIZE / 32)

/** Estimated table level stats from sampled value.
@param value sampled stats
@param index index being sampled
@param sample number of sampled rows
@param ext_size external stored data size
@param not_empty table not empty
@return estimated table wide stats from sampled value */
constexpr uint64_t BTR_TABLE_STATS_FROM_SAMPLE(uint64_t value,
                                               dict_index_t *index,
                                               uint64_t sample, ulint ext_size,
                                               ulint not_empty) {
  return (value * index->stat_n_leaf_pages + sample - 1 + ext_size +
          not_empty) /
         (sample + ext_size);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/buf/buf0buf.cc
Function: buf_page_io_complete
bool buf_page_io_complete(buf_page_t *bpage, bool evict) {
  auto buf_pool = buf_pool_from_bpage(bpage);
  const bool uncompressed = (buf_page_get_state(bpage) == BUF_BLOCK_FILE_PAGE);

  ut_a(buf_page_in_file(bpage));

  /* We do not need protect io_fix here by mutex to read it because this is the
  only function where we can change the value from BUF_IO_READ or BUF_IO_WRITE
  to some other value, and our code ensures that this is the only thread that
  handles the i/o for this block. There are other methods that reset the IO to
  NONE, but they must do that before the IO is requested to OS and must be done
  as a part of cleanup in thread that was trying to make such IO request. */

  ut_ad(bpage->current_thread_has_io_responsibility());
  const auto io_type =
      bpage->is_io_fix_read_as_opposed_to_write() ? BUF_IO_READ : BUF_IO_WRITE;
  const auto flush_type = buf_page_get_flush_type(bpage);

  if (io_type == BUF_IO_READ) {
    bool compressed_page;
    byte *frame{};
    page_no_t read_page_no;
    space_id_t read_space_id;
    bool is_wrong_page_id [[maybe_unused]] = false;

    if (bpage->size.is_compressed()) {
      frame = bpage->zip.data;
      buf_pool->n_pend_unzip.fetch_add(1);
      if (uncompressed && !buf_zip_decompress((buf_block_t *)bpage, false)) {
        buf_pool->n_pend_unzip.fetch_sub(1);

        compressed_page = false;
        goto corrupt;
      }
      buf_pool->n_pend_unzip.fetch_sub(1);
    } else {
      frame = reinterpret_cast<buf_block_t *>(bpage)->frame;
      ut_a(uncompressed);
    }

    /* If this page is not uninitialized and not in the
    doublewrite buffer, then the page number and space id
    should be the same as in block. */
    read_page_no = mach_read_from_4(frame + FIL_PAGE_OFFSET);
    read_space_id = mach_read_from_4(frame + FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID);

    if (bpage->id.space() == TRX_SYS_SPACE &&
        dblwr::v1::is_inside(bpage->id.page_no())) {
      ib::error(ER_IB_MSG_78) << "Reading page " << bpage->id
                              << ", which is in the doublewrite buffer!";

    } else if (read_space_id == 0 && read_page_no == 0) {
      /* This is likely an uninitialized page. */
    } else if ((bpage->id.space() != 0 && bpage->id.space() != read_space_id) ||
               bpage->id.page_no() != read_page_no) {
      /* We did not compare space_id to read_space_id
      if bpage->space == 0, because the field on the
      page may contain garbage in MySQL < 4.1.1,
      which only supported bpage->space == 0. */

      ib::error(ER_IB_MSG_79) << "Space id and page number stored in "
                                 "the page read in are "
                              << page_id_t(read_space_id, read_page_no)
                              << ", should be " << bpage->id;
      is_wrong_page_id = true;
    }

    compressed_page = Compression::is_compressed_page(frame);

    /* If the decompress failed then the most likely case is
    that we are reading in a page for which this instance doesn't
    support the compression algorithm. */
    if (compressed_page) {
      Compression::meta_t meta;

      Compression::deserialize_header(frame, &meta);

      ib::error(ER_IB_MSG_80)
          << "Page " << bpage->id << " "
          << "compressed with " << Compression::to_string(meta) << " "
          << "that is not supported by this instance";
    }

    /* From version 3.23.38 up we store the page checksum
    to the 4 first bytes of the page end lsn field */
    bool is_corrupted;
    {
      BlockReporter reporter =
          BlockReporter(true, frame, bpage->size,
                        fsp_is_checksum_disabled(bpage->id.space()));
      is_corrupted = reporter.is_corrupted();
    }

#ifdef UNIV_LINUX
    /* A crash during extending file might cause the inconsistent contents.
    No problem for the cases. Just fills with zero for them.
    - The next log record to apply is initializing
    - No redo log record for the page yet (brand new page) */
    if (recv_recovery_is_on() && (is_corrupted || is_wrong_page_id) &&
        recv_page_is_brand_new((buf_block_t *)bpage)) {
      memset(frame, 0, bpage->size.logical());
      is_corrupted = false;
    }
#endif /* UNIV_LINUX */

    if (compressed_page || is_corrupted) {
      /* Not a real corruption if it was triggered by
      error injection */
      DBUG_EXECUTE_IF("buf_page_import_corrupt_failure",
                      goto page_not_corrupt;);

    corrupt:
      /* Compressed pages are basically gibberish avoid
      printing the contents. */
      if (!compressed_page) {
        ib::error(ER_IB_MSG_81)
            << "Database page corruption on disk"
               " or a failed file read of page "
            << bpage->id << ". You may have to recover from "
            << "a backup.";

        buf_page_print(frame, bpage->size, BUF_PAGE_PRINT_NO_CRASH);

        ib::info(ER_IB_MSG_82) << "It is also possible that your"
                                  " operating system has corrupted"
                                  " its own file cache and rebooting"
                                  " your computer removes the error."
                                  " If the corrupt page is an index page."
                                  " You can also try to fix the"
                                  " corruption by dumping, dropping,"
                                  " and reimporting the corrupt table."
                                  " You can use CHECK TABLE to scan"
                                  " your table for corruption. "
                               << FORCE_RECOVERY_MSG;
      }

      if (srv_force_recovery < SRV_FORCE_IGNORE_CORRUPT) {
        /* We do not have to mark any index as
        corrupted here, since we only know the space
        id but not the exact index id. There could
        be multiple tables/indexes in the same space,
        so we will mark it later in upper layer */

        buf_read_page_handle_error(bpage);
        return (false);
      }
    }

    DBUG_EXECUTE_IF("buf_page_import_corrupt_failure", page_not_corrupt
                    : bpage = bpage;);

    if (recv_recovery_is_on()) {
      /* Pages must be uncompressed for crash recovery. */
      ut_a(uncompressed);
      recv_recover_page(true, (buf_block_t *)bpage);
    }

    if (uncompressed && !Compression::is_compressed_page(frame) &&
        !recv_no_ibuf_operations &&
        fil_page_get_type(frame) == FIL_PAGE_INDEX && page_is_leaf(frame) &&
        !fsp_is_system_temporary(bpage->id.space()) &&
        !fsp_is_undo_tablespace(bpage->id.space()) && !bpage->was_stale()) {
      ibuf_merge_or_delete_for_page((buf_block_t *)bpage, bpage->id,
                                    &bpage->size, true);
    }
  }

  bool has_LRU_mutex = false;

  auto block_mutex = buf_page_get_mutex(bpage);

  if (io_type == BUF_IO_WRITE) {
    /* We decide whether or not to evict the page from the
    LRU list based on the flush_type.
    - BUF_FLUSH_LIST: don't evict
    - BUF_FLUSH_LRU: always evict
    - BUF_FLUSH_SINGLE_PAGE: eviction preference is passed
    by the caller explicitly. */
    ut_ad(!(flush_type == BUF_FLUSH_LIST && evict));
    if (flush_type == BUF_FLUSH_LRU) {
      evict = true;
    }
    if (evict
#if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
        /* The LRU mutex is required on debug in this path:
           buf_flush_write_complete (called later in this method) ->
           buf_flush_remove -> buf_LRU_insert_zip_clean().
           It is safe to query the page state without mutex protection, as
           transition to BUF_BLOCK_ZIP_DIRTY is possible only when the page
           descriptor is initialized. Assuming this thread has the IO
           responsibility (which is assured earlier in this method), the
           transitions from the BUF_BLOCK_ZIP_DIRTY are only allowed from this
           thread and no one else can modify the state. */
        || buf_page_get_state(bpage) == BUF_BLOCK_ZIP_DIRTY
#endif /* UNIV_DEBUG || UNIV_BUF_DEBUG */
    ) {
      has_LRU_mutex = true;
      mutex_enter(&buf_pool->LRU_list_mutex);
    }
  }
  mutex_enter(block_mutex);

#ifdef UNIV_IBUF_COUNT_DEBUG
  if (io_type == BUF_IO_WRITE || uncompressed) {
    /* For BUF_IO_READ of compressed-only blocks, the
    buffered operations will be merged by buf_page_get_gen()
    after the block has been uncompressed. */
    ut_a(ibuf_count_get(bpage->id) == 0);
  }
#endif /* UNIV_IBUF_COUNT_DEBUG */

  /* Because this thread which does the unlocking is not the same that
  did the locking, we use a pass value != 0 in unlock, which simply
  removes the newest lock debug record, without checking the thread
  id. */

  buf_page_monitor(bpage, io_type);

  switch (io_type) {
    case BUF_IO_READ:

      ut_ad(!has_LRU_mutex);

      buf_page_set_io_fix(bpage, BUF_IO_NONE);

      /* NOTE that the call to ibuf may have moved the ownership of
      the x-latch to this OS thread: do not let this confuse you in
      debugging! */

      if (uncompressed) {
        rw_lock_x_unlock_gen(&((buf_block_t *)bpage)->lock, BUF_IO_READ);
      }

      mutex_exit(block_mutex);

      ut_ad(buf_pool->n_pend_reads > 0);
      buf_pool->n_pend_reads.fetch_sub(1);
      buf_pool->stat.n_pages_read.fetch_add(1);

      break;

    case BUF_IO_WRITE:
      /* Write means a flush operation: call the completion
      routine in the flush system */

      buf_flush_write_complete(bpage);

      if (uncompressed) {
        rw_lock_sx_unlock_gen(&((buf_block_t *)bpage)->lock, BUF_IO_WRITE);
      }

      buf_pool->stat.n_pages_written.fetch_add(1);

      ut_ad(!(evict && !has_LRU_mutex));
      if (evict && buf_LRU_free_page(bpage, true)) {
        has_LRU_mutex = false;
      } else {
        mutex_exit(block_mutex);
      }
      if (has_LRU_mutex) {
        mutex_exit(&buf_pool->LRU_list_mutex);
      }

      break;

    default:
      ut_error;
  }

  DBUG_PRINT("ib_buf", ("%s page " UINT32PF ":" UINT32PF,
                        io_type == BUF_IO_READ ? "read" : "wrote",
                        bpage->id.space(), bpage->id.page_no()));

  return (true);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/clone/clone0repl.cc
Function: Clone_persist_gtid::flush_gtids
void Clone_persist_gtid::flush_gtids(THD *thd) {
  int err = 0;
  Sid_map sid_map(nullptr);
  Gtid_set table_gtid_set(&sid_map, nullptr);

  DBUG_EXECUTE_IF("gtid_persist_flush_disable", return;);

  /* During recovery, fetch existing GTIDs from gtid_executed table. */
  bool is_recovery = !m_thread_active.load();
  if (is_recovery && !opt_initialize) {
    gtid_table_persistor->fetch_gtids(&table_gtid_set);
  }

  bool explicit_request = m_explicit_request.load();

  trx_sys_serialisation_mutex_enter();
  /* Get oldest transaction number that is yet to be committed. Any transaction
  with lower transaction number is committed and is added to GTID list. */
  auto oldest_trx_no = trx_sys_oldest_trx_no();
  bool compress_recovery = false;
  /* Check and write if any GTID is accumulated. */
  if (m_num_gtid_mem.load() != 0) {
    m_flush_in_progress.store(true);
    /* Switch active list and get the previous list to write to disk table. */
    auto flush_list_number = switch_active_list();
    /* Exit trx mutex during write to table. */
    trx_sys_serialisation_mutex_exit();
    err = write_to_table(flush_list_number, table_gtid_set, sid_map);
    m_flush_in_progress.store(false);
    /* Compress always after recovery, if GTIDs are added. */
    if (!m_thread_active.load()) {
      compress_recovery = true;
      ib::info(ER_IB_CLONE_GTID_PERSIST) << "GTID compression after recovery. ";
    }
  } else {
    trx_sys_serialisation_mutex_exit();
  }

  if (is_recovery) {
    /* Allocate buffer and fill GTIDs */
    char *gtid_buffer = nullptr;
    auto gtid_buffer_size = table_gtid_set.to_string(&gtid_buffer);
    /* Update GTID set to status for clone recovery. */
    std::string all_gtids;
    if (gtid_buffer_size > 0) {
      all_gtids.assign(gtid_buffer);
    }
    /* Must update GITD status even if no GTID. This call completes
    clone operation. */
    clone_update_gtid_status(all_gtids);
    my_free(gtid_buffer);
  }

  /* Update trx number up to which GTID is written to table. */
  update_gtid_trx_no(oldest_trx_no);

  /* Request Compression once the counter reaches threshold. */
  bool debug_skip = debug_skip_write(true);
  if (err == 0 && !debug_skip && (compress_recovery || check_compress())) {
    m_compression_counter = 0;
    m_compression_gtid_counter = 0;
    /* Write non-innodb GTIDs before compression. */
    write_other_gtids();
    err = gtid_table_persistor->compress(thd);
  }
  if (err != 0) {
    ib::error(ER_IB_CLONE_GTID_PERSIST) << "Error persisting GTIDs to table";
    ut_ad(debug_skip || srv_force_recovery > 0);
  }

  /* Reset the explicit compression request, if our previous check
  for explicit returned true. If the request is made after previous
  check then we do the compression next time. */
  if (explicit_request) {
    m_explicit_request.store(false);
  }
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/dict/dict0boot.cc
Function: dict_boot
dberr_t dict_boot(void) {
  dict_hdr_t *dict_hdr;
  mtr_t mtr;
  dberr_t err = DB_SUCCESS;

  mtr_start(&mtr);

  /* Create the hash tables etc. */
  dict_init();

  /* Get the dictionary header */
  dict_hdr = dict_hdr_get(&mtr);

  /* Because we only write new row ids to disk-based data structure
  (dictionary header) when it is divisible by
  DICT_HDR_ROW_ID_WRITE_MARGIN, in recovery we will not recover
  the latest value of the row id counter. Therefore we advance
  the counter at the database startup to avoid overlapping values.
  Note that when a user after database startup first time asks for
  a new row id, then because the counter is now divisible by
  ..._MARGIN, it will immediately be updated to the disk-based
  header. */

  dict_sys->row_id =
      DICT_HDR_ROW_ID_WRITE_MARGIN +
      ut_uint64_align_up(mach_read_from_8(dict_hdr + DICT_HDR_ROW_ID),
                         DICT_HDR_ROW_ID_WRITE_MARGIN);

  /* For upgrading, we need to load the old InnoDB internal SYS_*
  tables. */
  if (srv_is_upgrade_mode) {
    dict_table_t *table;
    dict_index_t *index;
    mem_heap_t *heap;

    /* Be sure these constants do not ever change.  To avoid bloat,
    only check the *NUM_FIELDS* in each table */
    static_assert(DICT_NUM_COLS__SYS_TABLES == 8);
    static_assert(DICT_NUM_FIELDS__SYS_TABLES == 10);
    static_assert(DICT_NUM_FIELDS__SYS_TABLE_IDS == 2);
    static_assert(DICT_NUM_COLS__SYS_COLUMNS == 7);
    static_assert(DICT_NUM_FIELDS__SYS_COLUMNS == 9);
    static_assert(DICT_NUM_COLS__SYS_INDEXES == 8);
    static_assert(DICT_NUM_FIELDS__SYS_INDEXES == 10);
    static_assert(DICT_NUM_COLS__SYS_FIELDS == 3);
    static_assert(DICT_NUM_FIELDS__SYS_FIELDS == 5);
    static_assert(DICT_NUM_COLS__SYS_FOREIGN == 4);
    static_assert(DICT_NUM_FIELDS__SYS_FOREIGN == 6);
    static_assert(DICT_NUM_FIELDS__SYS_FOREIGN_FOR_NAME == 2);
    static_assert(DICT_NUM_COLS__SYS_FOREIGN_COLS == 4);
    static_assert(DICT_NUM_FIELDS__SYS_FOREIGN_COLS == 6);

    heap = mem_heap_create(450, UT_LOCATION_HERE);

    /* Insert into the dictionary cache the descriptions of the basic
    system tables */
    table = dict_mem_table_create("SYS_TABLES", DICT_HDR_SPACE, 8, 0, 0, 0, 0);

    dict_mem_table_add_col(table, heap, "NAME", DATA_BINARY, 0,
                           MAX_FULL_NAME_LEN, true);
    dict_mem_table_add_col(table, heap, "ID", DATA_BINARY, 0, 8, true);
    /* ROW_FORMAT = (N_COLS >> 31) ? COMPACT : REDUNDANT */
    dict_mem_table_add_col(table, heap, "N_COLS", DATA_INT, 0, 4, true);
    /* The low order bit of TYPE is always set to 1.  If ROW_FORMAT
    is not REDUNDANT or COMPACT, this field matches table->flags. */
    dict_mem_table_add_col(table, heap, "TYPE", DATA_INT, 0, 4, true);
    dict_mem_table_add_col(table, heap, "MIX_ID", DATA_BINARY, 0, 0, true);
    /* MIX_LEN may contain additional table flags when
    ROW_FORMAT!=REDUNDANT.  Currently, these flags include
    DICT_TF2_TEMPORARY. */
    dict_mem_table_add_col(table, heap, "MIX_LEN", DATA_INT, 0, 4, true);
    dict_mem_table_add_col(table, heap, "CLUSTER_NAME", DATA_BINARY, 0, 0,
                           true);
    dict_mem_table_add_col(table, heap, "SPACE", DATA_INT, 0, 4, true);

    table->id = DICT_TABLES_ID;

    dict_table_add_system_columns(table, heap);
    dict_sys_mutex_enter();
    dict_table_add_to_cache(table, false);
    dict_sys_mutex_exit();
    dict_sys->sys_tables = table;
    mem_heap_empty(heap);

    index = dict_mem_index_create("SYS_TABLES", "CLUST_IND", DICT_HDR_SPACE,
                                  DICT_UNIQUE | DICT_CLUSTERED, 1);

    index->add_field("NAME", 0, true);

    index->id = DICT_TABLES_ID;

    err = dict_index_add_to_cache(
        table, index,
        mtr_read_ulint(dict_hdr + DICT_HDR_TABLES, MLOG_4BYTES, &mtr), false);
    ut_a(err == DB_SUCCESS);

    /*-------------------------*/
    index = dict_mem_index_create("SYS_TABLES", "ID_IND", DICT_HDR_SPACE,
                                  DICT_UNIQUE, 1);
    index->add_field("ID", 0, true);

    index->id = DICT_TABLE_IDS_ID;

    err = dict_index_add_to_cache(
        table, index,
        mtr_read_ulint(dict_hdr + DICT_HDR_TABLE_IDS, MLOG_4BYTES, &mtr),
        false);
    ut_a(err == DB_SUCCESS);

    /*-------------------------*/
    table = dict_mem_table_create("SYS_COLUMNS", DICT_HDR_SPACE, 7, 0, 0, 0, 0);

    dict_mem_table_add_col(table, heap, "TABLE_ID", DATA_BINARY, 0, 8, true);
    dict_mem_table_add_col(table, heap, "POS", DATA_INT, 0, 4, true);
    dict_mem_table_add_col(table, heap, "NAME", DATA_BINARY, 0, 0, true);
    dict_mem_table_add_col(table, heap, "MTYPE", DATA_INT, 0, 4, true);
    dict_mem_table_add_col(table, heap, "PRTYPE", DATA_INT, 0, 4, true);
    dict_mem_table_add_col(table, heap, "LEN", DATA_INT, 0, 4, true);
    dict_mem_table_add_col(table, heap, "PREC", DATA_INT, 0, 4, true);

    table->id = DICT_COLUMNS_ID;

    dict_table_add_system_columns(table, heap);
    dict_sys_mutex_enter();
    dict_table_add_to_cache(table, false);
    dict_sys_mutex_exit();
    dict_sys->sys_columns = table;
    mem_heap_empty(heap);

    index = dict_mem_index_create("SYS_COLUMNS", "CLUST_IND", DICT_HDR_SPACE,
                                  DICT_UNIQUE | DICT_CLUSTERED, 2);

    index->add_field("TABLE_ID", 0, true);
    index->add_field("POS", 0, true);

    index->id = DICT_COLUMNS_ID;

    err = dict_index_add_to_cache(
        table, index,
        mtr_read_ulint(dict_hdr + DICT_HDR_COLUMNS, MLOG_4BYTES, &mtr), false);
    ut_a(err == DB_SUCCESS);

    /*-------------------------*/
    table = dict_mem_table_create("SYS_INDEXES", DICT_HDR_SPACE,
                                  DICT_NUM_COLS__SYS_INDEXES, 0, 0, 0, 0);

    dict_mem_table_add_col(table, heap, "TABLE_ID", DATA_BINARY, 0, 8, true);
    dict_mem_table_add_col(table, heap, "ID", DATA_BINARY, 0, 8, true);
    dict_mem_table_add_col(table, heap, "NAME", DATA_BINARY, 0, 0, true);
    dict_mem_table_add_col(table, heap, "N_FIELDS", DATA_INT, 0, 4, true);
    dict_mem_table_add_col(table, heap, "TYPE", DATA_INT, 0, 4, true);
    dict_mem_table_add_col(table, heap, "SPACE", DATA_INT, 0, 4, true);
    dict_mem_table_add_col(table, heap, "PAGE_NO", DATA_INT, 0, 4, true);
    dict_mem_table_add_col(table, heap, "MERGE_THRESHOLD", DATA_INT, 0, 4,
                           true);

    table->id = DICT_INDEXES_ID;

    dict_table_add_system_columns(table, heap);
    dict_sys_mutex_enter();
    dict_table_add_to_cache(table, false);
    dict_sys_mutex_exit();
    dict_sys->sys_indexes = table;
    mem_heap_empty(heap);

    index = dict_mem_index_create("SYS_INDEXES", "CLUST_IND", DICT_HDR_SPACE,
                                  DICT_UNIQUE | DICT_CLUSTERED, 2);

    index->add_field("TABLE_ID", 0, true);
    index->add_field("ID", 0, true);

    index->id = DICT_INDEXES_ID;

    err = dict_index_add_to_cache(
        table, index,
        mtr_read_ulint(dict_hdr + DICT_HDR_INDEXES, MLOG_4BYTES, &mtr), false);
    ut_a(err == DB_SUCCESS);

    /*-------------------------*/
    table = dict_mem_table_create("SYS_FIELDS", DICT_HDR_SPACE, 3, 0, 0, 0, 0);

    dict_mem_table_add_col(table, heap, "INDEX_ID", DATA_BINARY, 0, 8, true);
    dict_mem_table_add_col(table, heap, "POS", DATA_INT, 0, 4, true);
    dict_mem_table_add_col(table, heap, "COL_NAME", DATA_BINARY, 0, 0, true);

    table->id = DICT_FIELDS_ID;

    dict_table_add_system_columns(table, heap);
    dict_sys_mutex_enter();
    dict_table_add_to_cache(table, false);
    dict_sys_mutex_exit();
    dict_sys->sys_fields = table;
    mem_heap_free(heap);

    index = dict_mem_index_create("SYS_FIELDS", "CLUST_IND", DICT_HDR_SPACE,
                                  DICT_UNIQUE | DICT_CLUSTERED, 2);

    index->add_field("INDEX_ID", 0, true);
    index->add_field("POS", 0, true);

    index->id = DICT_FIELDS_ID;

    err = dict_index_add_to_cache(
        table, index,
        mtr_read_ulint(dict_hdr + DICT_HDR_FIELDS, MLOG_4BYTES, &mtr), false);
    ut_a(err == DB_SUCCESS);

    dict_sys_mutex_enter();
    dict_load_sys_table(dict_sys->sys_tables);
    dict_load_sys_table(dict_sys->sys_columns);
    dict_load_sys_table(dict_sys->sys_indexes);
    dict_load_sys_table(dict_sys->sys_fields);
    dict_sys_mutex_exit();
  }

  mtr_commit(&mtr);

  /*-------------------------*/

  /* Initialize the insert buffer table, table buffer and indexes */

  ibuf_init_at_db_start();

  if (srv_force_recovery != SRV_FORCE_NO_LOG_REDO && srv_read_only_mode &&
      !ibuf_is_empty()) {
    ib::error(ER_IB_MSG_161) << "Change buffer must be empty when"
                                " --innodb-read-only is set!";

    err = DB_ERROR;
  }

  return (err);
}


-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/dict/dict0load.cc
Function: dict_load_table_one not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/dict/dict0load.cc
Function: dict_load_table_one not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/dict/dict0load.cc
Function: dict_load_table_one not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/dict/dict0stats.cc
Function: dict_stats_update_transient_for_index not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/dict/dict0stats.cc
Function: dict_stats_update_transient_for_index not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/dict/dict0stats.cc
Function: dict_stats_update_transient_for_index not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/dict/dict0stats.cc
Function: dict_stats_update_transient_for_index not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/dict/dict0stats.cc
Function: dict_stats_update_transient_for_index not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/dict/dict0stats.cc
Function: dict_stats_update_transient_for_index not found.

-------------------------------------------------------------------------------------------
File: /root/LLVM/mysql-8.0.36/storage/innobase/dict/dict0stats.cc
Function: dict_stats_update
dberr_t dict_stats_update(dict_table_t *table, /*!< in/out: table */
                          dict_stats_upd_option_t stats_upd_option)
/*!< in: whether to (re) calc
the stats or to fetch them from
the persistent statistics
storage */
{
  ut_ad(!dict_sys_mutex_own());

  if (table->ibd_file_missing) {
    if (!dict_table_is_discarded(table)) {
      ib::warn(ER_IB_MSG_224)
          << "Cannot calculate statistics for table " << table->name
          << " because the .ibd file is missing. " << TROUBLESHOOTING_MSG;
    }
    dict_stats_empty_table(table);
    return (DB_TABLESPACE_DELETED);
  } else if (srv_force_recovery >= SRV_FORCE_NO_IBUF_MERGE) {
    /* If we have set a high innodb_force_recovery level, do
    not calculate statistics, as a badly corrupted index can
    cause a crash in it. */
    dict_stats_empty_table(table);
    return (DB_SUCCESS);
  }

  switch (stats_upd_option) {
    dberr_t err;

    case DICT_STATS_RECALC_PERSISTENT:

      if (srv_read_only_mode) {
        break;
      }

      /* wakes the last purge batch for exact recalculation */
      if (trx_sys->rseg_history_len.load() > 0) {
        srv_wake_purge_thread_if_not_active();
      }

      /* Persistent recalculation requested, called from
      1) ANALYZE TABLE, or
      2) the auto recalculation background thread, or
      3) open table if stats do not exist on disk and auto recalc
         is enabled */

      /* InnoDB internal tables (e.g. SYS_TABLES) cannot have
      persistent stats enabled */
      ut_a(strchr(table->name.m_name, '/') != nullptr);

      err = dict_stats_update_persistent(table);

      if (err != DB_SUCCESS) {
        return (err);
      }

      return (dict_stats_save(table, nullptr));

    case DICT_STATS_RECALC_TRANSIENT:
      break;

    case DICT_STATS_EMPTY_TABLE:

      dict_stats_empty_table(table);

      /* If table is using persistent stats,
      then save the stats on disk */

      if (dict_stats_is_persistent_enabled(table)) {
        return (dict_stats_save(table, nullptr));
      }

      return (DB_SUCCESS);

    case DICT_STATS_FETCH_ONLY_IF_NOT_IN_MEMORY:

      /* fetch requested, either fetch from persistent statistics
      storage or use the old method */

      if (table->stat_initialized) {
        return (DB_SUCCESS);
      }

      /* InnoDB internal tables (e.g. SYS_TABLES) cannot have
      persistent stats enabled */
      ut_a(strchr(table->name.m_name, '/') != nullptr);

      /* Create a dummy table object with the same name and
      indexes, suitable for fetching the stats into it. */
      dict_table_t *t = dict_stats_table_clone_create(table);

      err = dict_stats_fetch_from_ps(t);

      t->stats_last_recalc = table->stats_last_recalc;
      t->stat_modified_counter = 0;

      switch (err) {
        case DB_SUCCESS:

          dict_table_stats_lock(table, RW_X_LATCH);

          dict_stats_copy(table, t);

          dict_stats_assert_initialized(table);

          dict_table_stats_unlock(table, RW_X_LATCH);

          dict_stats_table_clone_free(t);

          return (DB_SUCCESS);
        case DB_STATS_DO_NOT_EXIST:

          dict_stats_table_clone_free(t);

          if (srv_read_only_mode) {
            break;
          }

          if (dict_stats_auto_recalc_is_enabled(table)) {
            return (dict_stats_update(table, DICT_STATS_RECALC_PERSISTENT));
          }

          ib::info(ER_IB_MSG_225)
              << "Trying to use table " << table->name
              << " which has persistent statistics enabled,"
                 " but auto recalculation turned off and the"
                 " statistics do not exist in " TABLE_STATS_NAME_PRINT
                 " and " INDEX_STATS_NAME_PRINT
                 ". Please either run \"ANALYZE TABLE "
              << table->name
              << ";\" manually or enable the"
                 " auto recalculation with \"ALTER TABLE "
              << table->name
              << " STATS_AUTO_RECALC=1;\"."
                 " InnoDB will now use transient statistics for "
              << table->name << ".";

          break;
        default:

          dict_stats_table_clone_free(t);

          ib::error(ER_IB_MSG_226)
              << "Error fetching persistent statistics"
                 " for table "
              << table->name
              << " from " TABLE_STATS_NAME_PRINT " and " INDEX_STATS_NAME_PRINT
                 ": "
              << ut_strerr(err) << ". Using transient stats method instead.";

          break;
      }
      /* no "default:" in order to produce a compilation warning
      about unhandled enumeration value */
  }

  dict_table_stats_lock(table, RW_X_LATCH);

  dict_stats_update_transient(table);

  dict_table_stats_unlock(table, RW_X_LATCH);

  return (DB_SUCCESS);
}


